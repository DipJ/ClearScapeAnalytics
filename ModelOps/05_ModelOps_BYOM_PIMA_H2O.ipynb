{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>ModelOps demo - H2O with ModelOps BYOM no code</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![image](images/byom_meth.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This Notebook, we will show you how to work with the Bring Your Own Model (BYOM) pattern and BYOM In-Vantage Scoring. This deployment pattern allows you to use whatever data science platform you want to perform model training and import back to Vantage to do a direct deployment, scoring. For understanding more about BYOM you can review official user documentation.\n",
    "\n",
    "When you use BYOM mechanisms you can deploy models directly from IDE environment, or make a proper operationalization through ModelOps. With ModelOps, you get **full governance** around your models deployment and you can **leverage ModelOps automations** for Validation, Scoring and Monitoring with an intuitive user interface that let you audit at any time all the information from your models and provide dashboards to monitor and review alerts from your deployments.\n",
    "\n",
    "This notebook will cover the Operationalization of the PIMA diabetes use case with H2O model format. **H2O** is an open source, distributed in-memory machine learning library with linear scalability. H2O supports the most widely used statistical & machine learning algorithms including gradient boosted machines, generalized linear models, deep learning and more. The most used capabilities in H2O are the **AutoML** capabilities that provides. In this example we generate a H2O xgboost and operationalize it through ModelOps in the same Model Catalog than other trained models based on other libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in this Notebook\n",
    "\n",
    "<li>1. Configure the Environment </li>\n",
    "    <li>2. Connect to Vantage</li>\n",
    "    <li>3. Train a model and export to H2O native format</li>\n",
    "    <li>4. Import the H2O into ModelOps</li>\n",
    "    <li>5. Go through Lifecycle - Evaluation (Automated Model Report)</li>\n",
    "    <li>6. Go through Lifecycle - Approve </li>\n",
    "    <li>7. Go through Lifecycle - Deploy (Publish and Schedule)</li>\n",
    "    <li>8. Go through Lifecycle - Monitor (Data Drift and Performance)</li>\n",
    "    <li>9. Configure Monitoring alert treshold (Optional) </li>\n",
    "    <li>10. On demand Scoring from SQL (Optional)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Configure the Environment\n",
    "\n",
    "Here, we import the required libraries, set environment variables and environment paths (if required).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Libraries installation\n",
    "\n",
    "**A restart of the Kernel is needed to confirm changes**. We use -q parameter for a non-verbose log of the installation command, you may remove this parameter if you want to know all the steps of the pip installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q teradataml==17.20.0.3 aoa==7.0.1 pandas==1.1.5 scikit-learn==0.24.2 h2o==3.40.0.4 install-jdk==1.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import (\n",
    "    create_context, \n",
    "    remove_context,\n",
    "    get_context,\n",
    "    get_connection,\n",
    "    DataFrame,\n",
    "    retrieve_byom,\n",
    "    H2OPredict,\n",
    "    configure)\n",
    "from teradatasqlalchemy.types import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import logging\n",
    "import sys\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import h2o\n",
    "import os\n",
    "import jdk\n",
    "from h2o.estimators import H2OXGBoostEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Connect to Vantage and configure VAL-BYOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../UseCases/startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO=05_ModelOps_BYOM_PIMA_H2O;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train a model using H2O libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import os\n",
    "import jdk\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "\n",
    "# Check Java installation, installs if required\n",
    "try:\n",
    "    print(f\"Java is installed at {os.environ['JAVA_HOME']}\")\n",
    "except:\n",
    "    os.environ['JAVA_HOME'] = '/home/jovyan/.jdk/jdk-17.0.7+7'\n",
    "    if os.path.isdir(os.environ['JAVA_HOME']) is False:\n",
    "        print ('Installing Java...')\n",
    "        import jdk\n",
    "        jdk.install('17', path='/home/jovyan/.jdk')\n",
    "\n",
    "train_pdf = DataFrame.from_query(\"\"\"\n",
    "SELECT \n",
    "    F.*, D.hasdiabetes \n",
    "FROM pima_patient_features F\n",
    "JOIN pima_patient_diagnoses D\n",
    "    ON F.patientid = D.patientid \n",
    "    WHERE F.patientid MOD 5 <> 0\n",
    "\"\"\").to_pandas(all_rows=True)\n",
    "\n",
    "features = [\"NumTimesPrg\", \"Age\", \"PlGlcConc\", \"BloodP\", \"SkinThick\", \"TwoHourSerIns\", \"BMI\", \"DiPedFunc\"]\n",
    "target = \"HasDiabetes\"\n",
    "\n",
    "# Initialize H2O engine\n",
    "h2o.init()\n",
    "\n",
    "# Convert dataset to H2O\n",
    "train_hf=h2o.H2OFrame(train_pdf)\n",
    "\n",
    "# convert target column to categorical\n",
    "train_hf[target] = train_hf[target].asfactor()\n",
    "\n",
    "model = H2OXGBoostEstimator(eta=0.2, max_depth=6)\n",
    "model.train(x = features, y = target, training_frame = train_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the model to H2O\n",
    "\n",
    "You can save the model as h2o format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.path.abspath(os.getcwd())\n",
    "artifacts_path = \"artifacts\"\n",
    "mojo = model.download_mojo(path=artifacts_path, get_genmodel_jar=True)\n",
    "new_mojo = os.path.join(current_path, artifacts_path, \"model.h2o\")\n",
    "if os.path.isfile(new_mojo):\n",
    "    print(\"The file already exists\")\n",
    "else:\n",
    "    # Rename the file\n",
    "    os.rename(mojo, new_mojo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 -  Import into ModelOps to Operationalize\n",
    "\n",
    "Note some of the images may contain PMML because the operationalization steps are the same. Go to the ModelOps UI and import this as a new model inside the **ModelOps Getting Started** project. \n",
    "\n",
    "Navigate to the projects screen and select the **ModelOps Getting Started** project. Click on it to navigate to the models screen of the project.\n",
    "\n",
    "<img src=\"images/04_01.png\" alt=\"Projects screen\" />\n",
    "\n",
    "If you haven't added a default connection, you will be prompted to add one. Check how to [add a default connection](link here).\n",
    "\n",
    "Once there, click on the **DEFINE BYOM MODEL** button on the top right of the screen.\n",
    "\n",
    "<img src=\"images/04_02.png\" alt=\"Models screen\" />\n",
    "\n",
    "Ensure that **Enable Model Monitoring** is checked and classification as model type is selected. Then set the table the one you have been using (probably your username) and use as Prediction Expression\n",
    "\n",
    "```sql\n",
    "CAST(prediction AS INT)\n",
    "```\n",
    "\n",
    "<img src=\"images/04_03.png\" alt=\"BYOM model import sidesheeet\" />\n",
    "\n",
    "Then click on **SAVE**, and the import job will start.\n",
    "\n",
    "<img src=\"images/04_04.png\" alt=\"BYOM model import job log\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Go through Lifecycle - Evaluation (Automated Model Report)\n",
    "\n",
    "Open the imported ModelID Lifecycle Screen. Review imported artifacts and evaluate the model with default logic (No code needed)\n",
    "\n",
    "<img src=\"images/04_05.png\" alt=\"BYOM model lifecycle\"/>\n",
    "\n",
    "\n",
    "Select Evaluation dataset and run the evaluation process\n",
    "                                 \n",
    "<img src=\"images/04_06.png\" alt=\"Evaluation\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "Now you can review the Model evaluation report generated with default metrics and confusion matrix plot - this can be customized with a custom evaluation logic (later in this notebook)\n",
    "\n",
    "Click on View Report from ModelID Lifecycle screen\n",
    "\n",
    "<img src=\"images/04_07.png\" alt=\"Model Evaluation Report\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Go through Lifecycle - Approve \n",
    "\n",
    "Open the imported ModelID Lifecycle Screen. Click on Approve button to move forward on the next stage\n",
    "\n",
    "Include description of approval and accept\n",
    "\n",
    "<img src=\"images/04_08.png\" alt=\"Approval\" width=\"500\" height=\"500\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Go through Lifecycle - Deploy (Publish and Schedule)\n",
    "\n",
    "Open the imported ModelID Lifecycle Screen. Click on Deploy button to publish Model in Vantage\n",
    "\n",
    "<img src=\"images/04_09.png\" alt=\"Model Lifecycle screen\"/>\n",
    "\n",
    "Now select In-Vantage engine and click next\n",
    "\n",
    "<img src=\"images/04_10.png\" alt=\"Deployment Engine\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "Now select which Connection (here you could use a Service Connection to run in Production optionally), Database and table you want to publish your BYOM model. Use your user and the table \"aoa_byom_models\"\n",
    "\n",
    "<img src=\"images/04_11.png\" alt=\"Deployment Publish\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "Now select if you want to schedule your model scoring, datset template to gather where you want to store your predictions. \n",
    "and run the deploy process\n",
    "\n",
    "<img src=\"images/04_12.png\" alt=\"Deployment Schedule\" width=\"500\" height=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Go through Lifecycle - Monitor (Data Drift and Performance)\n",
    "\n",
    "Open the Deployment and review details of the deployed model\n",
    "\n",
    "<img src=\"images/04_14.png\" alt=\"Deployment details\"/>\n",
    "\n",
    "you can run the Prediction job from here , click the button to run the prediction job\n",
    "\n",
    "<img src=\"images/04_15.png\" alt=\"Deployment Scoring Job\" />\n",
    "\n",
    "\n",
    "You can also review the predictions, you can take this query and run into your SQL IDE or in Notebook later\n",
    "\n",
    "<img src=\"images/04_16.png\" alt=\"Deployment Predictions\" width=\"500\" height=\"500\"/> <img src=\"images/04_17.png\" alt=\"Deployment Predictions query\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "Review your Feature Drift, Prediction Drift. Here ModelOps shows the comparison of the distribution of data between training and evaluation/scoring, every scoring this gets updated and different KPIs are calculated. The one we used by default for monitoring is the Population Stability Index (PSI)\n",
    "\n",
    "<img src=\"images/04_18.png\" alt=\"Feature Drift\" />\n",
    "<img src=\"images/04_19.png\" alt=\"Prediction Drift\" />\n",
    "\n",
    "\n",
    "For Performance Monitoring, we track over time the metrics of the model. For generating new metrics we need to create a new evaluation dataset and run an evaluation job.\n",
    "\n",
    "<img src=\"images/04_20.png\" alt=\"Performance Drift\" />\n",
    "\n",
    "this has been generated using this query for evaluation dataset target:\n",
    "SELECT * FROM pima_patient_diagnoses F WHERE F.patientid MOD 8 <> 0\n",
    "\n",
    "Now the performance has changed:\n",
    "\n",
    "<img src=\"images/04_21.png\" alt=\"Performance Drift change\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Configure Monitoring alert treshold (Optional) \n",
    "\n",
    "we can update the Alerts configuration for the models. \n",
    "\n",
    "First enable Alert from Model catalog\n",
    "\n",
    "<img src=\"images/04_23.png\" alt=\"Alert Configuration\" /> \n",
    "\n",
    "Now, you can change your default alerting mechanism.\n",
    "\n",
    "Go to your Model, and find the Tab \"Alert Configuration\"\n",
    "\n",
    "<img src=\"images/04_22.png\" alt=\"Alert Configuration\" /> \n",
    "\n",
    "Let's change the PSI value to 0.01 instead 0.2\n",
    "Use Edit option:\n",
    "\n",
    "<img src=\"images/04_24.png\" alt=\"Alert Configuration PSI\" width=\"500\" height=\"500\"/> <img src=\"images/04_25.png\" alt=\"Alert Configuration PSI\" width=\"500\" height=\"500\"/> \n",
    "\n",
    "After few minutes, this has generated new alerts on the model deployed\n",
    "Go to Menu -> Alert and review the alerts generated for your model\n",
    "\n",
    "<img src=\"images/04_26.png\" alt=\"Alerts\" />\n",
    "\n",
    "Now go to ModelID and click on View Model Drift\n",
    "\n",
    "<img src=\"images/04_27.png\" alt=\"Model Lifecycle View Model Drift\" width=\"500\" height=\"500\"/>\n",
    "\n",
    "Now review the Feature drift, you can check this screen also from your deployments\n",
    "<img src=\"images/04_28.png\" alt=\"Feature Drift\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 On demand Scoring from SQL (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 View Published Models\n",
    "\n",
    "Once deployed via ModelOps, we can view the models published to vantage by querying the table they are published to. Note this information is available via the AOA APIs also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.from_query(\"SELECT TOP 10 * FROM aoa_byom_models WHERE model_type='H2O'\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 On-Demand Scoring\n",
    "Configuring VAL and BYOM locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure byom/val installation\n",
    "configure.val_install_location = \"VAL\"\n",
    "configure.byom_install_location = \"MLDB\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace model_version with the one we have operationalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teradataml version\n",
    "model_version=\"c14a3544-1cb3-4f96-aeec-9a6cfd67daad\"\n",
    "\n",
    "model = DataFrame.from_query(f\"\"\"\n",
    "SELECT * FROM aoa_byom_models \n",
    "    WHERE model_version='{model_version}'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "preds = H2OPredict(\n",
    "        modeldata=model,\n",
    "        newdata=DataFrame.from_query(\"SELECT * FROM pima_patient_features WHERE patientid MOD 5 = 0\"),\n",
    "        accumulate=['PatientId'])\n",
    "\n",
    "preds.result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL version\n",
    "query = f\"\"\"\n",
    "SELECT * FROM MLDB.H2OPredict (\n",
    "    ON (SELECT * FROM pima_patient_features WHERE patientid MOD 5 = 0) AS InputTable\n",
    "    ON (SELECT * FROM aoa_byom_models \n",
    "            WHERE model_version='{model_version}') AS ModelTable DIMENSION\n",
    "    USING\n",
    "      Accumulate ('patientid')\n",
    ") AS td;\n",
    "\"\"\"\n",
    "\n",
    "DataFrame.from_query(query).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">©2023 Teradata. All Rights Reserved</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
