{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>GLM Fraud Detection with Python and Vantage BYOM</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>This notebook provides a demonstration \"data science workflow\" that illustrates how to leverage open source ML Pipelines with the power and scale of Teradata Vantage.  Users perform the large-scale operations such as feature analysis, data transformation, and ML Moodel Scoring in the Vantage environment without having to move data.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Uses a Data set and feature discovery methods outlined here: <a href = 'https://www.kaggle.com/georgepothur/4-financial-fraud-detection-xgboost/notebook'>https://www.kaggle.com/georgepothur/4-financial-fraud-detection-xgboost/notebook</a></li>\n",
    "    <li>Python Package User Guide: <a href = 'https://docs.teradata.com/reader/eteIDCTX4O4IMvazRMypxQ/uDjppX7PJInABCckgu~KFg'>https://docs.teradata.com/reader/eteIDCTX4O4IMvazRMypxQ/uDjppX7PJInABCckgu~KFg</a></li>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/reader/GsM0pYRZl5Plqjdf9ixmdA/MzdO1q_t80M47qY5lyImOA'>https://docs.teradata.com/reader/GsM0pYRZl5Plqjdf9ixmdA/MzdO1q_t80M47qY5lyImOA</a></li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Contents</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Initiate a connection to Vantage</li>\n",
    "    <li>Read the data from Vantage as a teradaml Dataframe</li>\n",
    "    <li>Perform discovery on the data and analyze features</li>\n",
    "    <li>Clean up the dataset</li>\n",
    "    <li>Create training and testing datasets in Vantage</li>\n",
    "    <li>Create a PMML pipeline locally using sklearn and train it</li>\n",
    "    <li>Load trained PMML Model into Vantage</li>\n",
    "    <li>Score the model directly in Vantage</li>\n",
    "    <li>Visualize the results (ROC curve and AUC)</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Experience</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This demo takes about 5 minutes to run.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Installing some dependencies</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn2pmml in /home/jovyan/.local/lib/python3.9/site-packages (0.86.3)\n",
      "Requirement already satisfied: sklearn-pandas>=0.0.10 in /home/jovyan/.local/lib/python3.9/site-packages (from sklearn2pmml) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.13.0 in /opt/conda/lib/python3.9/site-packages (from sklearn2pmml) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /opt/conda/lib/python3.9/site-packages (from sklearn2pmml) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18.0->sklearn2pmml) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18.0->sklearn2pmml) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18.0->sklearn2pmml) (3.1.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.9/site-packages (from sklearn-pandas>=0.0.10->sklearn2pmml) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml) (1.16.0)\n",
      "Requirement already satisfied: jdk4py in /opt/conda/lib/python3.9/site-packages (17.0.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn2pmml --user\n",
    "!pip install jdk4py --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Configuring the Environment</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jdk4py import JAVA, JAVA_HOME, JAVA_VERSION\n",
    "\n",
    "from teradataml import *\n",
    "from teradataml.options.display import display\n",
    "# from teradataml.catalog.byom import *\n",
    "\n",
    "# import tdconnect\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "\n",
    "import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some environmental stuff - need java in the path if necessary\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH'] + os.pathsep + str(JAVA_HOME)\n",
    "os.environ['PATH'] = os.environ['PATH'] + os.pathsep + str(JAVA)[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'> Accessing the Data\n",
    "<p style = 'font-size:16px;font-family:Arial'>These demos will work either with foreign tables accessed from Cloud Storage via NOS or you may import the tables to your machine. If you import data for multiple demos, you may need to use the Data Dictionary \"Manage Your Space\" routine to cleanup tables you no longer need. \n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Use the link below to access the 2 options for using data from the data dictionary notebook:\n",
    "\n",
    "[Click Here to get data for this notebook](../Data_Dictionary/Data_Dictionary.ipynb#TRNG_BYOM)\n",
    "\n",
    "[Click Here to Manage Your Space](../Data_Dictionary/Data_Dictionary.ipynb#Manage_Your_Space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the BYOM functions\n",
    "configure.byom_install_location = 'TRNG_BYOM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Initiate a connection to Vantage</b>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Make changes for your execution</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The Jupyter Module for Teradata provides a helper library called tdconnect - this can use the underlying client configs and pass a JWT token for SSO. Establish connection to Teradata Vantage server (uses the Teradata SQL Driver for Python). Before you execute the following statement, replace the variables &ltHOSTNAME&gt, &ltUID&gt and &ltPWD&gt with your target Vantage system hostname (or IP address), and your database user ID(QLID) and password, respectively.</p>\n",
    "    \n",
    "<p style = 'font-size:14px;font-family:Arial'>td_context = create_context(host=\"tdprdX.td.teradata.com\", username=\"xy123456\", password=gp.getpass(prompt='Password:'), logmech=\"LDAP\")</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ···\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(teradatasql://demo_user:***@host.docker.internal)\n"
     ]
    }
   ],
   "source": [
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = getpass.getpass())\n",
    "# eng = tdconnect.create_context('Vantage-LIVE')\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Read the data from Vantage as a teradaml Dataframe</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The data from <a href = 'https://www.kaggle.com/code/georgepothur/4-financial-fraud-detection-xgboost/data'>https://www.kaggle.com/code/georgepothur/4-financial-fraud-detection-xgboost/data</a> is loaded in Vantage in a table named \"ip_data\". Check the data size and print sample rows. 600k rows and 11 columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data as a teradataml dataframe\n",
    "ip_data = DataFrame('ip_data')\n",
    "\n",
    "print(ip_data.shape)\n",
    "ip_data.to_pandas(num_rows = 5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>In-database data manipulation</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Example of an in-database manipulation of data. Here we rename a misspelt column without moving the data out of Vantage. We are renaming <b>oldbalanceOrg</b> to <b>oldbalanceOrig</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = ip_data.assign(oldbalanceOrig = ip_data.oldbalanceOrg).drop(['oldbalanceOrg'] , axis=1)\n",
    "\n",
    "new_data.to_pandas(num_rows = 5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Data Fields</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>txn_id:</b> transaction-id</li>\n",
    "    <li><b>step:</b> maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (31 days simulation).</li>\n",
    "    <li><b>type:</b> CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.</li>\n",
    "    <li><b>amount:</b> amount of the transaction in local currency.</li>\n",
    "    <li><b>nameOrig:</b> customer who started the transaction</li>\n",
    "    <li><b>oldbalanceOrg:</b> initial balance before the transaction</li>\n",
    "    <li><b>newbalanceOrig:</b> new balance after the transaction</li>\n",
    "    <li><b>nameDest:</b> customer who is the recipient of the transaction</li>\n",
    "    <li><b>oldbalanceDest:</b> initial balance recipient before the transaction.</li>\n",
    "    <li><b>newbalanceDest:</b> new balance recipient after the transaction.</li>\n",
    "    <li><b>isFraud:</b> This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Check if any column has missing values</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.info(null_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. Perform discovery on the data and analyze features</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The following section is an example of dataset analysis.  We're trying to see what features are most impactful and can be used to train our model. We also want to minimize the amount of data transferred to the client, and maximize the amount of work done on the cluster.</p>\n",
    "<br>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>6 Million records -> 8,213 records -> 20/40 records.<br>Feel free to skip down to the next section for analysis and next steps</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.1 Statitics of the dataset</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.2 How many fraudulent transactions do we have in our dataset?</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data.loc[new_data.isFraud == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.3 How many fraudulent transactions do we have group by transaction type?</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data.isFraud == 1].groupby('type').count().get(['type','count_step']).sort('count_step', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.4 Are there any patterns in amount of transaction?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We see many transactions with amounts 10000000.0 and 0.0 as old balance in origin account. This might be and indication of attempted fraud.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.max_rows = 5\n",
    "new_data.loc[new_data.isFraud == 1].groupby('oldbalanceOrig').count().get(['oldbalanceOrig','count_step']).sort('count_step', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.5 What percentage of fraudulent transactions do we have where transaction amount is equal to old balance in the origin account?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This might be the case where the fraudster emptied the account of the victim.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = new_data.loc[(new_data.isFraud == 1) and (new_data.amount == new_data.oldbalanceOrig)].shape[0] / new_data.loc[new_data.isFraud == 1].shape[0] * 100\n",
    "print(str(round(t, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.6 What percentage of fraudulent transactions do we have where new balance in the origin account is zero?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This might be the case where the fraudster emptied the account of the victim.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = new_data.loc[new_data.isFraud == 1][new_data.newbalanceOrig == 0].shape[0] / new_data.loc[new_data.isFraud == 1].shape[0] * 100\n",
    "print(str(round(t, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.7 What percentage of fraudulent transactions do we have where old balance in the destination account is zero?</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This might be the case where the fraudster regularly makes fraud transaction and withdraws entire amount from the destiantion account.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = new_data.loc[new_data.isFraud == 1][new_data.oldbalanceDest == 0].shape[0] / new_data.loc[new_data.isFraud == 1].shape[0] * 100\n",
    "print(str(round(t, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.8 has this been \"flagged\" as fraud using prior predictive methods?</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[ip_data.isFraud == 1].groupby('isFlaggedFraud').count().get(['isFlaggedFraud','count_step']).sort('count_step', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> \n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.9 Feature Analysis</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>By analyzing the dataset, we come to the following conclusions about the features:</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>step</b> : Include this feature. The fraudulent transactions distributed in many 'step' values.</li>\n",
    "    <li><b>type</b> : Include this feature. The fraudulent transaction happened only in 'CASH_OUT' and 'TRANSFER' transaction types. So we will include only the records with type as 'CASH_OUT' and 'TRANSFER.'</li>\n",
    "    <li><b>amount</b> : Include this feature. Though it won't explain all fraudulent transactions, amount as 10000000.0 and 0.0 denotes a high chance of fraud.</li>\n",
    "    <li><b>nameOrig</b> : Drop this feature. There is no useful information from this column.</li>\n",
    "    <li><b>oldbalanceOrig</b> : Include this feature. You could see that in almost all fraudulent transactions, 'oldbalanceOrig' and 'amount' has the same value. This is a strong indicator of a fraudulent transaction.</li>\n",
    "    <li><b>newbalanceOrig</b> : Include this feature. For most of the fraudulent transactions, 'newbalanceOrig' = 0 (this fact supports our finding in #5)</li>\n",
    "    <li><b>nameDest</b> : Drop this feature. There is no useful information from this column.</li>\n",
    "    <li><b>oldbalanceDest</b> : Include this feature. Value of 'oldbalanceDest' is zero for nearly half of the fraudulent transaction.</li>\n",
    "    <li><b>newbalanceDest</b> : Include this feature. Value of 'newbalanceDest' is zero for more than half of the fraudulent transaction. We will include this feature in our model.</li>\n",
    "    <li><b>isFlaggedFraud</b> : Drop this feature. Only 2 transactions flagged correctly, so we can drop this.</li>    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Clean up the dataset</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Based on what we discovered above, we will:</p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Remove all data that isn't 'CASH OUT' or 'TRANSFER'</li>\n",
    "    <li>Drop \"nameOrig\" and \"nameDest\" since the origin and destination accounts don't matter.</li>\n",
    "    <li>Drop \"isFlaggedFraud\" because that's a useless indicator as well</li>\n",
    "</ol> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = new_data.loc[(new_data.type == 'CASH_OUT') | (new_data.type == 'TRANSFER')]\n",
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.drop(['nameDest', 'nameOrig', 'isFlaggedFraud'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>6. Create training and testing datasets in Vantage</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here we'll copy this teradata Dataframe to a separate table in Vantage. We'll also create two datasets for training and testing in the ratio of 80:20.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the source data table in the database\n",
    "clean_data.to_sql('clean_data', if_exists = 'replace', primary_index='txn_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do it in sql - drop TRAIN table if exists\n",
    "\n",
    "qry = 'DROP TABLE clean_data_train;'\n",
    "# Execute Query\n",
    "\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create TRAIN table using SAMPLE\n",
    "\n",
    "qry = '''\n",
    "CREATE MULTISET TABLE clean_data_train \n",
    "  AS(SELECT * FROM clean_data SAMPLE 0.8) \n",
    "WITH DATA\n",
    "PRIMARY INDEX (txn_id);\n",
    "'''\n",
    "\n",
    "# Execute Query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets do it in sql - drop TEST table if exists\n",
    "\n",
    "qry = 'DROP TABLE clean_data_test;'\n",
    "# Execute Query\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except Exception as e:\n",
    "    if str(e.args).find('3807') >= 1:\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create TEST table using SAMPLE\n",
    "\n",
    "qry = '''\n",
    "CREATE MULTISET TABLE clean_data_test\n",
    "  AS(SELECT * FROM clean_data\n",
    "    EXCEPT\n",
    "    SELECT * FROM clean_data_train)\n",
    "WITH DATA\n",
    "PRIMARY INDEX (txn_id);  \n",
    "'''\n",
    "\n",
    "# Execute Query\n",
    "eng.execute(qry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>7. Create a PMML pipeline locally using sklearn and train it</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here we will use Logistic Regression as a classifier model in our PMML pipeline. The Predictive Model Markup Language (PMML) is an XML-based language which provides a way for applications to define machine learning, statistical and data mining models and to share models between PMML compliant applications.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating TD dataframes for training and testing datasets\n",
    "clean_data_train = DataFrame('clean_data_train')\n",
    "clean_data_test = DataFrame('clean_data_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>7.1 Create a local pandas dataframe.<b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>This dataframe is created outside Vantage. The model is trained outside Vantage. The model would be later saved to Vantage and in-database scoring would be performed at scale.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_train_df = clean_data_train.to_pandas(all_rows = True)\n",
    "clean_data_train_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>7.2 Train the Pipeline and save the model locally<b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The model would be saved in a file called <b>mm_fraud_glm_model.pmml</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = clean_data_train_df[['isFraud']].astype(int)\n",
    "X_train = clean_data_train_df[['step','amount','newbalanceOrig','oldbalanceDest','newbalanceDest','oldbalanceOrig']].astype(float)\n",
    "\n",
    "\n",
    "pipeline = PMMLPipeline([\n",
    "     (\"classifier\", LogisticRegression())\n",
    "     ])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "sklearn2pmml(pipeline, \"mm_fraud_glm_model.pmml\", with_repr = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>8. Load trained PMML Model into Vantage</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Pass the local pmml file to the save_byom function. This function would load the <b>mm_fraud_glm_model.pmml</b> file into Vantage in a table called <b>mm_glm</b>. If there is alredy a model with same name, the previous on e would be deleted and new one would be loaded.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PMML file into Vantage\n",
    "try:\n",
    "    res = save_byom(model_id = 'mm_glm1', model_file = 'mm_fraud_glm_model.pmml', table_name = 'mm_glm')\n",
    "\n",
    "except Exception as e:\n",
    "    # if our model exists, delete and rewrite\n",
    "    if str(e.args).find('TDML_2200') >= 1:\n",
    "        res = delete_byom(model_id = 'mm_glm1', table_name = 'mm_glm')\n",
    "        res = save_byom(model_id = 'mm_glm1', model_file = 'mm_fraud_glm_model.pmml', table_name = 'mm_glm')\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# Obtain a pointer to the model\n",
    "model_tdf = DataFrame.from_query(\"SELECT * FROM mm_glm WHERE model_id = 'mm_glm1'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>9. Score the model directly in Vantage</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'> PMMLPredict will score the model on data resident in Vantage without moving data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the PMMLPredict function in Vantage\n",
    "result = PMMLPredict(\n",
    "            modeldata = model_tdf,\n",
    "            newdata = clean_data_test,\n",
    "            accumulate = ['step','amount','newbalanceOrig','oldbalanceDest','newbalanceDest','oldbalanceOrig', 'isFraud'],\n",
    "            overwrite_cached_models = '*',\n",
    "            model_output_fields = ['probability(1)', 'probability(0)']\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local pandas dataframe of the results\n",
    "result_df = result.result.to_pandas(all_rows = True)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>10. Visualize the results (ROC curve and AUC)</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Calculate mean absolute error and AUC(Area Under the Curve) for Receiver Operating Characteritic Curve</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Mean Absolute Error is the summation of difference of actual and predicted value averaged over the number of observations.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(result_df['isFraud'], result_df['probability(1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>ROC curve is a graph between TPR(True Positive Rate) and FPR(False Positive Rate). The area under the ROC curve is a metric on how good the model is able to distinguish between positive and negative classes. The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes. AUC above 0.75 is generally considered decent.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(result_df['isFraud'], result_df['probability(1)'])\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(result_df['isFraud'], result_df['probability(1)'])\n",
    "plt.plot(fpr, tpr, color='orange', label='ROC. AUC = {}'.format(str(AUC)))\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>11. Cleanup</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE clean_data_train;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE clean_data_test;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE mm_glm;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">©2022 Teradata. All Rights Reserved</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
