{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acquired-consideration",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Energy Consumption Forecasting using Dataiku</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701a2ac-9d7c-4498-a23c-7ae3955f6a32",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this business use case, we leverage the power of Dataiku and Teradata Vantage to enhance our machine learning capabilities and enable scalable model scoring. Our goal is to efficiently utilize the strengths of both platforms to streamline our data analysis and decision-making processes.\n",
    "<br>\n",
    "<br>\n",
    "Dataiku serves as a comprehensive data science platform that empowers us to read data from Teradata Vantage, a powerful analytical database. By leveraging Dataiku's seamless integration with Vantage, we can easily extract and analyze large volumes of data stored within the database.\n",
    "<br>\n",
    "<br>\n",
    "Within Dataiku, we harness its rich set of features and functionalities to build and fine-tune multiple machine learning models. With its user-friendly interface and wide array of machine learning algorithms, we can develop models that are tailored to our specific business requirements. Dataiku enables us to handle data preprocessing, feature engineering, model training, and evaluation, providing a complete end-to-end data science workflow.\n",
    "<br>\n",
    "<br>\n",
    "Once the models are trained and validated within Dataiku, we can seamlessly bring them back to Teradata Vantage. Here, we leverage Vantage's advanced functionality known as BYOM (Bring Your Own Model), which allows us to score our machine learning models directly within the Vantage environment. This capability empowers us to perform model scoring at scale, leveraging the high-performance and parallel processing capabilities of Vantage.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset used in this demo represents electricity consumption in Norway from the 1st of January 2016 to the 31st of August 2019. Each line in this dataset reflects consumption for one hour. Apart from electricity consumption, this datamart also reflects additional data: weather from multiple sources, daylight information and labour calendar. We collected all data from open data sources.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419e9f9-0356-4e40-b59f-34281de410b2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d4207-bc98-428b-93d3-7955c99a34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jdk4py import JAVA, JAVA_HOME, JAVA_VERSION\n",
    "\n",
    "from teradataml import *\n",
    "from teradataml.dataframe.dataframe import DataFrame, in_schema\n",
    "from teradataml.context.context import create_context, remove_context\n",
    "from teradataml.options.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "display.max_rows = 5\n",
    "\n",
    "# Modify the following to match the specific client environment settings\n",
    "configure.val_install_location = 'val'\n",
    "configure.byom_install_location = 'mldb'\n",
    "os.environ['PATH'] = os.pathsep.join([os.environ['PATH'], str(JAVA_HOME), str(JAVA)[:-5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d75d8d-d58b-4bb8-87e5-cdf1a8add76a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Let's start by connecting to the Teradata system </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef7d0b-af14-43a8-8725-7952ea3d0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO=Energy_Consumption_Forecasting_Dataiku.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0be93a-2c49-4708-a17e-3e9e1401c8fc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20217e-9600-4ef7-adc5-6ba10c76a5cc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a490a6-75b8-4d4d-8986-46b03fc57081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_Energy_cloud');\"        # Takes 15 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_Energy_local');\"        # Takes 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c1780-0cca-4b25-8fc5-cefbf8bde51b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step â€“ if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c657c8-2122-4426-9d38-c5a619f7817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393eb65-b65d-4ca2-a1e2-1f546512449e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Dataiku (In-Progress)</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Now that you have got the data in Vantage, let's see how to create a dataiku flow which looks like below.</p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Dataiku Flow:</b></p>\n",
    "<img src=\"images/flow.jpeg\" alt=\"Dataiku Flow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000091c5-6b3c-49e8-ae65-42a2db0c02d9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>2.1 Import dataset</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Create a new project and click on <b>+ IMPORT YOUR FIRST DATASET</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Select your connection from the dropdown</li>\n",
    "    <li>Enter Table as <b>consumption</b></li>\n",
    "    <li>Enter Schema as <b>DEMO_Energy_db</b></li>\n",
    "    <li>Click on CREATE</li>\n",
    "</ol>\n",
    "<img src = 'images/data.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954082f9-8a77-44ef-acb6-032642396c92",
   "metadata": {},
   "source": [
    "- Consumption dataframe is loaded from vantage to dataiku\n",
    "- Data Transformation\n",
    "    - One-hot encoding\n",
    "    - Min-Max Scaler\n",
    "- transformed_df is stored in dataiku\n",
    "- Train test split\n",
    "- Training\n",
    "    - Creating sklearn pipeline for Linear Regression and Random Forest models\n",
    "    - Training both the models\n",
    "    - Saving the models in Vantage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-poetry",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Model Scoring and Evaluation</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The final step in this process is to test the trained model.  The PMMLPredict function will take the stored pipeline object (including any data preparation and mapping tasks) and execute it against the data on the Vantage Nodes.  Note that we can keep many models in the model table, with versioning, last scored timestamp, or any other management data to allow for the operational management of the process.</p>\n",
    "        <ol style = 'font-size:16px;font-family:Arial'>\n",
    "            <li>Create a pointer to the model in Vantage</li>\n",
    "            <li>Execute the Scoring function using the model against the testing data</li>\n",
    "            <li>Visualize the results</li>\n",
    "        </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3f5de-48ac-40e8-8815-12066e927438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a pointer to the model\n",
    "table_name = 'dataiku_models'\n",
    "model_id = 'lr'\n",
    "model_lr = retrieve_byom(model_id, table_name=table_name, schema_name=\"demo_user\")\n",
    "df_test = DataFrame('DATAIKUBYOM_test_df')\n",
    "\n",
    "result_lr = PMMLPredict(\n",
    "            modeldata = model_lr,\n",
    "            newdata = df_test,\n",
    "            accumulate = ['TD_TIMECODE','consumption'],\n",
    "            ).result.to_pandas(all_rows = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c31e0ce-b465-44eb-87ac-42af306d4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee4881e-3107-4567-aad6-4daac51b6231",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the above step, we use the PMMLPredict method from teradataml library to score the model in the database. The PMMLPredict function in Teradata allows users to score the PMML model directly on the data in the Vantage system, without having to move the data or the model outside the system. This can help to improve the efficiency and security of the scoring process.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c73a7-4832-408b-a3fb-844612a06aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a pointer to the model\n",
    "table_name = 'dataiku_models'\n",
    "model_id = 'rf'\n",
    "model_rf = retrieve_byom(model_id, table_name=table_name, schema_name=\"demo_user\")\n",
    "df_test = DataFrame('DATAIKUBYOM_test_df')\n",
    "\n",
    "result_rf = PMMLPredict(\n",
    "            modeldata = model_rf,\n",
    "            newdata = df_test,\n",
    "            accumulate = ['TD_TIMECODE','consumption'],\n",
    "            ).result.to_pandas(all_rows = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10c2b9-51f9-467d-be59-4e0bab6128c6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the above step, we use the PMMLPredict method from teradataml library to score the model in the database. The PMMLPredict function in Teradata allows users to score the PMML model directly on the data in the Vantage system, without having to move the data or the model outside the system. This can help to improve the efficiency and security of the scoring process.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989b9d6-cd74-4e66-a2c6-c08051f4bcc1",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. Visualize the results</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7703ce-fc14-4f5b-af26-4434509ea197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and preprocess\n",
    "df_lr = result_lr\n",
    "df_rf = result_rf\n",
    "\n",
    "# Calculate RMS errors\n",
    "normalize_value = int(DataFrame('DATAIKUBYOM_train_df').to_pandas(all_rows=True).sort_values('TD_TIMECODE').tail(24).mean()['consumption'])\n",
    "rms_lr = mean_squared_error(result_lr['consumption'], result_lr['prediction'].astype(float) + normalize_value, squared=False)\n",
    "rms_rf = mean_squared_error(result_rf['consumption'], result_rf['prediction'].astype(float) + normalize_value, squared=False)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Add the first plot (linear regression)\n",
    "ax.plot(df_lr.index, df_lr['consumption'], label=f'Actual Consumption', color='red', linewidth=2)\n",
    "ax.plot(df_lr.index, df_lr['prediction'].astype(float) + normalize_value, label=f'Linear Regression (RMS={rms_lr:.2f})', color='blue', linestyle='--')\n",
    "\n",
    "# Add the second plot (random forest)\n",
    "ax.plot(df_rf.index, df_rf['prediction'].astype(float) + normalize_value, label=f'Random Forest (RMS={rms_rf:.2f})', color='green', linestyle='--')\n",
    "\n",
    "# Set the axis labels, title, and legend\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Energy Consumption')\n",
    "ax.set_title('Energy Consumption Prediction')\n",
    "ax.legend()\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(axis='y', linestyle='--')\n",
    "\n",
    "# Add a background color\n",
    "fig.patch.set_facecolor('#f2f2f2')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5e1b8-f01e-490b-a8f9-15f2d0a201b6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above graph displays the Root Mean Squared (RMS) error values for both Linear Regression and Random Forest models. The lower the RMS error value, the better the model's performance. As we can see, Random Forest outperforms Linear Regression in predicting energy demand, as it has a lower RMS error value. Therefore, Random Forest is more suitable for proactively predicting energy demand in our use case.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>This demonstration has illustrated a simplified - but complete - overview of how a typical machine learning workflow can be improved using Vantage in conjunction with open-source tools and techniques.  This combination allows users to leverage open-source innovation with Vantage's operational scale, power, and stability.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e9e44-3119-4852-8574-9303a40fcd52",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee1d3b-4f55-4e97-95ab-7a4689321563",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='energy_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ce515-d02e-4872-91ae-7735a9db9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='DATAIKUBYOM_train_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80323e7-2d7b-40e1-be91-2ed040b795bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='DATAIKUBYOM_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024e65c-581b-4b59-9d09-75995a7d07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_drop_table(table_name='dataiku_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377fef9-b377-4b59-a313-5eb9784dba93",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472c2ca-65d0-4116-9c45-6411fcea52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_Energy');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0b73e-0c50-4110-be9c-05aaf1181960",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright Â© Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
