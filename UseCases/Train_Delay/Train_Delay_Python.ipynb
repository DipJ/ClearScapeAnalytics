{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e9543f-e1dc-48da-8a07-007bc1c65df7",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Train Delay Prediction</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5a94f-446b-44d5-bff0-134f597692ac",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Train delays significantly affect both the operational effectiveness of railway companies and the overall experience of passengers in the transportation sector. \n",
    "Understanding and examining the reasons for delays can offer insightful information to enhance train operations and reduce interruptions.\n",
    "Predictive models can anticipate potential delays and enable pro-active planning, so that resources are allocated as necessary.\n",
    "<center><img src=\"images/introduction.png\"/></center>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo we will use synthetic data dealing with train travel from one station to another. During these travels, events are recorded. This notebook illustrates how to use Vantage to extract valuable insights from this event table.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9e6ab-9ff3-42b7-8fad-12d5fac094f8",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Import python packages and connect to Vantage</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c983d10-1966-422b-8c4e-9fb95bcd213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from teradataml import *\n",
    "\n",
    "# Modify the following to match the specific client environment settings\n",
    "display.max_rows = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a41075-b70f-4aee-83c2-99aaccd43f15",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Let's start by connecting to the Teradata system </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bc050-6a42-4cfe-acbb-45e9ba69f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO=Train_Delay.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebdd3f-3ffe-458d-a713-691f5af68862",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5768fc-74e8-4c83-81b0-658cbe7599b5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b31f9-399b-4c34-a942-1442e6abbe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run -i ../run_procedure.py \"call get_data('DEMO_TrainDelay_cloud');\"        # Takes 30 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_TrainDelay_local');\"        # Takes 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e3111-7a88-4d25-b851-0f3e27ab6f40",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9b7a9-2d15-4435-a15e-544ed4cd8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023b0fa-f4d8-4804-9e19-ab948fb42dc9",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Data Exploration</b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Create a \"Virtual DataFrame\" that points to the data set in Vantage. Check the shape of the dataframe as check the datatypes of all the columns of the dataframe.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7102e12-92e3-4efb-884f-7a1827b1bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = DataFrame(in_schema(\"DEMO_TrainDelay\" ,\"Train_Dataset\"))\n",
    "mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9bbe1-0c45-41e4-aff9-073cb03c0974",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "Two major functions from tdml are highlighted here:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>    \n",
    "<li> DataFrame which is the key object that point to the Teradata tables of interest without data export to the client machine</li>\n",
    "<li>in_schema that aims to specify on which schema/database the tables are.</li>\n",
    "</ul>  \n",
    "<p style = 'font-size:16px;font-family:Arial'><i>mydata</i> is a DataFrame object from Teradata. However, it shares several features and methods in common with numpy array and pandas dataframes, like:\n",
    "<ul style = 'font-size:16px;font-family:Arial'> \n",
    "    <li> shape to get the number of rows and columns</li>\n",
    "    <li> dtypes to get the data types per columns</li>\n",
    "    <li> groupby, select, agg, ... to compute and manipulate aggregation</li>\n",
    "    <li> iloc, loc to filter rows and columns</li>\n",
    "    <li> columns to get the column names</li>\n",
    "    </ul>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77362182-1eab-4907-9b46-dcd468433253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "type(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41287d99-4fc6-43a0-9c85-5e9a42c89106",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36389b88-6df3-4b16-9b12-48261ca1ec5d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>mydata dataframe contains 54616 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7c48c-5683-413c-825a-5f0fbb8013db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87e891-20d3-4194-8ac8-fbcbe3cbe17f",
   "metadata": {},
   "source": [
    "<ul style = 'font-size:16px;font-family:Arial'>The columns are 3:\n",
    "    <li> TravelID as int </li>\n",
    "<li> events as string</li>\n",
    "    <li> datetime as datetime</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbc27f-63c3-4fc1-a83e-6e29abe203bd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>As an example, we can see all different events contained in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a39d3-aedd-4055-bd00-07e40a467d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.groupby(['Events']).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea658f6-9d06-4818-baf3-fe327d54e715",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>It is possible to plot the aggregated data using the to_pandas() method to collect the data in the client and use the matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e20173-8535-4522-be40-d9dc2ba2afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4plot = mydata.groupby(['Events']).agg('count').to_pandas()\n",
    "df4plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7178d-3ad0-455c-853c-1ae2356a2702",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here we see that we have as much departure as arrival which is expected. The most frequent events are <i>Door light failure</i> and <i>Normal stop</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9b5e9-5e0c-4538-9ec1-f54b80c3645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rc('ytick', labelsize=20)\n",
    "df4plot.plot.barh(x='Events',y='count_TravelID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e24e0e-8485-4bd9-ad62-e9590c12acd9",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Advanced Data Exploration : Path Analysis </b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The *NPATH* function of the Advanced SQL of Teradata allows direct query of specific paths contained in an event table.<br>\n",
    "In this example, we want to build all the path of events the travels pass through, meaning:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li> for each travel</li>\n",
    "    <li> get the sequence of events</li>\n",
    "A travel can be modelled as a sequence of event starting from the *departure* event, and ending with the *arrival* event.</ul>\n",
    "<center><img src=\"images/npath_sankey.png\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b37c8c-e9a4-4e23-b36d-0d35a1f2026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myPathAnalysis = NPath(data1     = mydata,\n",
    "               data1_partition_column = 'TravelID',\n",
    "               data1_order_column     = 'Datetime',\n",
    "               result                 = ['FIRST (TravelID OF any (Dep,Arr)) AS TravelID',\n",
    "                                         'ACCUMULATE (cast(events as VARCHAR(50) CHARACTER SET UNICODE NOT CASESPECIFIC)OF any(Other,Dep,Arr)) AS MyPath',\n",
    "                                         'first(Datetime of Dep) AS departure_time',\n",
    "                                         'last(Datetime of Arr) As arrival_time'\n",
    "                                        ],\n",
    "               mode                   = 'nonoverlapping',\n",
    "               pattern                = '^Dep.Other*.Arr$',\n",
    "               symbols                = [\"events='departure' AS Dep\",\n",
    "                                         \"events='arrival' AS Arr\",\n",
    "                                         \"true as Other\"\n",
    "                                        ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8b365-0686-427f-9063-933bdcd5aae2",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The results of the npath can be customized. We can add the path (here the *mypath* column) but also the departure and arrival time for each travel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648747e-c07b-427d-8c63-66d381c2c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myPathAnalysis.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e2594-fccc-4584-ba75-e64342b58a3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In order to visualize the distribution of the different path of events, we typically use Sankey diagram of the aggregated over the paths reported by the NPATH command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ba2c0-8c12-4298-b1db-b077a4c9a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdnpathviz.visualizations import plot_first_main_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e565c17c-551e-422b-9d62-722cd9ca04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_first_main_paths(myPathAnalysis.result,path_column='mypath',id_column='travelid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d1ab6-0533-42cd-a5cd-37b280fcfdb3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "To check the details of any path or node we can move the mouse pointer over it and check details. The number on the path represent the count of travelids which have that path and source and target mentions the incoming and outcoming events.<br>\n",
    "When the pointer is moved over a Node, for example when the pointer is on the long purple Node at the right top arrival it shows incoming flow count: 4 and outgoing flow count: 0 which means that there are 4 different events which lead to this node similarly outgoing flow count gives the count of events after this event.<br>\n",
    "<br>\n",
    "For sake of clarity, it is important to focus on the most important paths from a business viewpoint. Here we decided to look at the most frequent ones, i.e. a frequency > 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9b978-e686-44dc-b36c-2754effe288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nPathdf_group=myPathAnalysis.result.groupby(\"mypath\")\\\n",
    "                .count()\\\n",
    "                .sort('count_travelid',ascending=False)\n",
    "nPathdf_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99dd1eb-bcf8-46ae-8019-b38803010bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_travel=nPathdf_group.count_travelid\n",
    "nPathdf_group_plot=nPathdf_group[count_travel >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99baf6-f30f-4d5e-8a1a-2b6c56632326",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plot_first_main_paths(nPathdf_group_plot,path_column='mypath',id_column='count_travelid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc4f3e-25aa-48ae-a6f5-72a66331ac67",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The visualization of paths in event table is critical to design the best modeling strategy. For instance the business may decide to ignore some events because to doubt about the meaning of a given event and rapidly assess its importance in its entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2229f-a555-4656-b73f-2ab744c1a455",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Data Preparation using the Massive Parallel Processing of Teradata</b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "In this example, we want to predict the delay induced by each event assuming each delay adds up independently from each other. For this purpose, we will use Machine Learning algorithm to predict the delay from the frequency of each event.\n",
    "<center><img src=\"images/data_science_model.png\"/></center>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "It is a good practice to perform the data preparation as a table or a view. In this case, we are sure the data preparation leverage the Massive Parallel Processing of Teradata. Moreover, the data preparation is shareable across the enterprise and guarantee the operationalization of the solution.<br>In this example, we decide to use a view, named *usecase_dataset*. Doing will always provide an updated dataset with the latest data. This view can be used later on to historize as many dataset as needed for training and testing.<br>\n",
    "To do so, we can push a SQL query to build this view in a data lab space in Teradata. Note that this view relies on the NPATH Teradata function and timestamp manipulation to create the target feature which is the travel duration in second (*travel_duration_sec*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03255044-8ad5-4ac1-8139-48cafc0a9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery = \"\"\"REPLACE VIEW demo_user.usecase_dataset (TravelID,travel_duration_sec, travel)\n",
    " AS\n",
    " SELECT TravelID,travel_duration_sec, travel  FROM (\n",
    "  SELECT \n",
    "        TravelID AS TravelID,\n",
    "        departure_time AS departure_time,\n",
    "        arrival_time AS arrival_time,\n",
    "        (arrival_time - departure_time) HOUR TO SECOND(4) as travel_duration,\n",
    "        INTERVAL(PERIOD(departure_time,arrival_time)) MINUTE(3) as travel_duration_min,\n",
    "        EXTRACT(HOUR FROM travel_duration)*3600 + EXTRACT(MINUTE FROM travel_duration)*60 + EXTRACT(SECOND FROM travel_duration) as travel_duration_sec,\n",
    "        travel as travel\n",
    "  FROM NPATH (\n",
    "  ON (\n",
    "        SELECT TravelID, events, datetime\n",
    "        FROM DEMO_TrainDelay.train_dataset\n",
    "     ) \n",
    "    PARTITION BY TravelID ORDER BY datetime\n",
    "    USING MODE (NONOVERLAPPING)\n",
    "    Pattern ('^Dep.Other*.Arr$')\n",
    "    Symbols (\n",
    "        events='departure' AS Dep,\n",
    "        events='arrival' AS Arr,\n",
    "        events not in ('departure','arrival') as Other\n",
    "            )\n",
    "    Result (accumulate(cast(events as VARCHAR(50) CHARACTER SET UNICODE NOT CASESPECIFIC) OF ANY(Other)) AS travel,\n",
    "            first(datetime of Dep) AS departure_time,\n",
    "            last(datetime of Arr) As arrival_time,\n",
    "            first(TravelID of ANY(Dep,Arr)) as TravelID)\n",
    ") as dt\n",
    ") A;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b6567-9ce4-467e-ae9e-81938632912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute(myquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a1db3-c9bb-4719-a44f-eea1c230796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mydata = DataFrame(in_schema(\"demo_user\",\"usecase_dataset\"))\n",
    "df_mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21b6c2-53a7-4791-8a25-709787eca7d0",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Model development : prepare the data for the Machine Learning Algorithm</b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "The dataset built in Teradata contains all the information to address the business question. However, the Data Scientist will define how to expose these data to a machine learning algorithm to get the insights he is looking for.<br>\n",
    "In this example, the strategy proposed by the data scientist consists of spliting the paths and count frequency of each event in it.\n",
    "<center><img src=\"images/model_strategy.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd01d81-e34a-4047-8bd0-c87933aa31f9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We use the <i>NGramSplitter</i> function to process the paths of each travel. The function will split the corpus of texts into \"terms\" (grams) of selected size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3316c-4440-4194-8f20-b6bec8df2074",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = NGramSplitter(data=df_mydata,\n",
    "                          text_column='travel',\n",
    "                          delimiter = \",\",\n",
    "                          grams = \"1\",\n",
    "                          overlapping=False,\n",
    "                          to_lower_case=True,\n",
    "                          total_gram_count=True,\n",
    "                          punctuation = \"[\\\\]\\\\\\\\[\\\\`]\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e01e4f-b64d-4f71-ba5e-af82c74d353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406bda19-39fb-4999-ae00-407567a8162b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The NGRAMS function add new columns (and rows). We will use two of them:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li> ngram : is the event found in the travel</li>\n",
    "    <li> frequency : is the frequency of this event in the path</li>\n",
    " </ul>   \n",
    "<p style = 'font-size:16px;font-family:Arial'>We need to get the number of possible ngrams: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02abce5-bbc0-4831-bab4-ac0a9134d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = (ngrams.result).select(['ngram','frequency']).groupby(['ngram']).sum().to_pandas()\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d80cf-2061-4972-b669-960211478e51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can visualize again the distribution of events in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6829541-8469-4492-ba73-ebcc92d327b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "keys.sort_values('sum_frequency',ascending=True).plot.barh(x='ngram',figsize=(10,5),fontsize=20,legend=False)\n",
    "plt.ylabel('events',fontsize=20)\n",
    "plt.xlabel('frequency',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93171c-eb3d-4b38-a4f0-d209a684d58f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In order to make the dataset ready for the Machine Learning algorithm, we need to pivot the data and fill missing values with 0.<br>\n",
    "For this purpose, we use two functions:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "  <li>Pivot, to pivot the data and generate as many columns as event type. When an event does not occur during the travel, pivot assign its frequency to NULL or NaN</li>\n",
    "    <li>assign, is used here to fill the missing values using the *isnan* function</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9569b56-16bb-449a-ad30-706ad8ee535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram = ngrams.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8160f8-e18f-430c-8272-50c138658042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1c607-437c-4a1c-bd22-f77a237990f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3713ff-43c9-4ca5-9063-c05e9215262b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><i>* below command is pivoting the data and takes approx 1min 30sec to execute </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea37fb-cc46-4806-a6e7-0e9de79dfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pivot = df_ngram.pivot(columns=df_ngram.ngram, aggfuncs=df_ngram.frequency.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3f999-f87a-4f09-9a91-d9f47fee7198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pivot.assign(drop_columns                 = True,\n",
    "           travelid                              = pivot.TravelID,\n",
    "           travel                                = pivot.travel,\n",
    "           travel_duration_sec                   = pivot.travel_duration_sec, \n",
    "           frequency_abnormal_weather_condition  = pivot['sum_frequency_abnormalweathercondition']  if not pivot['sum_frequency_abnormalweathercondition'].isna() else (1.-pivot['sum_frequency_abnormalweathercondition'].isna()),\n",
    "           frequency_accident_involving_person   = pivot['sum_frequency_accidentinvolvingperson']  if not pivot['sum_frequency_accidentinvolvingperson'].isna() else (1.-pivot['sum_frequency_accidentinvolvingperson'].isna()),\n",
    "           frequency_body_on_track               = pivot['sum_frequency_bodyontrack']  if not pivot['sum_frequency_bodyontrack'].isna() else (1.-pivot['sum_frequency_bodyontrack'].isna()),          \n",
    "           frequency_crowded_stop                = pivot['sum_frequency_crowdedstop']  if not pivot['sum_frequency_crowdedstop'].isna() else (1.-pivot['sum_frequency_crowdedstop'].isna()),\n",
    "           frequency_door_failure                = pivot['sum_frequency_doorfailure']  if not pivot['sum_frequency_doorfailure'].isna() else (1.-pivot['sum_frequency_doorfailure'].isna()),          \n",
    "           frequency_door_light_failure          = pivot['sum_frequency_doorlightfailure']  if not pivot['sum_frequency_doorlightfailure'].isna() else (1.-pivot['sum_frequency_doorlightfailure'].isna()),\n",
    "           frequency_electrical_failure          = pivot['sum_frequency_electricalfailure']  if not pivot['sum_frequency_electricalfailure'].isna() else (1.-pivot['sum_frequency_electricalfailure'].isna()),          \n",
    "           frequency_engine_failure              = pivot['sum_frequency_electricalfailure']  if not pivot['sum_frequency_electricalfailure'].isna() else (1.-pivot['sum_frequency_electricalfailure'].isna()),\n",
    "           frequency_normal_stop                 = pivot['sum_frequency_normalstop']  if not pivot['sum_frequency_normalstop'].isna() else (1.-pivot['sum_frequency_normalstop'].isna()),          \n",
    "           frequency_road_work                   = pivot['sum_frequency_roadwork'] if not pivot['sum_frequency_roadwork'].isna() else (1.-pivot['sum_frequency_roadwork'].isna()),\n",
    "           frequency_stop_sign_failure           = pivot['sum_frequency_stopsignfailure'] if not pivot['sum_frequency_stopsignfailure'].isna() else (1.-pivot['sum_frequency_stopsignfailure'].isna()),          \n",
    "           frequency_unexpected_stop             = pivot['sum_frequency_unexpectedstop'] if not pivot['sum_frequency_unexpectedstop'].isna() else (1.-pivot['sum_frequency_unexpectedstop'].isna())\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a3d61-fe0c-4d5a-ad22-cd3e9a442290",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Here we decide to create a table with the dataset in order to test different machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587da21-06f5-43a7-9856-00788a09752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(dataset,table_name='my_dataset',schema_name= 'demo_user',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097fa86-94a2-4725-af2e-54d5ef6b606b",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Model development : apply Machine Learning Algorithm</b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "In our case, using a Generalized Linear Model answers the following business questions:\n",
    "<ul style = 'font-size:16px;font-family:Arial'>   \n",
    "    <li>what is the travel duration when no event occur ? (even if this travel does not exist) => the answer is the intercept</li>\n",
    "    <li>what is the delay induced by each event type ? (under the assumption there is no interaction between events) => the answers are the coefficients of the model</li>\n",
    "    <li>can I simulate a new scenario ? => this is addressed by the scoring on new data. By the way, it can be done with any Machine Learning trained model</li>\n",
    " </ul>   \n",
    "<center><img src=\"images/GLM.png\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a6e6a-c94a-47b6-b204-b07910fab55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num = DataFrame(in_schema('demo_user','my_dataset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698774e-4214-487f-97f1-889ef0f383a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1baa04-38d5-4fff-a7f8-aae8ab003923",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num.loc[:,['travelid','travel_duration_sec']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac8553-9506-4a74-9e1c-6de9e9432077",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let's make a train/test split using the *travelid*:\n",
    "    <ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>training set : *travelid < 5479* with 75% of the data (5028 rows)</li>   \n",
    "    <li>testing set  : *travelid > 5478* with 25% of the data (1676 rows)</li> \n",
    "</ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We assume that all the events are present in both datasets, although it has to be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee7305-0427-4e35-83dd-a149a369884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = dataset_num.loc[dataset_num.travelid < 5479,:]\n",
    "dataset_testing  = dataset_num.loc[dataset_num.travelid > 5478,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797414b4-be02-4605-ac4f-5f5d02e23556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b66a95-fa18-4531-aaca-5a6022cb9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_testing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbabec7-83ae-4b27-b7c4-bf2bc879900e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We want to predict the travel_duration_sec using the frequencies of all events: we define the formula accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ac96e-722d-42ef-b862-8ae91973587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'travel_duration_sec ~ '+' + '.join(dataset_num.columns[3:-1])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abc173-b811-4e2c-ab05-b26fda20a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import GLM, TDGLMPredict\n",
    "glm_out = GLM(     formula      = formula,\n",
    "                   linkfunction = 'IDENTITY',\n",
    "                   family       = \"GAUSSIAN\",\n",
    "                   data         = dataset_training,\n",
    "                   threshold    = 0.001,\n",
    "                   iter_max=300,\n",
    "                   tolerance=0.001,\n",
    "                   momentum=0.1,\n",
    "                   nesterov=True,\n",
    "                   learning_rate='CONSTANT'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286e377-9879-4280-bc86-532abf7dee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_out.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac8494-828c-4dba-9848-2333ba6ef5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefficients = glm_out.result.to_pandas().reset_index()\n",
    "feat_imp = model_coefficients[model_coefficients['attribute'] > 0].sort_values(by = 'estimate', ascending = False)\n",
    "\n",
    "# Specify figure size\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Use ax.barh() for horizontal bar chart\n",
    "ax.barh(feat_imp['predictor'], feat_imp['estimate'], edgecolor='red')\n",
    "\n",
    "# Add text labels on right of the bars\n",
    "for x, y in zip(feat_imp['estimate'], feat_imp['predictor']):\n",
    "    ax.text(x, y, str(round(x, 2)), ha='left', va='center')\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_xlabel('Estimate')\n",
    "\n",
    "plt.title('Feature importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce82f97-1888-40e6-a742-056dec0696b3",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The figure above displays feature importance which are significant factors in predicting the target variable which in our case is travel_duration_sec. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129f1e6-79cc-4de3-8636-9b47a8016c81",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Model Performances</b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The model accuracy is tested on the testing dataset (dataset_testing) using the GLMPredict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea3ed0-a2e3-45de-9d3e-24cf80534f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = TDGLMPredict(object=glm_out.result,\n",
    "                                        newdata=dataset_testing,\n",
    "                                        accumulate=\"travel_duration_sec\",\n",
    "                                        id_column=\"travelid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc11b57-f4ba-4e90-a2c4-3b9fe81da2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65969d5a-f0bd-4632-b330-f46ab02b8efb",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The TD_RegressionEvaluator function computes metrics to evaluate and compare multiple models and summarizes how close predictions are to their expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe8493-468e-459c-be31-c999887cea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import RegressionEvaluator\n",
    "RegressionEvaluator_out = RegressionEvaluator(data = predictions.result,\n",
    "                                                      observation_column = \"travel_duration_sec\",\n",
    "                                                      prediction_column = \"prediction\",\n",
    "                                                      freedom_degrees = [1, 2],\n",
    "                                                      metrics = ['RMSE','R2','FSTAT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee49321-ec08-4164-aaad-35229ba7d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegressionEvaluator_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9cc6b-b5de-4fac-8945-c02d9909fe91",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The Metrics of the regression evaluator has the RMSE, R2 and the F-STAT metrics which are specified in the Metrics.<br>The Regression evaluator is used to evaluate and compare the models. </p>  \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Root mean squared error (RMSE)The most common metric for evaluating linear regression model performance is called root mean squared error, or RMSE. The basic idea is to measure how bad/erroneous the model’s predictions are when compared to actual observed values. So a high RMSE is “bad” and a low RMSE is “good”.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The coefficient of determination — more commonly known as R² — allows us to measure the strength of the relationship between the response and predictor variables in the model. It’s just the square of the correlation coefficient R, so its values are in the range 0.0–1.0. Higher values of R- Squared is Good.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'> F-statistics (FSTAT) conducts an F-test. An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis.\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>F_score = F_score value from the F-test.</li>\n",
    "<li>F_Critcialvalue = F critical value from the F-test.</li>\n",
    "<li>p_value = Probability value associated with the F_score value.</li>\n",
    "<li>F_conclusion = F-test result, either 'reject null hypothesis' or 'fail to reject null hypothesis'. If F_score > F_Critcialvalue, then 'reject null hypothesis' Else 'fail to reject null hypothesis'</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5cf71-6fa0-4186-883b-4f072a9e7c6a",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Conclusion</b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this notebook we have seen the end-to-end model creation using the The Teradata Vantage In-Database functions. We built a basic model and you can experiment by adjusting the model parameters to observe their impact on predictions and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fb989-e14d-48f5-9b34-08f9d77c904f",
   "metadata": {},
   "source": [
    "<h1 style = 'font-size:28px;font-family:Arial;color:#E37C4D'><b>Cleanup</b></h1>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;'>\n",
    "Cleanup work tables to prevent errors next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d33736-d96a-448b-86c5-5dcfd693d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE my_dataset;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee29562-7d27-48bc-8614-c9bd15b7dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP VIEW usecase_dataset;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa7b9b-5eb6-4357-a86c-327c0ea3f397",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0f759-a8ce-4c0a-a8b2-f972070ed90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_TrainDelay');\" \n",
    "#Takes 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081d7f0-1fc6-4200-b3cb-36c0941b88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a0ee8-4615-4c24-846d-11f7703c89f7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Reference Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'> \n",
    "       <li>Teradata Vantage™ - Analytics Database Analytic Functions - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions '>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Introduction-to-Analytics-Database-Analytic-Functions </a></li>    \n",
    "  <li>Teradata® Package for Python User Guide - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python'>https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-Package-for-Python-User-Guide-17.20/Introduction-to-Teradata-Package-for-Python</a></li>\n",
    "  <li>Teradata® Package for Python Function Reference - 17.20: <a href = 'https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference'>https://docs.teradata.com/r/Enterprise/Teradata-Package-for-Python-Function-Reference-17.20/Teradata-Package-for-Python-Function-Reference</a></li>      \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd057557-2dea-4247-8848-0f29c01d304c",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">©2023 Teradata. All Rights Reserved</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
