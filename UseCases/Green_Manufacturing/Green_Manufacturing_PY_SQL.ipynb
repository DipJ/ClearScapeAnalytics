{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb0e42b-1d06-4ae0-91ec-e06fd55d6d3d",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Green Manufacturing for vehicles\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Since the first automobile, the Real Wheel Motor Company has stood for important automotive innovations. These include, for example, the passenger safety cell with crumple zone, the airbag and intelligent assistance systems. Real Wheel Motor Company applies for nearly 2000 patents per year, making the brand the European leader among premium car makers. These cars are leaders in the premium car industry. With a huge selection of features and options, customers can choose the customized models of their dreams.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To ensure the safety and reliability of each and every unique car configuration before they hit the road, the engineers have developed a robust testing system. But, optimizing the speed of their testing system for so many possible feature combinations is complex and time-consuming without a powerful algorithmic approach. As one of the world’s biggest manufacturers of premium cars, safety and efficiency are paramount on their production lines.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The goal is to work with a dataset representing different permutations of Real Wheel Motor Company car features to predict the time it takes to pass testing. This will contribute to speedier testing, resulting in lower carbon dioxide emissions without reducing the standards of the company cars.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This dataset contains an anonymized set of variables, each representing a custom feature in a car. For example, a variable could be 4WD, added air suspension, or a head-up display. The ground truth is labelled ‘y’ and represents the time (in seconds) that the car took to pass testing for each variable.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c9b40-011f-4903-a3ce-3621f83470f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1. Connect to Vantage</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6694c3-bc4b-4ff5-9960-8d564783e888",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f0705-e1cd-4089-8823-c15404f1445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# # '%%capture' suppresses the display of installation steps of the following packages\n",
    "# !pip install xgboost==1.7.3\n",
    "# !pip install colorlover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e76b4-c312-4281-a52e-d5eb91674e09",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a393e50b-2226-436e-8dee-4a320a84aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import json\n",
    "import getpass\n",
    "import pandas as pd\n",
    "\n",
    "from teradataml.dataframe.dataframe import DataFrame\n",
    "from teradataml import *\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "color = sns.color_palette()\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from collections import defaultdict\n",
    "import plotly.offline as offline\n",
    "import colorlover as cl\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "display.max_rows=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f03f1-65de-4a7b-b5bc-87efaed7f11d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f417e8-a4ea-4ce1-bced-6142a250d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459cd2a-d152-46a9-b2cd-7746febe992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Green_Manufacturing_PY_SQL.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746e656-3028-4abd-9278-af179bdd2963",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage.  You have the option of either running the demo using foreign tables to access the data without using any storage on your environment or downloading the data to local storage which may yield somewhat faster execution, but there could be considerations of available storage.  There are two statements in the following cell, and one is commented out.  You may switch which mode you choose by changing the comment string.</p>    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>** Note : Due to the large number of columns the initial table creation and data loading make take more time.</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f88a3-c62c-45e5-a083-81f1931df590",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call get_data('DEMO_GreenManufacturing_cloud');\"\n",
    " # Takes about 50 seconds\n",
    "# %run -i ../run_procedure.py \"call get_data('DEMO_GreenManufacturing_local');\"\n",
    " # Takes about 3 minutes 30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4122e51-c891-4c48-bec9-4f364e178f46",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next is an optional step – if you want to see status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a295649-45ea-4cb1-ace9-ecc1c1f8cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3479e16-ac99-48ba-9aec-6d5eda6c4d96",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Analyze the raw data set</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create a DataFrame to get the data from the table created.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b><i>** Note : There may be a warning message due to a large number of columns in the dataframe. It's a Warning and not an error. Please ignore the warning</i></b></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfab48-052f-4d10-9547-47e321ac2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = DataFrame(in_schema('DEMO_GreenManufacturing', 'Manufacturing_Data'))\n",
    "datadf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b4a74-0383-41fa-a884-00fd703c193c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ID column is the ID of the cars, 'y' is the time in seconds which the car took to pass testing for each variable. The variables X0-X8 are categorical variables and the remaining are numerical variables having values of 0 and 1. These are the variables which impact the value of 'y'.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac4d49-3b81-421b-8b7d-a9a7d3c5f553",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Check the impact of Categorical variables on target variable 'y'</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create a DataFrame to get the data from the table created.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d8382-ad00-49c2-a52c-c37501a8f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=datadf.to_pandas().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1de150-7f1b-4958-b23e-7fa109fa2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X0\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "# sns.stripplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "sns.countplot(x=var_name, data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab88ef-9a91-4d4d-8d47-fb4494861621",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X1\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.stripplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da1621-cc48-4885-92d6-32d3f7a9c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X2\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abadca04-df20-47e2-9f3c-8ee7f20429b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X3\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddc45c-d32f-44b7-aac4-b82817fc4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X4\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7868ab3-06f2-4f32-99b1-5355341b4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X5\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f019de-1bb0-4095-90b3-b875741be1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X6\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac4a66-bee1-4b1c-8146-6cf2447c66df",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "var_name = \"X8\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b69f2-d98e-4a87-8012-5166f72b9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_name = \"ID\"\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.regplot(x=var_name, y='y', data=train_df, scatter_kws={'alpha':0.5, 's':30})\n",
    "# sns.barplot(x=var_name, y='y', data=train_df)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11993c-bad6-4f3f-956a-d46bd70a02e4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>After the initial analysis done on the variables and the value of y based on these variables, let's go ahead and try to predict the value of Y using these variables. Below are some steps that should be done before using any prediction model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a9ed0-0571-451e-a095-271f8bc14bf0",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5. Check the importance of various features on target variable 'y'</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We are using the python xgboost model to check the feature importance.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631e179-e487-44c2-a2e5-a03897fc8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "for f in [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f].values)) \n",
    "        train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "        \n",
    "train_y = train_df['y'].values\n",
    "train_X = train_df.drop([\"ID\", \"y\"], axis=1)\n",
    "\n",
    "\n",
    "def xgb_r2_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'r2', r2_score(labels, preds)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1\n",
    "}\n",
    "dtrain = xgb.DMatrix(train_X, train_y, feature_names=train_X.columns.values)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100, feval=xgb_r2_score, maximize=True)\n",
    "\n",
    "# plot the important features #\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b2900-451f-4bf7-96ef-9079c2d49095",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>6. OrdinalEncoding of the categorical variables</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Machine learning models require all input and output variables to be numeric.\n",
    "This means that if your data contains categorical data, you must encode it to numbers before you can fit and evaluate a model.\n",
    "The two most popular techniques are an Ordinal Encoding and a One-Hot Encoding.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Ordinal encoding, which turns each label into an integer value and depicts the sequence of labels in the encoded data, is employed when the variables in the data are ordinal. Ordinal encoding converts each label into integer values and the encoded data represents the sequence of labels.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Since the variables X0-X8 are categorical, we will need to convert them into numerical to use them in different models. We are using the OrdinalEncoding for this conversion. The <b>TD_OrdinalEncodingFit</b> function identifies distinct categorical values from the input table or a user defined list and returns the distinct categorical values along with the ordinal value for each category.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Ordinal encoding will be done for both the Train and Test Datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576758c-c5d9-4116-b284-0374e5311116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoding for Dataset\n",
    "query = '''Select * from TD_OrdinalEncodingFit (ON \n",
    "DEMO_GreenManufacturing.Manufacturing_Data AS INPUTTABLE\n",
    "OUT table outputtable(Ordinal_fit_output)\n",
    "USING TargetColumn('X0','X1','X2','X3','X4','X5','X6','X8')) as dt;\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('Ordinal_fit_output')\n",
    "    execute_sql(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cb130-a672-4225-9878-4134af5105e7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Ordinal encoding transform is used on the ordinal encoding fit data to get the numerical values for the categorical values.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The <b>TD_OrdinalEncodingTransform</b> function maps the categorical value to a specified ordinal value using the TD_OrdinalEncodingFit output.</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb30881-5486-496e-8da4-bfb7d2b8e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Transform for Dataset\n",
    "query = '''Create multiset table Ordinal_transform_output as  (SELECT * FROM TD_OrdinalEncodingTransform (\n",
    "ON DEMO_GreenManufacturing.Manufacturing_Data  AS InputTable\n",
    "ON Ordinal_fit_output AS FitTable DIMENSION\n",
    "USING\n",
    "Accumulate ('id','y')\n",
    ") as dt) with data primary index(\"ID\");\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('Ordinal_transform_output')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accdaec-dd2e-4419-bdfa-71d7654338c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=DataFrame.from_query('SELECT * FROM Ordinal_transform_output;')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63539398-6d2d-4a04-b279-8f024bc4d407",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Preparation of Data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the below steps we are preparing the data by joining the converted categorical features and some other important features to be used in Model Training, Scoring and Evaluation</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We join the converted dataframe and the important numerical features to get the final dataset which will be used for the model.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Get the output of OrdinalTransform into dataframe.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe79f2-a52e-4d74-a4f7-5365f09187db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OrdTransdf = DataFrame('Ordinal_transform_output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e700ab-f096-4044-b68d-171daa1112ea",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We join the converted dataframe and the original data to get important numerical features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c362d-95fa-444f-8688-4fe91e8ccad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "datadf=datadf.drop(columns=[\"X0\", \"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"X8\"])\n",
    "datadf_join = OrdTransdf.join(other = datadf, on = [\"ID\"], how = \"left\",lprefix='t1',rprefix='t2')\n",
    "datadf_join=datadf_join.drop(columns=[\"t2_ID\", \"t2_y\"])\n",
    "datadf_join = datadf_join.assign(ID=datadf_join.t1_ID, y=datadf_join.t1_y)\n",
    "datadf_join = datadf_join.drop(columns=[\"t1_ID\", \"t1_y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658c178-ae52-4e75-874e-a4dbc0d97ed8",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create a final dataframe with only the required important features along with the ID and the response column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a6431-c94a-477a-8a9e-5cb191c2e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_df = datadf_join[[\"ID\",\n",
    "\"y\",\n",
    "\"X0\",\n",
    "\"X1\",\n",
    "\"X2\",\n",
    "\"X3\",\n",
    "\"X4\",\n",
    "\"X5\",                          \n",
    "\"X6\",\n",
    "\"X8\",\n",
    "\"X47\",\n",
    "\"X314\",\n",
    "\"X118\",\n",
    "\"X315\",\n",
    "\"X127\",\n",
    "\"X29\",\n",
    "\"X115\",\n",
    "\"X351\",                           \n",
    "\"X151\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3e40a-03f7-4c1c-8010-d11e81c814c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df = data_new_df, table_name = 'final_data',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a1d49-a066-41d9-bbc0-af0e4c05e468",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We split the data into Train and Test data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4a4d6-5da8-41d0-8cb5-a04e28346d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''Create multiset table TTS_output as (\n",
    "SELECT * FROM TD_TrainTestSplit(\n",
    "ON final_data AS InputTable\n",
    "USING\n",
    "IDColumn('Id')\n",
    "Seed(42)\n",
    ")AS dt\n",
    ") with data;\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('TTS_output')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d2fb6-77cc-4a07-b55d-a3c0fcbf2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''Create multiset table final_train_data as (\n",
    "SELECT * FROM TTS_OUTPUT WHERE TD_IsTrainRow = 1\n",
    ") with data;\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('final_train_data')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c9c73-bd90-4e23-8943-6efc595f5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''Create multiset table final_test_data as (\n",
    "SELECT * FROM TTS_OUTPUT WHERE TD_IsTrainRow = 0\n",
    ") with data;\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('final_test_data')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6bd1c-7847-42eb-a5ea-760baab0bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_df=DataFrame(in_schema('demo_user', 'final_train_data'),index=True,index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845219a-b7c0-4b14-9b33-53788eb47dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_df=DataFrame(in_schema('demo_user', 'final_test_data'),index=True,index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c85b2db-cee0-498f-b73e-4c1c6c51e14b",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>8. Decision Forest </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Decision Forest is a powerful method used for predicting outcomes in both classification and regression problems. It's an improvement on the technique of combining (or \"bagging\") multiple decision trees. Normally, building a decision tree involves assessing the importance of each feature in the data to determine how to divide the information. This method takes a unique approach by only considering a random subset of features at each division point in the tree. This forces each decision tree within the \"forest\" to be different from one another, which ultimately improves the accuracy of the predictions. The function relies on a training dataset to develop a prediction model. Then, the TD_DecisionForestPredict function uses the model built by the TD_DecisionForest function to make predictions. It supports regression, binary, and multi-class classification tasks.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Typically, constructing a decision tree involves evaluating the value for each input feature in the data to select a split point. The function reduces the features to a random subset (that can be considered at each split point); the algorithm can force each decision tree in the forest to be very different to improve prediction accuracy. The function uses a training dataset to create a predictive model. The TD_DecisionForestPredict function uses the model created by the TD_DecisionForest function for making predictions. The function supports regression, binary, and multi-class classification.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Consider the following points:\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>All input features are numeric. Convert the categorical columns to numerical columns as preprocessing step.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>For classification, class labels (ResponseColumn values) can only be integers. A maximum of 500 classes is supported for classification.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Observations with missing values in any input column will be ignored during training. To fill in missing values, use the TD_SimpleImpute function.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>The number of trees built by the TD_DecisionForest function depends on the values of NumTrees, TreeSize, and CoverageFactor, as well as the data distribution in the cluster. The trees are built simultaneously by all the processing units (AMPs) that have a non-empty portion of the data.</li>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ce758-9cad-4f9b-9bba-d6652e0ad02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''Create multiset table DF_train as (\n",
    "SELECT * FROM TD_DecisionForest (\n",
    "ON final_train_data AS INPUTTABLE partition by ANY\n",
    "USING\n",
    "  ResponseColumn('y')\n",
    "InputColumns('id','X0','X1','X2','X3','X4','X5','X6','X8','X47','X314','X118','X315','X127','X29','X115','X351','X151')\n",
    "MaxDepth(12)\n",
    "MinNodeSize(1)\n",
    "NumTrees(4)\n",
    "ModelType('REGRESSION')\n",
    "Seed(1)\n",
    "Mtry(-1)\n",
    "MtrySeed(1)\n",
    ") AS dt\n",
    ") with data;\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('DF_train')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa33acf-f428-4dc5-be09-0271feeabd07",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>TD_DecisionForestPredict function uses the model output by TD_DecisionForest function to analyze the input data and make predictions. This function outputs the probability that each observation is in the predicted class. Processing times are controlled by the number of trees in the model. When the number of trees is more than what can fit in memory, then the trees are cached in a local spool space.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89318ef-2efa-4c81-a59f-4e26d3dbf8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "Create multiset table DF_Predict as (\n",
    "SELECT * FROM TD_DecisionForestPredict (\n",
    "ON final_test_data AS InputTable PARTITION BY ANY\n",
    "ON DF_Train AS ModelTable DIMENSION\n",
    "USING\n",
    "  IdColumn ('id')\n",
    "  Detailed('false')\n",
    "  Accumulate('y')\n",
    ") AS dt) with data;'''\n",
    "\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('DF_Predict')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb08ff0-a623-466d-92e8-dd16f4074644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = DataFrame(in_schema('demo_user', 'DF_Predict'))\n",
    "df_result_pd=df_result.to_pandas().reset_index().sort_values(\"ID\")\n",
    "df_result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4d4a6-bcb9-44d8-8030-6654a102a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.ylabel('Time in Test Cycle', fontsize = 14)\n",
    "plt.xlabel('Vehicle ID', fontsize = 14)\n",
    "plt.plot(df_result_pd['ID'][:50], df_result_pd['y'][:50], color='g', label='Actual Value')\n",
    "plt.plot(df_result_pd['ID'][:50], df_result_pd['prediction'][:50], color='r', label='Predicted Value')\n",
    "plt.title('Actual vs Predicted using DecisionForest Classification', fontsize = 18)\n",
    "plt.legend()\n",
    "# plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33acc4e-ff45-4d03-836a-34504c97ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT * FROM TD_RegressionEvaluator(\n",
    "ON DF_Predict as InputTable\n",
    "USING\n",
    "ObservationColumn('y')\n",
    "PredictionColumn('prediction')\n",
    "Metrics('MAE','MSE','RMSE','R2','FSTAT')\n",
    "DegreesOfFreedom(5,28)\n",
    "NUMOFINDEPENDENTVARIABLES(15)\n",
    ") as dt;\n",
    "'''\n",
    "\n",
    "DF_eval=DataFrame.from_query(query)\n",
    "DF_eval=DF_eval.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc30c09-54ae-47cb-bda3-4543c8b9fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_eval['model']='DecisionForest'\n",
    "DF_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccbeeba-dc33-4106-a5f9-4ea6fe4fef3c",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>9. XGBoost </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The TD_XGBoost function, also known as eXtreme Gradient Boosting, is an implementation of the gradient boosted decision tree designed for speed and performance. It has recently been dominating applied machine learning.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In gradient boosting, each iteration fits a model to the residuals (errors) of the previous iteration to correct the errors made by existing models. The predicted residual is multiplied by this learning rate and then added to the previous prediction. Models are added sequentially until no further improvements can be made. It is called gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Gradient boosting involves three elements:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>A loss function to be optimized.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>A weak learner to make predictions.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>An additive model to add weak learners to minimize the loss function.</li></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The loss function used depends on the type of problem being solved. For example, regression may use a squared error and binary classification may use binomial. A benefit of the gradient boosting is that a new boosting algorithm does not have to be derived for each loss function. Instead, it provides a generic enough framework that any differentiable loss function can be used. The TD_XGBoost function supports both regression and classification predictive modelling problems. The model that it creates is used in the TD_XGBoostPredict function for making predictions. </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49719257-07af-4bd4-9ea8-c9709b8e9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''create multiset table xgb_model as (\n",
    "SELECT * FROM TD_XGBoost (\n",
    "ON final_train_data partition by ANY\n",
    "OUT TABLE MetaInformationTable(xgb_out) \n",
    "USING\n",
    "ResponseColumn('y')\n",
    " InputColumns('id','X0','X1','X2','X3','X4','X5','X6','X8','X47','X314','X118','X315','X127','X29','X115','X351')---,'X151')\n",
    " MaxDepth(8)\n",
    " MinNodeSize(1)\n",
    " NumBoostedTrees(24)\n",
    " ModelType('REGRESSION')\n",
    " Seed(1) \n",
    " RegularizationLambda(1000)\n",
    " ShrinkageFactor(0.7)\n",
    " IterNum(4)\n",
    " ColumnSampling(1.0) \n",
    ") as dt) with data;\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('xgb_model')\n",
    "    db_drop_table('xgb_out')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed05487-d2f5-428e-8c15-48824ecf8e8f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>TD_XGBoostPredict performs prediction for test input data using multiple simple trees in the trained model. The test input data should have the same attributes as used during the training phase, which can be up to 2048. These attributes are used to score based on the trees in the model.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The output contains prediction for each data point in the test data based on regression or classification. The prediction probability is computed based on the majority vote from participating trees. A higher probability implies a more confident prediction by the model. Majority of the trees result in the same prediction.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d15f04-7250-46d1-9b27-4a5c90efa8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''create multiset table xgb_predict_out as (\n",
    "SELECT * FROM TD_XGBoostPredict(\n",
    "ON final_test_data as inputtable partition by ANY\n",
    "ON xgb_model as modeltable dimension ORDER BY task_index, tree_num, iter, tree_order\n",
    "\n",
    "USING\n",
    " IdColumn('id')\n",
    " ModelType('regression')\n",
    " accumulate('y')\n",
    " ) as dt) with data;\n",
    "'''\n",
    "try:\n",
    "    execute_sql(query)\n",
    "except:\n",
    "    db_drop_table('xgb_predict_out')\n",
    "    execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6c930-8b40-4ba4-bdcb-24997e92637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_result = DataFrame('xgb_predict_out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed69b1d-4fd5-4232-b1c3-6eaf87108093",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_result_pd=xgb_result.to_pandas().reset_index().sort_values(\"ID\")\n",
    "xgb_result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15eaa21-417b-440a-9979-f6712a9a0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.ylabel('Time in Test Cycle', fontsize = 14)\n",
    "plt.xlabel('Vehicle ID', fontsize = 14)\n",
    "plt.plot(xgb_result_pd['ID'][:50], xgb_result_pd['y'][:50], color='g', label='Actual Value')\n",
    "plt.plot(xgb_result_pd['ID'][:50], xgb_result_pd['Prediction'][:50], color='r', label='Predicted Value')\n",
    "plt.title('Actual vs Predicted using XGBoost Classification', fontsize = 18)\n",
    "plt.legend()\n",
    "# plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7111094-83b6-4ec7-8e72-5f9c6164b978",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The TD_RegressionEvaluator function computes metrics to evaluate and compare multiple models and summarizes how close predictions are to their expected values.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b><i>Note:</b> Since we have sample data here the predicted values do not seem to be very near to the actual values. In scenarios with real data the parameters can be tweaked to get better predicted values.</i></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9ed48-cbf8-47f0-8da9-ce2694ff84ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT * FROM TD_RegressionEvaluator(\n",
    "ON xgb_predict_out as InputTable\n",
    "USING\n",
    "ObservationColumn('confidence_lower')\n",
    "PredictionColumn('prediction')\n",
    "Metrics('MAE','MSE','RMSE','R2','FSTAT')\n",
    "DegreesOfFreedom(5,48)\n",
    "NUMOFINDEPENDENTVARIABLES(5)\n",
    ") as dt;\n",
    "'''\n",
    "\n",
    "XGB_Eval=DataFrame.from_query(query)\n",
    "XGB_Eval=XGB_Eval.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c9091-0d5b-4089-b911-c69009079bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Eval['model']='XGBoost'\n",
    "XGB_Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c2531-e3cd-46a5-9769-be64a2fd24d7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Metrics of the regression evaluator has the RMSE, R2 and the F-STAT metrics which are specified in the Metrics.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Thus, here we have used 2 different models to train and predict the data. The Regression evaluator is used to evaluate and compare the models. The Teradata In-Database functions are used for training, prediction and evaluation. In this case since we have sample data the result parameters may not be accurate for these models.</p>  \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Root mean squared error (RMSE)The most common metric for evaluating linear regression model performance is called root mean squared error, or RMSE. The basic idea is to measure how bad/erroneous the model’s predictions are when compared to actual observed values. So, a high RMSE is “bad” and a low RMSE is “good”.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The coefficient of determination — more commonly known as R² — allows us to measure the strength of the relationship between the response and predictor variables in the model. It’s just the square of the correlation coefficient R, so its values are in the range 0.0–1.0. Higher values of R- Squared is Good.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The metrics specified in the Metrics syntax element are displayed. For FSTAT, the following columns are displayed:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>F_score</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>F_Critcialvalue</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>p_value</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>F_Conclusion.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here we can see the comparison for MAE,MSE,RMSE and R2 for XGBoost and DecisionForest.</p> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed4237-8bc6-4e17-859f-7ae13bf91621",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[DF_eval,XGB_Eval]\n",
    "result = pd.concat(frames)\n",
    "result = result.set_index([['Decision Forest','XGBoost']])\n",
    "result = result.drop(['model'],axis=1)\n",
    "transposed_df_eval = result.transpose()\n",
    "# transposed_df_eval.reset_index()\n",
    "transposed_df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151e525-82e7-466b-b9f2-7773119fe38d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>10. Cleanup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Work Tables</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7416a835-394d-4ed2-bc3a-48f060e74cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['Ordinal_fit_output', 'Ordinal_transform_output','TTS_output','final_train_data','final_test_data','DF_train','DF_Predict',\n",
    "          'xgb_model','xgb_out','xgb_predict_out']\n",
    "\n",
    "# Loop through the list of tables and execute the drop table command for each table\n",
    "for table in tables:\n",
    "    try:\n",
    "        db_drop_table(table_name = table)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace406bb-4354-4611-8204-cff8275c911f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74588dc-5691-4e0e-a545-5389f776e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_GreenManufacturing');\" \n",
    "#Takes 40 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42baee5d-de56-43ec-a6f0-3fdbac49de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b404312-6af8-4d9a-b238-42636c0fe5f0",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
