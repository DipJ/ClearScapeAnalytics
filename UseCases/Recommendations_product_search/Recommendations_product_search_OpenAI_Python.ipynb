{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Recommendations during a product search using Generative AI with Vantage</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The combination of <b>OpenAIEmbeddings</b> and <b>Vantage in the db_function</b> assists consumers in receiving product recommendations while looking for items on the website in the recommendations system using generative AI demo.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo, we will build a product recommendation system using OpenAI embeddings and <b>Vantage in the db_function VectorDistance</b>. Recommendation systems are a type of information filtering system that seeks to predict the rating or preference that a user would give to an item. They are often used on e-commerce websites to recommend products to users based on their past purchase history, browsing behaviour, and other factors. In this demo, we use product-to-product recommendations based on embedding distances. The VectorDistance function will return the closest products from the databases as a recommendations.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following diagram illustrates the architecture.</p>\n",
    "\n",
    "<center><img src=\"images/openai_emb3.png\" alt=\"Product_search_architecture\"  width=800 height=800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e54d47-af28-412e-b27d-c2dae812ea11",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Before going any farther, let's get a better understanding of Cosine similarity(distance measure method) and Embeddings</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b89e1d8-35fc-44de-8783-aa762d996a7b",
   "metadata": {},
   "source": [
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>Cosine similarity:</b></li></ul>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp; In natural language processing (NLP), a vector is a way of representing a word or phrase as a set of numbers. These numbers represent the meaning of the word or phrase in a way that can be understood by computers.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cosine distance is a way of <b>measuring the similarity between two vectors</b>. It works by calculating the cosine of the angle between the two vectors. The cosine of an angle is a number between -1 and 1, where 0 means that the vectors are perpendicular, 1 means that they are pointing in the same direction and -1 means that they are pointing in the opposite directions</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>So, if you have two vectors that are very similar, the cosine of the angle between them will be close to 1. And if you have two vectors that are very different, the cosine of the angle between them will be close to 0.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Imagine you have a bunch of products, and you want to know how similar they are to each other. You could represent each product as a vector of numbers, where each number represents a different feature of the product. For example, you could have a vector for <b>cheese</b> that looks like this: <b>[0.6, -0.2, 0.8, 0.9, -0.1, -0.7]</b> Once you have represented each product as a vector, you can use cosine similarity to measure how similar they are.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, the <b>The cosine of an angle would be close to 1 </b> between <b>cheese</b> and <b>butter, </b> because they have many similar features and they both are dairy products. However, the <b>The cosine of an angle would be close to 0 or less than 0</b> between <b>cheese and eggs</b>, because they are not as similar.</p>\n",
    "\n",
    "<center><img src=\"images/cosine.png\" alt=\"cosine\" width=1000 height=800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c67cc-17ae-4317-becd-26f96fd6a444",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "<ul style = 'font-size:16px;font-family:Arial'><li> <b>Embeddings:</b></li></ul>\n",
    "<p style = 'font-size:16px;font-family:Arial'> &emsp;  &emsp; Embeddings are the A.I-native way to represent any kind of data, making them the perfect fit for working with all kinds of A.I-powered tools and algorithms. They can represent text, images, and soon audio and video. There are many options for creating embeddings, whether locally using an installed library, or by calling an API.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Imagine you have a bunch of words, and you want to find a way to represent them in a way that captures their meaning. One way to do this is to create a word embedding. A word embedding is a vector of numbers that represents the meaning of a word. The numbers in the vector are chosen so that words that are similar in meaning have similar vectors.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example, the word \"cheese\", \"butter\", \"chocolate\" and \"sauce\" might have a vector that looks like below:</p>\n",
    "\n",
    "<center><img src=\"images/word_embeddings.png\" alt=\"word_embeddings\"  width=1000 height=800/></center>\n",
    "\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The numbers in this vector don't have any special meaning by themselves. They just represent the way that the word \"cheese\" is related to other words in the vocabulary.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We can use word embeddings to find the similarity between words. For example, we can calculate the cosine similarity between the vector for \"cheese\" and the vector for \"butter\". The cosine similarity is a measure of how similar two vectors are, and it ranges from 0 to 1. A cosine similarity of 1 means that the two vectors are perfectly aligned, and a cosine similarity of 0 means that the two vectors are completely unrelated.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this case, the cosine similarity between the vector for \"cheese\" and the vector for \"butter\" would be very high. This is because the words \"cheese\" and \"butter\" are very similar in meaning. They are both foods that are made from milk, and they are both often used in cooking.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>We can also use word embeddings to find related words. For example, we can find all of the words that are similar in meaning to \"cheese\". This would include words like \"milk\", \"cream\", \"yogurt\", and \"feta\".</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Word embeddings are a powerful tool for natural language processing. They can be used for a variety of tasks, such as sentiment analysis, machine translation, and question answering.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Above is a visual representation of how word embeddings work</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Imagine a bunch of points in a high-dimensional space. Each point represents a word, and the position of the point in space represents the meaning of the word. Words that are similar in meaning will be close together in space, and words that are different in meaning will be far apart.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Now, imagine that we take a slice through this high-dimensional space. This slice will be a two-dimensional space, and the points in the two-dimensional space will represent the word embeddings. The distance between two points in the two-dimensional space will be a measure of the similarity between the two words.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this way, word embeddings can be used to represent the meaning of words in a way that is both compact and informative.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca49b9d-df0b-400a-acf8-0252ab8a2618",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Steps in the analysis:</b></p>\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Configuring the environment</li>\n",
    "    <li>Connect to Vantage</li>\n",
    "    <li>Data Exploration</li>\n",
    "    <li>Generate the OpenAI embeddings</li>\n",
    "    <li>Calculate the VectorDistance using Teradata Vantage in-DB function</li>\n",
    "    <li>Display the recommended products for the users</li>\n",
    "    <li>Cleanup</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Configuring the environment</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6027a7-888d-441f-abc7-a6ea1c45f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# '%%capture' suppresses the display of installation steps of the following packages\n",
    "\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97cdce-0d5e-4e54-b404-da7bae24ef51",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "    <i>The above statements will install the required libraries to run this demo. To gain access to installed libraries after running this, restart the kernel.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b160ce-5ace-4116-86b6-394d6502553b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>To restart the kernel, press the escape key first, then type 0 0.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61067c88-2e9a-4c92-985b-34dc4ab74a13",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>1.1 Import the required libraries</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import timeit\n",
    "\n",
    "# teradata lib\n",
    "from teradataml import *\n",
    "from teradataml import VectorDistance\n",
    "\n",
    "# open AI\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "display.max_rows = 10\n",
    "\n",
    "display.print_sqlmr_query=False\n",
    "display.suppress_vantage_runtime_warnings=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Connection to Vantage and OpenAI</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153b889-0924-4e0f-acc8-6b0d440c77b3",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>2.1 Get the OpenAI API key</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e10add-4b3c-4fc5-9359-0b44737bba0f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In order to utilize this demo, you will need an OpenAI API key. If you do not have one, please refer to the instructions provided in this guide to obtain your OpenAI API key: </p>\n",
    "\n",
    "[Openai_setup_api_key_guide](..//Openai_setup_api_key/Openai_setup_api_key.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd64269-9393-434a-ac26-0b8386fc0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your openai api key\n",
    "api_key = input(prompt = '\\n Please Enter Openai api key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e4d23-3f17-4d43-b9b9-7e125f59b8c7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>2.2 Connect to Vantage</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164cfc91-93ed-45b9-98ba-73b91a50c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO= Recommendations_product_search_OpenAI_Python.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22db506-84a7-406b-be9f-9fe69d268ba4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beec557-411b-4418-acf3-2f28d3c6beac",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>2.3 Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26ca7c-fa9e-4200-8e9e-27f5886aa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_Grocery_Data_cloud');\"        # Takes 1 minute\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_Grocery_Data_local');\"        # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99a16b5-da34-4326-b66b-5f7d5a9d9b04",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79252a5e-b2c1-404a-ae22-6c3d698510c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Data Exploration</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Product recommendation systems are a type of recommender system that suggests products to users based on what they are searching for in the search box. To recommend products to users, we will use OpenAI embeddings and Vantage in db_function.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The data for this demo comes from the products table of Instacart. There are also a few other tables, such as orders, aisles, departments, and order_products_prior. However, for this demo, we will only use the products table.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The products table contains information about all of the products that are available on Instacart. This includes the product id, product name, etc. The table also includes the product's department and aisle, which can be used to group products together.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The other tables in the Instacart dataset contain additional information about orders, aisles, departments, and product purchases. However, for this demo, we will only focus on the products table.<p/>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Each row is a snapshot of data taken from the products table, Below are the list of columns in the product table:</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'> \n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>product_id</li>\n",
    "    <li>product_name</li>\n",
    "    <li>aisle_id</li>\n",
    "   <li>department_id</li>\n",
    "\n",
    "</ol>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The source data from <a href=\"https://www.kaggle.com/competitions/instacart-market-basket-analysis/data\">kaggle</a> is loaded in Vantage with table named <i>Products</i>.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'><b><i>*Please scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8e565-b58b-4cc6-8d9c-50790ca3dcab",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>3.1 Examine the Products table</b></p>    \n",
    "<p style = 'font-size:16px;font-family:Arial'>Let's look at the sample data in the Products table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9951cf-e2b0-40d7-9a8f-a01c7f48ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = DataFrame(in_schema('DEMO_Grocery_Data', 'products'))\n",
    "print(\"Data information: \\n\",tdf.shape)\n",
    "tdf.sort('product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6d954-b72f-41c3-9f8c-bc15cf74d672",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>There are approx 50K records in all, and there are 4 variables. Products are listed from different departments. We shall recommend the products to the user when user is searching for some items from the page.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d769c12-652f-4ef5-8b19-d241d4589422",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To save the cost of generating embeddings from OpenAI, we will use the <b>50 products from snacks department</b> in this demo. This will allow us to test the system without incurring too much cost. Once we have validated the system, we can then consider expanding it to include more products.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b693c31-465d-4aef-afd4-42b66e36cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_sample = tdf.loc[tdf['department_id'] == 19].head(50)\n",
    "print(tdf_sample.shape)\n",
    "tdf_sample.sort('product_id').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89367d27-22ca-4a0e-b299-0f8e1a669157",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. Generate the embeddings </b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>4.1 Generate the embeddings for product table</b></p>    \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Under the hood, we will use the OpenAI embeddings method to generate the embeddings. OpenAI embeddings are a type of word embedding that can be used to represent products in a way that captures their semantic meaning. To generate embeddings for a product table, we will use the product name field. We will use the OpenAI Embeddings API to generate embeddings for each product. Please refer to the <a href=\"https://platform.openai.com/docs/guides/embeddings\"> Embeddings documentation</a> for more information about embeddings and types of models available.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The OpenAI Embeddings API takes a text string as input and returns a vector of numbers that represent the embedding. The length of the vector depends on the model that you are using. For example, the text-embedding-ada-002 model returns a vector of 1536 numbers.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>In this demo, we will use <b>text-embedding-ada-002</b> as the model and <b>cl100k_base</b> as the encoding technique.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484d1ae-6441-4de2-8b5a-b6ce94ea7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "# set api key\n",
    "openai.api_key = api_key\n",
    "\n",
    "def get_embeddings(tdf):\n",
    "    # convert to pandas df\n",
    "    result_df = tdf.to_pandas().reset_index()\n",
    "\n",
    "    # This may take a few minutes\n",
    "    result_df[\"embedding\"] = result_df.product_name.apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "    \n",
    "    # Generate all the embeddings columns from the \"embeddings\" column.\n",
    "    for i in range(len(result_df.loc[0, 'embedding'])):\n",
    "        result_df[\"embeddings_{}\".format(i)] = result_df[\"embedding\"].apply(lambda x: x[i])\n",
    "    \n",
    "    # drop embedding \n",
    "    result_df.drop(\"embedding\", axis=1, inplace=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bffd2a8-532e-40f1-bf39-66cd2d7cf21c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To generate the embeddings, we will call the <b>get_embeddings()</b> function. This function will convert the Teradata DataFrame to a Pandas DataFrame and generate the embeddings. Once the embeddings are generated, we will store them in separate columns so that we can pass them to the <b>VectorDistance()</b> function later on.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f735f0-6e2a-4cb2-b64c-51eb72932fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "df_sample = get_embeddings(tdf_sample)\n",
    "end = timeit.default_timer()\n",
    "load_time = end - start\n",
    "print(f'generate the embeddings for {tdf_sample.shape[0]} products:\\t', load_time)\n",
    "print('----- complete -----')\n",
    "\n",
    "# Print the DataFrame.\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932e4e0-d66d-40ae-815d-c5213e67065d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>We can see that generated embeddings for all of the products are in vector of 1536 columns. </p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>For example: The generated embeddings for product name: <b>Chocolate Sandwich Cookies</b> consists of 1536 numbers and looks like:<br>\n",
    "<code>-0.022753, -0.005572, 0.002955, -0.006420, -0.009042, -0.001586,  ... -0.020612\t </code></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b85fb4-20be-4b92-a565-271fb7f3a32e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Now, we have generated the embeddings from the product names.so to use it further first we have to save the product embeddings dataframe into a vantage table named <b>product_embeddings</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3979b3-8dac-4a25-b32f-158ca1f0704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only delete records if table exists\n",
    "qry = \"DELETE FROM product_embeddings\"\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# only insert records if table exists\n",
    "try:\n",
    "    copy_to_sql(df_sample, table_name='product_embeddings',primary_index='product_id', if_exists='append')\n",
    "except:\n",
    "    print('exception')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781b83c-0907-4bbd-8fe1-1067e587512b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b> 4.2 Get the embedding for few product search terms</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfc258-b177-41e1-805f-7264d24cce13",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Let's take <b>5 random products from the same department</b> to check their recommended products from our database. To do this, we need to follow the same process as before: generate the embeddings for the products and store them back to the Vantage table.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a422bf9-4051-493e-af09-e71da4a42acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_search_products = tdf.loc[tdf['department_id'] == 19].tail(5)\n",
    "\n",
    "print(tdf_search_products.shape)\n",
    "tdf_search_products.sort('product_id').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956aa406-e841-41b1-b22a-e4aa0a3ad7ac",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The get_embeddings() function uses the OpenAI Embeddings API to generate the embeddings.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e938f-8324-49ee-8646-84f02dc89bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "df_search_products = get_embeddings(tdf_search_products)\n",
    "end = timeit.default_timer()\n",
    "load_time = end - start\n",
    "print(f'generate the embeddings for {df_search_products.shape[0]} search products:\\t', load_time)\n",
    "print('----- complete -----')\n",
    "\n",
    "# Print the DataFrame.\n",
    "df_search_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9140060-c796-4f6a-8226-106482067361",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Since the product names were searched, we have now generated the embeddings. The product embeddings dataframe must therefore be saved into a new table called <b>search_product_embeddings</b> before we can utilise it further..</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b7d96-c57a-4a54-a02c-75499b712e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only delete records if table exists\n",
    "qry = \"DELETE FROM search_product_embeddings\"\n",
    "try:\n",
    "    eng.execute(qry)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "# only insert records if table exists\n",
    "try:\n",
    "    copy_to_sql(df_search_products, table_name='search_product_embeddings',primary_index='product_id', if_exists='append')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593971b5-89d1-4fa2-9098-7757889fa3ff",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Calculate the VectorDistance using Teradata Vantage in-DB function</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79ecde-2796-4745-baeb-586af0d60847",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The TD_VectorDistance function accepts a table of target vectors and a table of reference vectors and returns a table that contains the distance between target-reference pairs.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The function computes the distance between the target pair and the reference pair from the same table if you provide only one table as the input.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac3eea-69ca-47d1-8545-cd0c798a6455",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The VectorDistance function calculates the distance between a target vector and a reference vector. We use the cosine distance metric, which measures the similarity between two vectors. The function can return the maximum of 1 to 100 closest reference vectors to include in the output table for each target vector. In this demo, we want the top 2 closest reference vectors to the target vector.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>The VectorDistance function have a parameter <b>distance_measure</b>. You can pass anyone from the below list. Default value is cosine.</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial'>\n",
    "    <li><b>Cosine distance measures</b> the similarity between two vectors by calculating the cosine of the angle between them. It is a good measure of similarity for high-dimensional data, as it is not affected by the magnitude of the vectors.</li>\n",
    "    <li><b>Euclidean distance measures</b> the distance between two points in a Euclidean space. It is the most common distance measure, and it is a good measure of similarity for low-dimensional data.</li>\n",
    "    <li><b>Manhattan distance measures</b> the distance between two points in a Manhattan space. It is similar to Euclidean distance, but it uses the absolute value of the difference between the coordinates instead of the square of the difference.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79325118-ede2-433f-8693-38caea02048d",
   "metadata": {},
   "source": [
    "<center><img src=\"images/distance_measure.png\" alt=\"distance_measure\"  width=600 height=600/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299dc3a-ca6e-4721-8870-8443986a5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_embeddings_df = DataFrame(in_schema('demo_user', 'product_embeddings'))\n",
    "search_product_embeddings_df = DataFrame(in_schema('demo_user', 'search_product_embeddings'))\n",
    "\n",
    "# list out the embedding column names\n",
    "emb_column_names = search_product_embeddings_df.columns[4:]\n",
    "search_product_embeddings_df = search_product_embeddings_df.set_index(keys='product_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117f30f-5960-42d0-9f0f-ef4c7842067c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The below funtion: TD_VECTORDISTANCE will might be take upto 45 seconds to finish the execution.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec199b25-0eea-4bdd-9db5-27b5bba1ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 2\n",
    "query = f'''\n",
    "SELECT \n",
    "  target_id, \n",
    "  reference_id, \n",
    "  distancetype, \n",
    "  cast(\n",
    "    distance as decimal(36, 8)\n",
    "  ) as distance \n",
    "FROM \n",
    "  TD_VECTORDISTANCE (\n",
    "    ON search_product_embeddings as TargetTable \n",
    "    ON product_embeddings as ReferenceTable Dimension \n",
    "    USING TargetIDColumn('product_id') TargetFeatureColumns{tuple(emb_column_names) } \n",
    "    RefIDColumn('product_id') \n",
    "    RefFeatureColumns{tuple(emb_column_names) } \n",
    "    DistanceMeasure('cosine') \n",
    "    topk({topk})\n",
    "  ) as dt \n",
    "order by 3, 1, 2, 4;\n",
    "'''\n",
    "\n",
    "vector_distance_df = pd.read_sql(query, eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b578f-83c2-497f-b81c-2036d9544a9e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>6. Display the recommended products for the users.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def33ea-01e1-446b-8b75-7be46b7eaa72",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>To view the recommendations, we need to join two tables together. First, we will join the vector distance result table with the product embeddings table. This will give us a table that contains the vector distance scores for each product, as well as the product embeddings. Then, we will join this table with the search products table. This will give us a final table that contains the recommendations for the search products.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af433b-d895-4a30-aa59-e2a008d3f4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_embeddings_df_selected_columns = product_embeddings_df.select([\"product_id\", \"product_name\"]).to_pandas().reset_index()\n",
    "\n",
    "# join vector-distance results and products\n",
    "vec_prod_join_result = pd.merge(vector_distance_df, product_embeddings_df_selected_columns, left_on='reference_id', right_on='product_id', how='inner')\n",
    "\n",
    "# join the above joined table with search products\n",
    "vec_prod_join_result_selected = vec_prod_join_result[[\"product_id\",\"product_name\", \"target_id\",\"distancetype\",\"distance\"]]\n",
    "\n",
    "# join_result_sorted_selected\n",
    "df_search_products_selected = search_product_embeddings_df.select([\"product_id\", \"product_name\"]).to_pandas().reset_index()\n",
    "\n",
    "# recommandation results\n",
    "df_recommandations = pd.merge(df_search_products_selected, vec_prod_join_result_selected, left_on = \"product_id\", right_on=\"target_id\", how = \"inner\", suffixes=[\"_search\", '_recommended'])\n",
    "\n",
    "# sort by distance\n",
    "df_recommandations = df_recommandations.sort_values([\"product_id_search\", \"distance\"], ascending=True).reset_index()\n",
    "df_recommandations[['product_id_search', 'product_name_search','product_id_recommended', 'product_name_recommended', 'distance']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e598589-6215-4225-af70-6e14a23ec66f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the above table we can see the recommendations for searched products by the user. We can also see the cosine distance between searched and recommended products</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0654916-ba86-4f96-8f23-5b5c0c9dcdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def response_template(df, cnt, top_k):\n",
    "    view = '''<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Product Recommendations</b></p>'''\n",
    "    i = 0\n",
    "    while i < cnt*top_k and i < len(df):\n",
    "        product_name_search = df.loc[i,'product_name_search']\n",
    "        view = view + f''' <ul style = 'font-size:16px;font-family:Arial'>  <li> Based on your search for  <strong>{product_name_search}</strong> here are some recommended products: <ul>'''\n",
    "        j = i\n",
    "        \n",
    "        view2 = ''\n",
    "        while j < i + top_k:\n",
    "            product_name_recommended = df.loc[j,'product_name_recommended']\n",
    "            view2 = view2 + f''' <li>{product_name_recommended}</li>'''\n",
    "            j +=1\n",
    "            # print(view2)\n",
    "        i += top_k\n",
    "        view =  view + view2 + '</ul></ul>'\n",
    "    return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb37cd1-720d-45a8-a2c8-66f8d5ec7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response_template(df_recommandations, 3, topk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538269ba-a501-4cad-8904-cfbd5103e0e6",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the above list we can see the recommendations for the searched product.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8b817-c0ff-42b3-a651-c8268ac40942",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ccbcfb-8ae5-4a13-80af-262195c6a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\"product_embeddings\", \"search_product_embeddings\"]\n",
    "\n",
    "for t in tables:\n",
    "        try:\n",
    "            db_drop_table(table_name=t)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacb87c-0d81-40f0-8754-608d47e602cc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398148-9486-4535-8c06-d3f77669bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_Grocery_Data');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4cbe-1beb-4c65-ac60-ffd6250668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae971f90-bef1-4228-bcbf-c333e9843284",
   "metadata": {},
   "source": [
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Dataset:</b>\n",
    "\n",
    "\n",
    "- `product_id`: Unique row customer id\n",
    "- `product_name`: customer age (numeric)\n",
    "- `aisle_id` : Aisle id (numeric)\n",
    "- `department_id` : Depatment id (numeric)\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#E37C4D'><b>Links:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Teradataml Python reference: <a href = 'https://docs.teradata.com/search/all?query=Python+Package+User+Guide&content-lang=en-US'>here</a></li>\n",
    "    <li>OpenAI embeddings reference: <a href='https://platform.openai.com/docs/guides/embeddings'>here</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
