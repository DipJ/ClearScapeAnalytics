{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c7b2ca-a3a2-4525-aeb3-2276de42e3c2",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Demand Forecasting with In-Database Time Series\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Forecasting is a process of making predictions of the future based on past and present data and, most commonly, by analyzing trends.<br>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>For businesses, the ability to predict the future and make informed decisions is critical to their survival. The traditional method of generating forecasts from time series data often struggles to generate accurate predictions, especially when dealing with extensive data with irregular trends. The ability to predict demand accurately is a critical need for retailers. They need to know how many inventory store units to have at hand to be at full stock for each product at a given time. A low inventory level increases the risk of having a stock out, and a too-high inventory level increases the cost related to handling inventory.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Unbounded Array Framework (UAF) is the Teradata framework for building end-to-end time series forecasting pipelines. It also provides functions for digital signal processing and 4D spatial analytics. The series can reside in any Teradata supported or Teradata accessible table or in an analytic result table (ART).</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>UAF provides data scientists with the tools for all phases of forecasting:\n",
    "<li style = 'font-size:16px;font-family:Arial'>Data preparation functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Data exploration functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Model coefficient estimation functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Model validation functions</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Model scoring functions</li>\n",
    "\n",
    "<p></p>    \n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Hence as a data science consultant, we are showcasing the complete approach about how we can make prediction for the demand for each store. We are demonstrating how we can train our models and use them for scoring using the ClearScape Analytics platform. The data we are using is a sample dataset and the results and predictions may not be entirely accurate.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d3da0-34dd-4d23-8401-c2d817268273",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1. Connect to Vantage.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527135cc-6731-4019-8011-62bd08b18ba1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We start by importing the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e070e01-e395-4f3f-a661-d63b70d897e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# # '%%capture' suppresses the display of installation steps of the following packages\n",
    "# !pip install tdsense==0.1.3.11\n",
    "# !pip install  tdnpathviz==0.1.2.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a4f2b-da84-4013-9481-f7ef4ef38665",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed. If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f6655-e7d8-45ee-8b73-32ea33151f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import teradataml as tdml\n",
    "from teradataml import * \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import getpass\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tdsense.plot import plotcurves\n",
    "from tdsense.clustering import resample\n",
    "\n",
    "display.max_rows=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c2a75-1ce4-4481-8c62-239cb4154244",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>You will be prompted to provide the password. Enter your password, press the Enter key, then use down arrow to go to next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c3c50-7ca9-4d24-a29d-8797a490372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa17e5c-756f-4d9d-9985-c3e3d2cebf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=Retail_Demand_Forecasting_Python.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fd14a-95f7-4a3f-a963-3830cf78f1e7",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Getting Data for This Demo </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage.  You have the option of either running the demo using foreign tables to access the data without using any storage on your environment or downloading the data to local storage which may yield somewhat faster execution, but there could be considerations of available storage.  There are two statements in the following cell, and one is commented out.  You may switch which mode you choose by changing the comment string. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389d258-6ef6-4b26-8afb-7ee5e7ebecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_DemandForecast_cloud');\"\n",
    " # Takes about 45 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_DemandForecast_local');\"\n",
    " # Takes about 70 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c754c-2e1c-40da-8298-b4c89bcebb8f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Next is an optional step – if you want to see status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94903d-62d7-4d32-8d20-52b25c6ac94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223fe73-10a0-4d0d-9fdb-cfcc08653c45",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Analyze Raw Data.</b></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d415b0-4606-4d70-888c-d7e2173cb31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema('DEMO_DemandForecast','Demand_Data'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8714207f-d261-4489-b44e-beb618a3959b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The dataset is a retail dataset where we have the timekey(is the lowest granularity column used for our analysis), the Product(MODELID), the Store(MARKET) and the column DEMAND which will be used for analysis. The timekey is the column generated for creating a series for analyzing our data over time period.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae2205-8131-40b3-866b-935f85bdf882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.select(['timeKey', 'MARKET', 'MODELID'])\n",
    "df_count.count(distinct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77898705-7de6-4519-b6c6-78ca867f5b8f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The dataset contains 6 different Stores and 4106 different Products which we are analyzing over the timeKey generated series having 166 series IDs</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92a3f0-2002-45aa-bbb6-0cb9b77acb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df_count.groupby('MARKET')\n",
    "df_plot=df2.count(distinct=True).to_pandas()\n",
    "# df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5757c6-63b6-4ea7-a448-3b131d7bac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'MARKET',y = 'count_MODELID',data = df_plot)\n",
    "plt.xlabel('MARKET')\n",
    "plt.ylabel('Count of Products')\n",
    "plt.title('Count of Products Sold by each Market')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b271bd4-a38a-4667-86c5-7213d578505c",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>As seen in the above chart , as MARKET01 and MARKET06 do not have much data we will not consider these in further analysis.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will check if the Demand is Zero, and also calculate the duration of the Demand based on the timekey for these Products.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde850a-f49c-49f4-80ad-b594eee10470",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metrics = df[['MODELID','timeKey','DEMAND']]. \\\n",
    "                    assign(demand_is_zero=tdml.sqlalchemy.literal_column('CASE WHEN DEMAND=0 THEN 1 ELSE 0 END')). \\\n",
    "                    groupby('MODELID'). \\\n",
    "                    agg({'timeKey' : ['min','max'], 'demand_is_zero':['sum']}). \\\n",
    "                    assign(duration=tdml.sqlalchemy.literal_column('max_timeKey - min_timeKey')). \\\n",
    "                    select(['MODELID','sum_demand_is_zero','duration']). \\\n",
    "                    assign(ratio = tdml.sqlalchemy.literal_column('CAST(sum_demand_is_zero AS FLOAT) / NULLIFZERO(duration)'))\n",
    "\n",
    "dataset_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1fb7a-353e-4c62-9bf4-1287da02a2d7",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will check only those Series where the duration(difference between the max timekey and min timekey for each Product) is greater than 50 and MATERIAL less than 300. To fit data in a seasonal model, we would like to consider only series with at least 2 years  (24 months). So, considering duration greater than 30.</p>\n",
    "\n",
    "<p style = 'font-size:14px;font-family:Arial'><i>Material less than 300 is considered only to show lesser data in plots for better understanding </i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a932f90-c8fe-4efb-bb22-af2c2dc2d9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = df.join(other=dataset_metrics, on='MODELID', how='inner', lsuffix='l', rsuffix='r').assign(MODELID=tdml.sqlalchemy.literal_column('l_MODELID')).drop(columns=['l_MODELID','r_MODELID'])\n",
    "dataset = dataset[dataset.duration > 30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edb3e5-7963-491b-ab73-25473d01bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tdnpathviz.visualizations import plotcurves\n",
    "plotcurves(dataset[dataset.MATERIAL < 300],field='DEMAND',row_axis='timeKey', series_id='MODELID',row_axis_type='sequence',plot_type='line',\n",
    "           legend='best',width=1800,height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827f7d6-8fd0-4c44-bf22-dece382fea0e",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The above graph shows the Demand for each Product(MODELID) along the timekey axis.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>One of our strengths is that we can run thousands of models concurrently, however for the purposes of this demo, we will arbitrarily choose 3 products so you can follow the process. The Product selection is random. </p>\n",
    "<p style = 'font-size:12px;font-family:Arial'><i>** You can change the products(MODELIDs) in the below cell in case you want to see the output for other Products. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc84c85-f56f-4b14-b759-8adb61332b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELID_1 = 'MARKET0412164'\n",
    "MODELID_2 = 'MARKET0412341'\n",
    "MODELID_3 = 'MARKET0205595'\n",
    "\n",
    "# 'MARKET0301261'\n",
    "# 'MARKET0501264'\n",
    "# 'MARKET0200798'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4bb62-f7ab-4476-863f-d8ffa0118db5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial'>We will check the Demand for these Products</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0639b-9a82-4cc5-a8ad-d4c6b447bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_1 = df.loc[df.MODELID == MODELID_1,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_2 = df.loc[df.MODELID == MODELID_2,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_3 = df.loc[df.MODELID == MODELID_3,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4d1c0-89be-4289-bf14-c0c8a02fc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(21,5))\n",
    "df_ts_1.plot(ax=ax[0], title=MODELID_1)\n",
    "df_ts_2.plot(ax=ax[1], title=MODELID_2)\n",
    "df_ts_3.plot(ax=ax[2], title=MODELID_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6179702f-a003-47d1-b65c-fb3e2cbf85f4",
   "metadata": {},
   "source": [
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We use the window function on the timekey column to build a series for the Demands for different ModelIDs. We use this function to count the series length and filter out timeseries that are too short for ARIMA.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b7ccaf-672e-4e4f-9b62-5deeffce5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_for_counting = dataset.timeKey.window(\n",
    "                            partition_columns   = \"MODELID\",\n",
    "                            order_columns       = 'timeKey'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4f4f1-c010-4b74-b874-70d00ff62300",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new = dataset.assign(series_length = window_for_counting.count(),\n",
    "                             nb_zeros = tdml.sqlalchemy.literal_column('SUM(CASE WHEN DEMAND = 1 THEN 1 ELSE 0 END) OVER (PARTITION BY MODELID)'),\n",
    "                             frac_zeros = tdml.sqlalchemy.literal_column('CAST((SUM(CASE WHEN DEMAND = 0 THEN 1 ELSE 0 END) OVER (PARTITION BY MODELID)) AS FLOAT)/series_length'),\n",
    "                             fold = tdml.sqlalchemy.literal_column(\"CASE WHEN timeKey < 0.67*series_length + (min(timeKey) OVER (PARTITION BY MODELID)) THEN 'train' ELSE 'test' END\"),\n",
    "                             time_no_unit = tdml.sqlalchemy.literal_column(\"timeKey-(min(timeKey) OVER (PARTITION BY MODELID))\")\n",
    "                            )\n",
    "dataset_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee3c58-50a8-4af2-ac21-be995e028ffc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We use the subset of data where the series length is greater than 90 and the ratio of zero demand and series length is less than 0.1, which will filter out the Markets which show almost zero Demand (Market01 and Market06).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d2ba0-a5bb-4818-8bc5-8d3ec8f4814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset_new[(dataset_new.series_length > 90)&(dataset_new.frac_zeros < 0.1)]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff06e4-85ae-4193-9879-ac54dcd670ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918b4fb-d432-4732-ac89-55525815d322",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>So, the dataset we are using for our analysis has around 46k rows and 21 columns.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed8e73-e9f2-454d-88b8-5c67ee87aef9",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Checking for Stationarity of Time Series using the Dickey Fuller Test</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf337f98-70d1-4b0e-8ea2-dd3ba147757a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To be able to model a time series, it needs to be stationary(Stationarity is a property of a time series where the statistical properties of the series do not change over time. In other words, a stationary time series exhibits constant mean, constant variance, and constant covariance (or autocovariance) over different time periods.). ARIMA models deal with non-stationary time series by differencing (The \"d' parameter in ARIMA determines the number of differences needed to make a series stationary)</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here we will check for stationarity of the time series using the Dickey-Fuller Test. For more info on the test,  see <a href=\"https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/Teradata-VantageTM-Unbounded-Array-Framework-Time-Series-Reference-17.20/Diagnostic-Statistical-Test-Functions/TD_DICKEY_FULLER/TD_DICKEY_FULLER-Example\">here.</a> \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The null hypothesis for the test is that the data is non-stationary. We want to REJECT the null hypothesis for this test. So, we want a p-value of less than 0.05 (or smaller) and a negative coefficient value for the lag term in our regression model.</p> \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Dickey fuller function needs series data so we use the TDSeries function to create a series and apply DickeyFuller to check the stationarity of the data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f74d5-a88f-4b9c-81dc-29e6d47bc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create teradataml TDSeries object.\n",
    "data_series_df = tdml.TDSeries(data=subset,\n",
    "                          id=\"MODELID\",\n",
    "                          row_index=\"time_no_unit\",\n",
    "                          row_index_style=\"SEQUENCE\",\n",
    "                          payload_field=\"DEMAND\",\n",
    "                          payload_content=\"REAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b1994d-006e-4ba6-8a07-6a2cc62b7159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from teradataml import DickeyFuller\n",
    "df_out = DickeyFuller(   data=data_series_df,\n",
    "                           algorithm='NONE')\n",
    "\n",
    "# Print the result DataFrame.\n",
    "print(df_out.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b2f94-5022-41a5-b950-2646431cfb52",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above output the p-value corresponding to the calculated test statistic is less than 0.05. It means that the series is stationary. The output column NULL_HYP which means NULL HYPOTHESIS can have 2 values \n",
    "    <li style = 'font-size:16px;font-family:Arial'>ACCEPT means the null hypothesis is accepted. No Unit roots are present, and therefore the process is stationary.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>REJECT means the null hypothesis is rejected. Unit roots are present, and the process may or may not be stationary, depending on other factors.</li>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Since the P_VALUE is less than 0.05 we consider the series and stationary.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80890992-f8a7-47a3-87ec-3b3f399372b8",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5. Autocorrelation and Partial Autocorrelation of the time series</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>5.1 Check for Autocorrelation of the time series</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>ACF calculates the autocorrelation or autocovariance of a time series. The autocorrelation and autocovariance show how the time series correlates or covaries with itself when delayed by a lag in time or space. Here we check autocorrelation with a maximum lag of 10 time steps.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce9923-8586-4f3b-9f97-d7585b47b2af",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>First we use the Series created above to get the ACF and PACF.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8cb5c-bf6b-4a0d-9cbe-c7edbf7440cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ACF, PACF\n",
    "uaf_out = ACF(data=data_series_df,\n",
    "                  max_lags=10,\n",
    "             alpha=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81780e3d-b55d-4667-bbf7-487b76920e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uaf_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb685a4-7d12-4e4b-b7d6-a60a493d417b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ACF() function calculates the autocorrelation or autocovariance of a time series. The autocorrelation and autocovariance show how the time series correlates or covaries with itself when delayed by a lag in time or space.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above output: </p> \n",
    "    <li style = 'font-size:16px;font-family:Arial'>ROW_I :- index of the series.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>CONF_OFF :- Confidence bands in accordance with Bartlett’s formula.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>CONF_LOW :- Confidence bands in accordance with Bartlett’s formula (Lower limit).</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>CONF_HI :- Confidence bands in accordance with Bartlett’s formula (Higher limit).</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a678260-f071-417d-a1e4-ee73328adf38",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>5.2. Check for partial autocorrelation of the time series</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The PACF function provides insight as to whether the modelled function is stationary. The partial autocorrelations measure the degree of correlation between time series sample points. Here we check partial autocorrelation with a maximum lag of 10 time steps.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4538-ea17-49fd-81b1-f465ba59417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PACF_out = PACF(data=data_series_df,\n",
    "                    algorithm='LEVINSON_DURBIN',\n",
    "                    max_lags=10,\n",
    "             alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86660cda-fdc2-4514-adf4-70a4f950badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PACF_out.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22454b44-d86c-4150-abe3-a09c663ec6dc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The PACF() function provides insight as to whether the function being modeled is stationary or not. The partial auto correlations are used to measure the degree of correlation between series sample points. The algorithm removes the effects of the previous lag.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above output: </p> \n",
    "    <li style = 'font-size:16px;font-family:Arial'>ROW_I :- index of the series.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>CONF_OFF :- Confidence bands in accordance with Bartlett’s formula.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>CONF_LOW :- Confidence bands in accordance with Bartlett’s formula (Lower limit).</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>CONF_HI :- Confidence bands in accordance with Bartlett’s formula (Higher limit).</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67515454-0011-4ca2-98c9-f7e56d22a8d4",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>5.3. Plot graphs for ACF and PACF of the time series</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We plot the ACF and PACF graphs for all the 3 series we are considering in our analysis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5aeaa0-bcb1-4d7e-bab6-1c2629dec03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_1 = subset.loc[subset.MODELID == MODELID_1,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_2 = subset.loc[subset.MODELID == MODELID_2,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n",
    "df_ts_3 = subset.loc[subset.MODELID == MODELID_3,['timeKey','DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577df50-ae44-4394-a614-bcfd72a22f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = ['MODELID_1', 'MODELID_2', 'MODELID_3']  # Add the desired MODELID values\n",
    "\n",
    "# Filter the subset DataFrame based on the MODELID values\n",
    "filtered_subset = subset.loc[subset['MODELID'].isin(model_ids), ['timeKey', 'DEMAND']].sort('timeKey').to_pandas().set_index('timeKey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065e4e7e-4c92-47db-8379-caf9a4389613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "def plot_acf_pacf(df,m=12):\n",
    "    # Create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,6))\n",
    "    # Make ACF plot\n",
    "    plot_acf(df, lags=12, zero=False, ax=ax1)\n",
    "    # Make PACF plot\n",
    "    plot_pacf(df, lags=12, zero=False, ax=ax2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bceaee1-ccc7-403d-8556-f0f127d578ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf_pacf(df_ts_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0798849-1614-4cf5-ac49-be4c35e6eeec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To get the value of the Moving Average or Q, we need the lag(here, ROW_I is the X axis) where the value from the ACF plot is outside the significant limit above the zero line. Looking at the graph, the Auto-Correlation value at ROW_I = 2 is outside the confidence band and much closer to it. Hence it is acceptable to say that the value of the Moving Average or <b>Q = 2</b>.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>To get the value of Auto-Regressive lags or P, we need the lag(here, Row_I) where the value from the PACF plot falls just outside the significant limit. Looking at the graph, the Partial Auto-Correlation value at ROW_I = 1 falls way outside the significant limit of the confidence band so here we will consider the value as zero. Hence we can say that the value of Auto-Regressive lags or <b>P = 0</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e1931-ebbd-4be7-be38-8bacd3064b76",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>6. Using ARIMA (AutoRegressive Integrated Moving Average) model to forecast Demand</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>ARIMA functions on VANTAGE run in the following order:</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial'>Run <b>ARIMAESTIMATE</b> function to get the coefficients for the ARIMA model.\n",
    "</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'><i>[Optional]</i> Run <b>ARIMAVALIDATE</b> function to validate the \"goodness of fit\" of the ARIMA model, when FIT_PERCENTAGE is not 100 in ARIMAESTIMATE.\n",
    "</li>\n",
    "<li style = 'font-size:16px;font-family:Arial'>Run the <b>ARIMAFORECAST</b> function with input from step 1 or step 2 to forecast the future periods beyond the last observed period.</li>\n",
    "</p>\n",
    "\n",
    "\n",
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>6.1 Estimation step using ARIMAESTIMATE</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ARIMAESTIMATE function estimates the coefficients corresponding to an ARIMA model and fits a series with an existing ARIMA model. The function can also provide the \"goodness of fit\" and the residuals of the fitting operation. The function generates a model layer used as input for the ARIMAVALIDATE and ARIMAFORECAST functions. This function is for univariate series.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, the previously estimated parameters P, d and Q need to be passed in the MODEL_ORDER(P, d, Q), i.e. <b>MODEL_ORDER(0, 1, 2)</b>. The output is stored in a dataframe. The fit percentage is 80, meaning the ARIMA model is being trained on 80% of the data. The remaining 20% of the data will be used to validate the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8feba-644e-4db4-9c15-a18da1887658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from teradataml import ArimaEstimate,ArimaValidate, ArimaForecast, TDAnalyticResult\n",
    "arima_estimate_op = ArimaEstimate(data1=data_series_df,\n",
    "                                       nonseasonal_model_order=[0,1,2],\n",
    "                                       seasonal_period=12,\n",
    "                                       seasonal_model_order=[1,1,1], \n",
    "                                       constant=False,\n",
    "                                       algorithm=\"MLE\",\n",
    "                                       coeff_stats=True,\n",
    "                                       fit_metrics=True,\n",
    "                                       residuals=True,\n",
    "                                       fit_percentage=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc98d38-81f0-4f26-bb3b-e4be7c9af38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_estimate = arima_estimate_op.fitresiduals\n",
    "results_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f59402-94b0-4530-8fe7-d30a7fcf8ccc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ArimaEstimate() function estimates the coefficients corresponding to an ARIMA (AutoRegressive Integrated Moving Average) model, and to fit a series with an existing ARIMA model.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above output: </p> \n",
    "    <li style = 'font-size:16px;font-family:Arial'>ROW_I :- Indexing column for the one dimensional multivariate output array containing the residuals. It is incremented by 1 for each row, starting from 1.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>ACTUAL_VALUE :- The actual value of the response variable.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>CALC_VALUE :- The calculated value of the response variable using the model.</li>\n",
    "    <li style = 'font-size:16px;font-family:Arial'>RESIDUAL :- The difference between the calculated response value and the actual response value.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c92f98-ed41-4be6-8f47-f5c2305e9201",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>6.2 Validate using ArimaValidate</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ArimaValidate() function performs an in-sample     forecast for both seasonal and non-seasonal auto-regressive (AR), moving-average (MA), ARIMA models and Box-Jenkins seasonal ARIMA model formula followed by an analysis of the produced residuals. The aim is to provide a collection of metrics useful to select the model and expose the produced residuals such that multiple model validation and statistical tests can be conducted.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The TDAnalyticResult function retrieves auxiliary result sets stored in the output dataframe of the ArimaEstimate. Here we extract the residuals from the previous estimation step. Analytical Result Tables have multiple layers that store different data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7ca54-d2bf-4cda-b54d-a2aa3e24536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_art_df = tdml.TDAnalyticResult(data=arima_estimate_op.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409e0e4-7911-4a88-920c-cd4ff98d1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_validate_op = ArimaValidate(data=data_art_df, fit_metrics=True, residuals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a65cc2-2b50-41c1-8cef-3dfb59b0658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_validate_op.result.sort('AIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54257d0f-d6a0-48ea-b5ce-58ab9ce2c0f0",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ArimaValidate function produces a multilayer output and returns up to four result\n",
    "sets (layers).</p>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>Primary layer contains the model selection metrics.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>Secondary layer contains the goodness-of-fit metrics.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>Tertiary layer contains the residuals from the validation procedure.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>Quaternary layer contains the model context, which can be used for forecasting with the model.</li>\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above output:    <li style = 'font-size:14px;font-family:Arial'>ROW_I :- index of the series.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial'>NUM_SAMPLES :- Total number of sample points found in each of the original, calculated,\n",
    "and residual series.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial'>VAR_COUNT :- Integer Total number of parameters involved in the model. For an ARMA(p,q) model, the calculation of VAR_COUNT is p + q + 1.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>AIC :- The calculated Akaike Information Criteria value.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>SBIC :- The calculated Schwarz Bayesian Information Criteria value.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>HQIC :- The calculated Hannon Quinn Information Criteria value.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>MLR :- The calculated Maximum Likelihood Rule value.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>MSE :- The calculated Mean Square Error value.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391cf92-d8b0-4c5f-862c-1f7964c079e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_validate = arima_validate_op.fitresiduals\n",
    "results_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d7c33-d658-42e0-bb09-fde5a9eb39f4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We plot the actual vs calculated values for the 3 different Products(MODELIDs) we are analyzing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a7c0d2-3378-4486-bd88-33bdeb3dde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(MODELID):\n",
    "    res1 = results_validate[results_validate.MODELID == MODELID].sort('ROW_I').to_pandas()\n",
    "    res2 = results_estimate[results_estimate.MODELID == MODELID].sort('ROW_I').to_pandas()\n",
    "    res1['ROW_I'] = res1['ROW_I']-res1['ROW_I'].values[0]+res2['ROW_I'].values[-1]+1\n",
    "    res3 = subset[subset.MODELID == MODELID][['MODELID','time_no_unit','DEMAND']].sort('time_no_unit').to_pandas()\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    res1.plot(x='ROW_I',y=['CALC_VALUE'],ax=ax, marker='o',xlabel='Time',ylabel='Demand')\n",
    "    res2.plot(x='ROW_I',y=['CALC_VALUE'],ax=ax, marker='s',xlabel='Time',ylabel='Demand')\n",
    "    # res1.plot(x='ROW_I',y=['CALC_VALUE'],ax=ax, xlabel='Time',ylabel='Demand',)\n",
    "    # res2.plot(x='ROW_I',y=['CALC_VALUE'],ax=ax, xlabel='Time',ylabel='Demand')\n",
    "    res3.plot(x='time_no_unit',y='DEMAND',ax=ax,xlabel='Time',ylabel='Demand')\n",
    "    return\n",
    "\n",
    "plot_results(MODELID_1)\n",
    "plot_results(MODELID_2)\n",
    "plot_results(MODELID_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65166abb-9e31-48cc-ab19-751ba47195b5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The above graphs show the <b>Actual Demand Values(Green)</b> and the Calculated Values for the Demand using the <b>ArimaEstimate(Orange)</b>, which is the train dataset(80%) as specified in the ArimaEstimate and <b>ArimaValidate(Blue)</b>, which is the test dataset(remaining 20%)</b>. The 3 graphs are for the 3 Products(MODELIDs).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29847e03-39f8-4792-b34a-269197e76e2f",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>6.3 Forecast Demand using ArimaForecast</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ArimaForecast() function is used to forecast a user-defined number of periods based on\n",
    "    models fitted from the ArimaEstimate() function.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ArimaForecast() function with input from step 1 or step 2 to forecast the future periods beyond the last observed period. Here we are forecasting for 20 periods.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bf238-c0d2-45eb-92fe-45f8674a6c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_art_df = TDAnalyticResult(data=arima_validate_op.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931335b-23e8-4c9e-bd3e-52086e9f5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_forecast_op = ArimaForecast(data=data_art_df, forecast_periods=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d84f9-d29f-4c96-aa6d-ad7e0790eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_forecast = arima_forecast_op.result\n",
    "results_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd06092-7de0-4a80-a010-da0549717734",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This function outputs a result set that contains the forecasted values.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the above output:    \n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>ROW_I :- index of the series.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>FORECAST_VALUE :- Forecasted values for the model.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>LO_80 :- Low end of the 80% prediction interval.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>HI_80 :- High end of the 80% prediction interval.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>LO_95 :- Low end of the 95% prediction interval.</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>HI_95 :- High end of the 95% prediction interval.</li>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3bbff-aad3-41ac-9a95-8d8ac29517fe",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We plot the actual vs forecast values for the 3 different Products(MODELIDs) we are analyzing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9fe5e-2c8e-41a6-bcaa-f30919ed31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(MODELID):\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    # Plot prediction\n",
    "    mean_forecast = results_forecast[results_forecast.MODELID==MODELID].sort('ROW_I').to_pandas()\n",
    "    res3 = subset[subset.MODELID == MODELID][['MODELID','time_no_unit','DEMAND']].sort('time_no_unit').to_pandas()\n",
    "    res3['time_no_unit'] = res3['time_no_unit'] - res3.time_no_unit.values[-1]\n",
    "    res3.plot(x='time_no_unit',y='DEMAND',label='actual',ax=ax)\n",
    "    mean_forecast.plot(x='ROW_I',y='FORECAST_VALUE',label='forecast',color='red',ax=ax)\n",
    "    # Shade uncertainty area\n",
    "    plt.fill_between(mean_forecast.ROW_I, mean_forecast.LO_80, mean_forecast.HI_80, color='pink', alpha=0.5)\n",
    "    plt.fill_between(mean_forecast.ROW_I, mean_forecast.LO_95, mean_forecast.HI_95, color='pink', alpha=0.2)\n",
    "    plt.title(MODELID)\n",
    "    plt.show()\n",
    "    return\n",
    "plot_forecast(MODELID_1)\n",
    "plot_forecast(MODELID_2)\n",
    "plot_forecast(MODELID_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1d9de-f015-47ab-9298-04b756016db9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The plot in pink color shows the forecasted values for each Product(MODELID) for the 20 periods we have specified in the ArimaForecast.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4342cc-9661-48bf-ad96-b2057f8b359d",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Conclusion:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have trained and validated the ARIMA model on the Weekly Sales dataset, and the results closely match the actual data. The goodness of fit metrics calculated in the estimate and validate phase also resonate with our understanding that the model is well-trained to forecast. This can be observed in the Estimate and the Validate function graphs. So, we can say that the model is well trained to forecast the Weekly Sales.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b3987-5668-4706-a7a3-5af33cfa1896",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>8. Cleanup</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf292234-0cdb-43a4-a370-f8039cf5f39b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333849a1-b510-404b-ad01-8a2e41defeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_DemandForecast');\" \n",
    "#Takes 45 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418001cb-0540-4836-9a34-35cc910aa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f134d-77d6-4a62-be43-51bb64920882",
   "metadata": {},
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analytics™</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Copyright © Teradata Corporation - 2023. All Rights Reserved\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
