{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial;color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Cancer Prediction using Google Vertex AI with TDApiClient using Custom Model\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>This is a Beta Release of this notebook!</b></p>   \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>   \n",
    "This should be considered a Beta Release.  Every effort has been made to ensure it's functionality and completeness.  If you discover any issue with any part of this notebook, your suggestions will be reviewed and, if approved, merged in the next round of notebook commits.   \n",
    "<br>   \n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>How to submit a Review of this Notebook</b></p>   \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>   \n",
    "First, please read through and execute the notebook.   \n",
    "<br> \n",
    "If you think the notebook is fine as it is, great.  Please send us a quick email and let us know. When the notebook is taken out of beta, this paragraph will be removed and the Beta designation the index page will be removed.   \n",
    "<br> \n",
    "If you find something that you question or you think needs to be changed or if you think it's great as it is:   \n",
    "</p>       \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>   \n",
    "  <li>Send us an email: <a href=\"mailto:ClearScapeAnalyticsNotebookReviews@Teradata.com?subject=Beta Notebook Review\">Click here.</a></li>   \n",
    "  <li>Please include the name of the notebook in email.</li>   \n",
    "  <li>Include a screen shot or a clear description of the section in the notebook you would like us to look at.</li>   \n",
    "  <li>Paste the screen shot or enter the description of the section into the email.</li>   \n",
    "  <li>Describe how you would change it.</li>   \n",
    "  <li>Send It!</li>   \n",
    "</ol>   \n",
    "</p>   \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If we have any follow-up questions, we'll reach out to you at the return email address. </p>   \n",
    "<hr style=\"height:4px;border:none;background-color:#00233C;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Worldwide, breast cancer is the most common type of cancer in women and the second highest in terms of mortality rates. Diagnosis of breast cancer is performed when an abnormal lump is found (from self-examination or x-ray) or a tiny speck of calcium is seen (on an x-ray). After a suspicious lump is found, the doctor will conduct a diagnosis to determine whether it is cancerous and, if so, whether it has spread to other parts of the body. Vantage Clearscape Analytics provides us various machine learning techniques to develop predictive models for cancer diagnosis. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass, using descriptions that define the characteristics of the cell nuclei.</p> \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Vertex AI empowers machine learning developers, data scientists, and data engineers to take their projects from ideation to deployment, quickly and cost-effectively. With the Teradata Vantage API_Request feature directly from Vantage, we can connect to these Vertex AI endpoints through a function to do real-time scoring on data. Google provides the Vertex AI Python SDK, which includes TrainingJob classes for training models on the Vertex AI platform. For the workflow, training runs on the Vertex AI platform. The model is then deployed on a Vertex AI online endpoint and on Teradata Vantage.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Business Values</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Comprehensive health predictions and a reduced number of false positive and false negative results.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Reduced cost to patients and hospitals caused by cancer.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Identify patterns and symptoms leading to breast cancer to ensure early intervention.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Advanced research and development stemming from the results of the data and models produced.</li></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Machine Learning and AI have a proven track record of improving patient outcomes and well-being across the entire healthcare industry. Traditional approaches to data preparation, model development, and deployment rely on manual, error-prone processes that prevent enterprises from realizing the true value of these tools and techniques.</p>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>However, Vantage provides these same proven data preparation and machine learning capabilities, integrated as native ClearScape Analytic functions.  This allows organizations to drastically reduce data preparation, model development, and testing time, while allowing for much more frequent and iterative testing and tuning to ensure maximum life-critical accuracy.</p>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Furthermore, the exact same development pipeline can be deployed seamlessly to production, eliminating the traditional development-to-deployment gap in the ML and AI industry.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1. Initial setup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Install packages</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the section, we will install the TDApiClient packages along with the necessary packages needed for the TDApiClient package.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# # '%%capture' suppresses the display of installation steps of the following packages\n",
    "!pip install --upgrade numpy pyopenssl\n",
    "!pip install tdapiclient\n",
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed.Â If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Setting up Google Cloud Vertex AI credentials</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>This notebook cannot be executed if you do not have a Vertex AI service account with the necessary permissions. Information regarding the Vertex AI account and the necessary permissions is given below</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Required Vertex AI Credentials:</b>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GOOGLE_APPLICATION_CREDENTIALS:</b> The json file which has credentials for the service account.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_REGION:</b> Region for the service account and the storage bucket.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_PROJECT_ID:</b> Project ID</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_TD_AUTH_OBJ:</b> Authorization object created in the database for Google Cloud</li>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>How to Get These Inputs:</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>GOOGLE_APPLICATION_CREDENTIALS, GCP_REGION, GCP_PROJECT_ID and GCP_TD_AUTH_OBJ: These credentials are related to your Google account and subscription. If you already have an Google account and an active subscription for the Vertex AI service account, you can find these credentials in the Google cloud portal. Here's how:\n",
    "    \n",
    "<ul style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "            <li><a href=\"https://developers.google.com/workspace/guides/create-credentials#:~:text=Click%20Keys%20%3E%20Add%20key%20%3E%20Create,json%20in%20your%20working%20directory.\">Download json with GCP Application credentials</a></li>\n",
    "            <li><a href=\"https://cloud.google.com/compute/docs/regions-zones\">Find your GCP Region</a></li>\n",
    "            <li><a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects\">Find your Project ID</a></li>\n",
    "    <li><a href=\"https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/SQL-Data-Definition-Language-Syntax-and-Examples/Authorization-Statements-for-External-Routines/CREATE-AUTHORIZATION-and-REPLACE-AUTHORIZATION/CREATE-AUTHORIZATION-and-REPLACE-AUTHORIZATION-Syntax\">GCP Authorization object in Teradata database</a></li>\n",
    "        </ul>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Below is the sample SQL for creation of the GCP Authorization object in Teradata database</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CREATE AUTHORIZATION Auth_S3_USR_IVO\n",
    "USER 'service-account-name@project-id.iam.gserviceaccount.com'\n",
    "PASSWORD '-----BEGIN PRIVATE KEY-----\\n\n",
    "MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCyfg3398iOxjt...almSAvk9SqPoyZ\n",
    "R7JJFs=\\n -----END PRIVATE KEY-----\\n';\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will also have to create a Google cloud bucket where we will be uploading our code and artifacts when using the Vertex AI models. If you already have a bucket created you can use the same else to create a new bucket check this <a href=\"https://cloud.google.com/storage/docs/creating-buckets?_gl=1*lboq4y*_ga*MTQyNzA2MDA1OC4xNzEwMzEzMTcw*_ga_WH2QY8WWF5*MTcxMTA4MDY3MC4xOS4xLjE3MTEwODIzMzguMC4wLjA.&_ga=2.269165169.-1427060058.1710313170\">link</a>. We also need to check the permissions needed for these buckets to be used by the Vertex AI API calls ad mentioned <a href=\"https://cloud.google.com/vertex-ai/docs/general/access-control\"> here.</a></p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Since we are going to use the Vertex AI Pre Built Containers and access them using the APIs, we will have to Enable the API as mentioned <a href= \"https://cloud.google.com/vertex-ai/docs/start/cloud-environment\">here</a></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can also create a new service account using the<a href= \" https://cloud.google.com/vertex-ai/docs/general/custom-service-account\"> Vertex AI custom service account </a></p>    \n",
    "   \n",
    "</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In case you do not have a Google cloud account you can create one by following the steps mentioned <a href=\"https://cloud.google.com/free/?utm_source=google&utm_medium=cpc&utm_campaign=japac-IN-all-en-dr-BKWS-all-cloud-trial-EXA-dr-1605216&utm_content=text-ad-none-none-DEV_c-CRE_634320416384-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt+-GCP-General-google+cloud+account-how-KWID_43700074200360382-kwd-310570337956&userloc_9062101-network_g&utm_term=KW_how+to+create+google+cloud+account&gad_source=1&gclid=Cj0KCQjw2PSvBhDjARIsAKc2cgOOL7cfu4LRkX9-nIT7sVizw8ubKIl2aYUXkAdbxxFnXpHo6lYk7CAaAiTNEALw_wcB&gclsrc=aw.ds&hl=en\">here</a>.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Connect to Vantage</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/jovyan/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from teradataml import *\n",
    "from tdapiclient import create_tdapi_context, TDApiClient, remove_tdapi_context\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "configure.byom_install_location = \"mldb\"\n",
    "configure.val_install_location = \"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing setup ...\n",
      "Setup complete\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter password:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logon successful\n",
      "Connected as: xxxxxsql://demo_user:xxxxx@host.docker.internal/dbc\n",
      "Engine(teradatasql://demo_user:***@host.docker.internal)\n"
     ]
    }
   ],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=CancerPrediction_TDApiClient_VertexAI_CustomModel.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That ran for   0:00:10.62 with 10 statements and 0 errors. \n"
     ]
    }
   ],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_CancerPrediction_cloud');\"\n",
    " # Takes about 50 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_CancerPrediction_local');\"\n",
    " # Takes about 2 minute 30 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional step â We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have:  #databases=6 #tables=58 #views=13  You have used 369.9 MB of 30,683.0 MB available - 1.2%  ... Space Usage OK\n",
      " \n",
      "   Database Name                  #tables  #views     Avail MB      Used MB\n",
      "   demo_user                           48       4  27,435.7 MB      84.6 MB \n",
      "   DEMO_CancerPrediction                0       1       0.0 MB       0.0 MB \n",
      "   DEMO_CancerPrediction_db             1       0     534.9 MB       0.3 MB \n",
      "   DEMO_Financial                       0       7       0.0 MB       0.0 MB \n",
      "   DEMO_Financial_db                    7       0   2,442.2 MB     266.1 MB \n",
      "   DEMO_ShipTimePred                    0       1       0.0 MB       0.0 MB \n",
      "   DEMO_ShipTimePred_db                 2       0     270.2 MB      18.9 MB \n"
     ]
    }
   ],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Analyze the raw data set</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let us start by creating a teradataml dataframe. A \"Virtual DataFrame\" that points directly to the dataset in Vantage.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>diagnosis</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91544002</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>11.06</td>\n",
       "\t\t<td>17.12</td>\n",
       "\t\t<td>71.25</td>\n",
       "\t\t<td>366.5</td>\n",
       "\t\t<td>0.1194</td>\n",
       "\t\t<td>0.1071</td>\n",
       "\t\t<td>0.04063</td>\n",
       "\t\t<td>0.04268</td>\n",
       "\t\t<td>0.1954</td>\n",
       "\t\t<td>0.07976</td>\n",
       "\t\t<td>0.1779</td>\n",
       "\t\t<td>1.03</td>\n",
       "\t\t<td>1.318</td>\n",
       "\t\t<td>12.3</td>\n",
       "\t\t<td>0.01262</td>\n",
       "\t\t<td>0.02348</td>\n",
       "\t\t<td>0.018</td>\n",
       "\t\t<td>0.01285</td>\n",
       "\t\t<td>0.0222</td>\n",
       "\t\t<td>0.008313</td>\n",
       "\t\t<td>11.69</td>\n",
       "\t\t<td>20.74</td>\n",
       "\t\t<td>76.08</td>\n",
       "\t\t<td>411.1</td>\n",
       "\t\t<td>0.1662</td>\n",
       "\t\t<td>0.2031</td>\n",
       "\t\t<td>0.1256</td>\n",
       "\t\t<td>0.09514</td>\n",
       "\t\t<td>0.278</td>\n",
       "\t\t<td>0.1168</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>905686</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>11.89</td>\n",
       "\t\t<td>21.17</td>\n",
       "\t\t<td>76.39</td>\n",
       "\t\t<td>433.8</td>\n",
       "\t\t<td>0.09773</td>\n",
       "\t\t<td>0.0812</td>\n",
       "\t\t<td>0.02555</td>\n",
       "\t\t<td>0.02179</td>\n",
       "\t\t<td>0.2019</td>\n",
       "\t\t<td>0.0629</td>\n",
       "\t\t<td>0.2747</td>\n",
       "\t\t<td>1.203</td>\n",
       "\t\t<td>1.93</td>\n",
       "\t\t<td>19.53</td>\n",
       "\t\t<td>0.009895</td>\n",
       "\t\t<td>0.03053</td>\n",
       "\t\t<td>0.0163</td>\n",
       "\t\t<td>0.009276</td>\n",
       "\t\t<td>0.02258</td>\n",
       "\t\t<td>0.002272</td>\n",
       "\t\t<td>13.05</td>\n",
       "\t\t<td>27.21</td>\n",
       "\t\t<td>85.09</td>\n",
       "\t\t<td>522.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2187</td>\n",
       "\t\t<td>0.1164</td>\n",
       "\t\t<td>0.08263</td>\n",
       "\t\t<td>0.3075</td>\n",
       "\t\t<td>0.07351</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>863270</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>12.36</td>\n",
       "\t\t<td>18.54</td>\n",
       "\t\t<td>79.01</td>\n",
       "\t\t<td>466.7</td>\n",
       "\t\t<td>0.08477</td>\n",
       "\t\t<td>0.06815</td>\n",
       "\t\t<td>0.02643</td>\n",
       "\t\t<td>0.01921</td>\n",
       "\t\t<td>0.1602</td>\n",
       "\t\t<td>0.06066</td>\n",
       "\t\t<td>0.1199</td>\n",
       "\t\t<td>0.8944</td>\n",
       "\t\t<td>0.8484</td>\n",
       "\t\t<td>9.227</td>\n",
       "\t\t<td>0.003457</td>\n",
       "\t\t<td>0.01047</td>\n",
       "\t\t<td>0.01167</td>\n",
       "\t\t<td>0.005558</td>\n",
       "\t\t<td>0.01251</td>\n",
       "\t\t<td>0.001356</td>\n",
       "\t\t<td>13.29</td>\n",
       "\t\t<td>27.49</td>\n",
       "\t\t<td>85.56</td>\n",
       "\t\t<td>544.1</td>\n",
       "\t\t<td>0.1184</td>\n",
       "\t\t<td>0.1963</td>\n",
       "\t\t<td>0.1937</td>\n",
       "\t\t<td>0.08442</td>\n",
       "\t\t<td>0.2983</td>\n",
       "\t\t<td>0.07185</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>89742801</td>\n",
       "\t\t<td>M </td>\n",
       "\t\t<td>17.06</td>\n",
       "\t\t<td>21.0</td>\n",
       "\t\t<td>111.8</td>\n",
       "\t\t<td>918.6</td>\n",
       "\t\t<td>0.1119</td>\n",
       "\t\t<td>0.1056</td>\n",
       "\t\t<td>0.1508</td>\n",
       "\t\t<td>0.09934</td>\n",
       "\t\t<td>0.1727</td>\n",
       "\t\t<td>0.06071</td>\n",
       "\t\t<td>0.8161</td>\n",
       "\t\t<td>2.129</td>\n",
       "\t\t<td>6.076</td>\n",
       "\t\t<td>87.17</td>\n",
       "\t\t<td>0.006455</td>\n",
       "\t\t<td>0.01797</td>\n",
       "\t\t<td>0.04502</td>\n",
       "\t\t<td>0.01744</td>\n",
       "\t\t<td>0.01829</td>\n",
       "\t\t<td>0.003733</td>\n",
       "\t\t<td>20.99</td>\n",
       "\t\t<td>33.15</td>\n",
       "\t\t<td>143.2</td>\n",
       "\t\t<td>1362.0</td>\n",
       "\t\t<td>0.1449</td>\n",
       "\t\t<td>0.2053</td>\n",
       "\t\t<td>0.392</td>\n",
       "\t\t<td>0.1827</td>\n",
       "\t\t<td>0.2623</td>\n",
       "\t\t<td>0.07599</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>869224</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>12.9</td>\n",
       "\t\t<td>15.92</td>\n",
       "\t\t<td>83.74</td>\n",
       "\t\t<td>512.2</td>\n",
       "\t\t<td>0.08677</td>\n",
       "\t\t<td>0.09509</td>\n",
       "\t\t<td>0.04894</td>\n",
       "\t\t<td>0.03088</td>\n",
       "\t\t<td>0.1778</td>\n",
       "\t\t<td>0.06235</td>\n",
       "\t\t<td>0.2143</td>\n",
       "\t\t<td>0.7712</td>\n",
       "\t\t<td>1.689</td>\n",
       "\t\t<td>16.64</td>\n",
       "\t\t<td>0.005324</td>\n",
       "\t\t<td>0.01563</td>\n",
       "\t\t<td>0.0151</td>\n",
       "\t\t<td>0.007584</td>\n",
       "\t\t<td>0.02104</td>\n",
       "\t\t<td>0.001887</td>\n",
       "\t\t<td>14.48</td>\n",
       "\t\t<td>21.82</td>\n",
       "\t\t<td>97.17</td>\n",
       "\t\t<td>643.8</td>\n",
       "\t\t<td>0.1312</td>\n",
       "\t\t<td>0.2548</td>\n",
       "\t\t<td>0.209</td>\n",
       "\t\t<td>0.1012</td>\n",
       "\t\t<td>0.3549</td>\n",
       "\t\t<td>0.08118</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9013579</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>13.46</td>\n",
       "\t\t<td>28.21</td>\n",
       "\t\t<td>85.89</td>\n",
       "\t\t<td>562.1</td>\n",
       "\t\t<td>0.07517</td>\n",
       "\t\t<td>0.04726</td>\n",
       "\t\t<td>0.01271</td>\n",
       "\t\t<td>0.01117</td>\n",
       "\t\t<td>0.1421</td>\n",
       "\t\t<td>0.05763</td>\n",
       "\t\t<td>0.1689</td>\n",
       "\t\t<td>1.15</td>\n",
       "\t\t<td>1.4</td>\n",
       "\t\t<td>14.91</td>\n",
       "\t\t<td>0.004942</td>\n",
       "\t\t<td>0.01203</td>\n",
       "\t\t<td>0.007508</td>\n",
       "\t\t<td>0.005179</td>\n",
       "\t\t<td>0.01442</td>\n",
       "\t\t<td>0.001684</td>\n",
       "\t\t<td>14.69</td>\n",
       "\t\t<td>35.63</td>\n",
       "\t\t<td>97.11</td>\n",
       "\t\t<td>680.6</td>\n",
       "\t\t<td>0.1108</td>\n",
       "\t\t<td>0.1457</td>\n",
       "\t\t<td>0.07934</td>\n",
       "\t\t<td>0.05781</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.07061</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9012315</td>\n",
       "\t\t<td>M </td>\n",
       "\t\t<td>16.35</td>\n",
       "\t\t<td>23.29</td>\n",
       "\t\t<td>109.0</td>\n",
       "\t\t<td>840.4</td>\n",
       "\t\t<td>0.09742</td>\n",
       "\t\t<td>0.1497</td>\n",
       "\t\t<td>0.1811</td>\n",
       "\t\t<td>0.08773</td>\n",
       "\t\t<td>0.2175</td>\n",
       "\t\t<td>0.06218</td>\n",
       "\t\t<td>0.4312</td>\n",
       "\t\t<td>1.022</td>\n",
       "\t\t<td>2.972</td>\n",
       "\t\t<td>45.5</td>\n",
       "\t\t<td>0.005635</td>\n",
       "\t\t<td>0.03917</td>\n",
       "\t\t<td>0.06072</td>\n",
       "\t\t<td>0.01656</td>\n",
       "\t\t<td>0.03197</td>\n",
       "\t\t<td>0.004085</td>\n",
       "\t\t<td>19.38</td>\n",
       "\t\t<td>31.03</td>\n",
       "\t\t<td>129.3</td>\n",
       "\t\t<td>1165.0</td>\n",
       "\t\t<td>0.1415</td>\n",
       "\t\t<td>0.4665</td>\n",
       "\t\t<td>0.7087</td>\n",
       "\t\t<td>0.2248</td>\n",
       "\t\t<td>0.4824</td>\n",
       "\t\t<td>0.09614</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>901303</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>16.17</td>\n",
       "\t\t<td>16.07</td>\n",
       "\t\t<td>106.3</td>\n",
       "\t\t<td>788.5</td>\n",
       "\t\t<td>0.0988</td>\n",
       "\t\t<td>0.1438</td>\n",
       "\t\t<td>0.06651</td>\n",
       "\t\t<td>0.05397</td>\n",
       "\t\t<td>0.199</td>\n",
       "\t\t<td>0.06572</td>\n",
       "\t\t<td>0.1745</td>\n",
       "\t\t<td>0.489</td>\n",
       "\t\t<td>1.349</td>\n",
       "\t\t<td>14.91</td>\n",
       "\t\t<td>0.00451</td>\n",
       "\t\t<td>0.01812</td>\n",
       "\t\t<td>0.01951</td>\n",
       "\t\t<td>0.01196</td>\n",
       "\t\t<td>0.01934</td>\n",
       "\t\t<td>0.003696</td>\n",
       "\t\t<td>16.97</td>\n",
       "\t\t<td>19.14</td>\n",
       "\t\t<td>113.1</td>\n",
       "\t\t<td>861.5</td>\n",
       "\t\t<td>0.1235</td>\n",
       "\t\t<td>0.255</td>\n",
       "\t\t<td>0.2114</td>\n",
       "\t\t<td>0.1251</td>\n",
       "\t\t<td>0.3153</td>\n",
       "\t\t<td>0.0896</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>87930</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>12.47</td>\n",
       "\t\t<td>18.6</td>\n",
       "\t\t<td>81.09</td>\n",
       "\t\t<td>481.9</td>\n",
       "\t\t<td>0.09965</td>\n",
       "\t\t<td>0.1058</td>\n",
       "\t\t<td>0.08005</td>\n",
       "\t\t<td>0.03821</td>\n",
       "\t\t<td>0.1925</td>\n",
       "\t\t<td>0.06373</td>\n",
       "\t\t<td>0.3961</td>\n",
       "\t\t<td>1.044</td>\n",
       "\t\t<td>2.497</td>\n",
       "\t\t<td>30.29</td>\n",
       "\t\t<td>0.006953</td>\n",
       "\t\t<td>0.01911</td>\n",
       "\t\t<td>0.02701</td>\n",
       "\t\t<td>0.01037</td>\n",
       "\t\t<td>0.01782</td>\n",
       "\t\t<td>0.003586</td>\n",
       "\t\t<td>14.97</td>\n",
       "\t\t<td>24.64</td>\n",
       "\t\t<td>96.05</td>\n",
       "\t\t<td>677.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2378</td>\n",
       "\t\t<td>0.2671</td>\n",
       "\t\t<td>0.1015</td>\n",
       "\t\t<td>0.3014</td>\n",
       "\t\t<td>0.0875</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "91544002        B         11.06         17.12           71.25      366.5          0.11940           0.10710         0.04063              0.04268         0.1954                 0.07976     0.1779      1.0300        1.3180   12.300       0.012620        0.023480      0.018000           0.012850      0.02220              0.008313         11.69          20.74            76.08       411.1            0.1662            0.20310          0.12560               0.09514          0.2780                  0.11680\n",
       "905686          B         11.89         21.17           76.39      433.8          0.09773           0.08120         0.02555              0.02179         0.2019                 0.06290     0.2747      1.2030        1.9300   19.530       0.009895        0.030530      0.016300           0.009276      0.02258              0.002272         13.05          27.21            85.09       522.9            0.1426            0.21870          0.11640               0.08263          0.3075                  0.07351\n",
       "863270          B         12.36         18.54           79.01      466.7          0.08477           0.06815         0.02643              0.01921         0.1602                 0.06066     0.1199      0.8944        0.8484    9.227       0.003457        0.010470      0.011670           0.005558      0.01251              0.001356         13.29          27.49            85.56       544.1            0.1184            0.19630          0.19370               0.08442          0.2983                  0.07185\n",
       "89742801        M         17.06         21.00          111.80      918.6          0.11190           0.10560         0.15080              0.09934         0.1727                 0.06071     0.8161      2.1290        6.0760   87.170       0.006455        0.017970      0.045020           0.017440      0.01829              0.003733         20.99          33.15           143.20      1362.0            0.1449            0.20530          0.39200               0.18270          0.2623                  0.07599\n",
       "869224          B         12.90         15.92           83.74      512.2          0.08677           0.09509         0.04894              0.03088         0.1778                 0.06235     0.2143      0.7712        1.6890   16.640       0.005324        0.015630      0.015100           0.007584      0.02104              0.001887         14.48          21.82            97.17       643.8            0.1312            0.25480          0.20900               0.10120          0.3549                  0.08118\n",
       "9013579         B         13.46         28.21           85.89      562.1          0.07517           0.04726         0.01271              0.01117         0.1421                 0.05763     0.1689      1.1500        1.4000   14.910       0.004942        0.012030      0.007508           0.005179      0.01442              0.001684         14.69          35.63            97.11       680.6            0.1108            0.14570          0.07934               0.05781          0.2694                  0.07061\n",
       "9012315         M         16.35         23.29          109.00      840.4          0.09742           0.14970         0.18110              0.08773         0.2175                 0.06218     0.4312      1.0220        2.9720   45.500       0.005635        0.039170      0.060720           0.016560      0.03197              0.004085         19.38          31.03           129.30      1165.0            0.1415            0.46650          0.70870               0.22480          0.4824                  0.09614\n",
       "862965          B         12.18         20.52           77.22      458.7          0.08013           0.04038         0.02383              0.01770         0.1739                 0.05677     0.1924      1.5710        1.1830   14.680       0.005080        0.006098      0.010690           0.006797      0.01447              0.001532         13.34          32.84            84.58       547.8            0.1123            0.08862          0.11450               0.07431          0.2694                  0.06878\n",
       "901303          B         16.17         16.07          106.30      788.5          0.09880           0.14380         0.06651              0.05397         0.1990                 0.06572     0.1745      0.4890        1.3490   14.910       0.004510        0.018120      0.019510           0.011960      0.01934              0.003696         16.97          19.14           113.10       861.5            0.1235            0.25500          0.21140               0.12510          0.3153                  0.08960\n",
       "87930           B         12.47         18.60           81.09      481.9          0.09965           0.10580         0.08005              0.03821         0.1925                 0.06373     0.3961      1.0440        2.4970   30.290       0.006953        0.019110      0.027010           0.010370      0.01782              0.003586         14.97          24.64            96.05       677.9            0.1426            0.23780          0.26710               0.10150          0.3014                  0.08750"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a teradataml dataframe using the table.\n",
    "df = DataFrame(in_schema(\"DEMO_CancerPrediction\",\"Patient_Data\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5. Data Preparation</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Label encoding a categorical data column is done to re-express existing values of a column (variable) into a new coding scheme or to correct data quality problems and focus an analysis of a particular value. It allows\n",
    "    for mapping individual values, NULL values, or any number of remaining values (ELSE option) to a new value, a NULL value or the same value. Label encoding supports charter, numeric, and date type columns.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Output of this function is passed to \"label_encode\" argument of \"Transform\" function from Vantage Analytic Library.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target column using label encoder.\n",
    "from teradataml import LabelEncoder \n",
    "rc = LabelEncoder(values=(\"M\", 1), columns=[\"diagnosis\"], default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_names= Retain(columns=[\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\n",
    "                                       \"compactness_mean\",\"concavity_mean\",\"concave_points_mean\",\"symmetry_mean\",\n",
    "                                       \"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\n",
    "                                       \"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave_points_se\",\n",
    "                                       \"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\n",
    "                                       \"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\n",
    "                                       \"concavity_worst\",\"concave_points_worst\",\"symmetry_worst\",\n",
    "                                       \"fractal_dimension_worst\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> The Variable Transformation analysis reads a teradataml DataFrame and produces an output containing transformed columns. This is useful when preparing data for input to an analytic algorithm. For example, a K-Means Clustering algorithm typically produces better results when the input columns are first converted to their Z-Score values to put all input variables on an equal footing, regardless of their magnitude.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Function supports following transformations:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Binning</code> - Binning replaces a continuous numeric column with a categorical one to produce ordinal values (for example, numeric categorical values where order is meaningful).</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Derive</code> - The Derive transformation requires the free-form transformation be specified as a formula.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>One Hot Encoding</code> - One Hot Encoding is useful when a categorical data element must be re-expressed as one or more numeric data elements, creating a binary numeric field for each categorical data value.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Missing Value</code> Treatment or Null Replacement.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Label Encoding</code> - Allows to re-express existing values of a categorical data column (variable) into a new coding scheme or to correct data quality problems and focus an analysis on a value.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Min-Max Scaling</code> - Limits the upper and lower boundaries of the data in a continuous numeric column using a linear rescaling function based on maximum and minimum data values.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Retain</code> - Allows copying of one or more columns into the final analytic data set.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Sigmoid</code> - Provides rescaling of continuous numeric data using a type of sigmoid or s-shaped function.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>ZScore</code> - Provides rescaling of continuous numeric data using Z-Scores.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we will be using the Lable Encode option for the diagnosis column</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>diagnosis</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>914862</td>\n",
       "\t\t<td>15.04</td>\n",
       "\t\t<td>16.74</td>\n",
       "\t\t<td>98.73</td>\n",
       "\t\t<td>689.4</td>\n",
       "\t\t<td>0.09883</td>\n",
       "\t\t<td>0.1364</td>\n",
       "\t\t<td>0.07721</td>\n",
       "\t\t<td>0.06142</td>\n",
       "\t\t<td>0.1668</td>\n",
       "\t\t<td>0.06869</td>\n",
       "\t\t<td>0.372</td>\n",
       "\t\t<td>0.8423</td>\n",
       "\t\t<td>2.304</td>\n",
       "\t\t<td>34.84</td>\n",
       "\t\t<td>0.004123</td>\n",
       "\t\t<td>0.01819</td>\n",
       "\t\t<td>0.01996</td>\n",
       "\t\t<td>0.01004</td>\n",
       "\t\t<td>0.01055</td>\n",
       "\t\t<td>0.003237</td>\n",
       "\t\t<td>16.76</td>\n",
       "\t\t<td>20.43</td>\n",
       "\t\t<td>109.7</td>\n",
       "\t\t<td>856.9</td>\n",
       "\t\t<td>0.1135</td>\n",
       "\t\t<td>0.2176</td>\n",
       "\t\t<td>0.1856</td>\n",
       "\t\t<td>0.1018</td>\n",
       "\t\t<td>0.2177</td>\n",
       "\t\t<td>0.08549</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>88249602</td>\n",
       "\t\t<td>14.03</td>\n",
       "\t\t<td>21.25</td>\n",
       "\t\t<td>89.79</td>\n",
       "\t\t<td>603.4</td>\n",
       "\t\t<td>0.0907</td>\n",
       "\t\t<td>0.06945</td>\n",
       "\t\t<td>0.01462</td>\n",
       "\t\t<td>0.01896</td>\n",
       "\t\t<td>0.1517</td>\n",
       "\t\t<td>0.05835</td>\n",
       "\t\t<td>0.2589</td>\n",
       "\t\t<td>1.503</td>\n",
       "\t\t<td>1.667</td>\n",
       "\t\t<td>22.07</td>\n",
       "\t\t<td>0.007389</td>\n",
       "\t\t<td>0.01383</td>\n",
       "\t\t<td>0.007302</td>\n",
       "\t\t<td>0.01004</td>\n",
       "\t\t<td>0.01263</td>\n",
       "\t\t<td>0.002925</td>\n",
       "\t\t<td>15.33</td>\n",
       "\t\t<td>30.28</td>\n",
       "\t\t<td>98.27</td>\n",
       "\t\t<td>715.5</td>\n",
       "\t\t<td>0.1287</td>\n",
       "\t\t<td>0.1513</td>\n",
       "\t\t<td>0.06231</td>\n",
       "\t\t<td>0.07963</td>\n",
       "\t\t<td>0.2226</td>\n",
       "\t\t<td>0.07617</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>855133</td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t\t<td>1.214</td>\n",
       "\t\t<td>2.188</td>\n",
       "\t\t<td>8.077</td>\n",
       "\t\t<td>106.0</td>\n",
       "\t\t<td>0.006883</td>\n",
       "\t\t<td>0.01094</td>\n",
       "\t\t<td>0.01818</td>\n",
       "\t\t<td>0.01917</td>\n",
       "\t\t<td>0.007882</td>\n",
       "\t\t<td>0.001754</td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t\t<td>1  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>8711003</td>\n",
       "\t\t<td>12.25</td>\n",
       "\t\t<td>17.94</td>\n",
       "\t\t<td>78.27</td>\n",
       "\t\t<td>460.3</td>\n",
       "\t\t<td>0.08654</td>\n",
       "\t\t<td>0.06679</td>\n",
       "\t\t<td>0.03885</td>\n",
       "\t\t<td>0.02331</td>\n",
       "\t\t<td>0.197</td>\n",
       "\t\t<td>0.06228</td>\n",
       "\t\t<td>0.22</td>\n",
       "\t\t<td>0.9823</td>\n",
       "\t\t<td>1.484</td>\n",
       "\t\t<td>16.51</td>\n",
       "\t\t<td>0.005518</td>\n",
       "\t\t<td>0.01562</td>\n",
       "\t\t<td>0.01994</td>\n",
       "\t\t<td>0.007924</td>\n",
       "\t\t<td>0.01799</td>\n",
       "\t\t<td>0.002484</td>\n",
       "\t\t<td>13.59</td>\n",
       "\t\t<td>25.22</td>\n",
       "\t\t<td>86.6</td>\n",
       "\t\t<td>564.2</td>\n",
       "\t\t<td>0.1217</td>\n",
       "\t\t<td>0.1788</td>\n",
       "\t\t<td>0.1943</td>\n",
       "\t\t<td>0.08211</td>\n",
       "\t\t<td>0.3113</td>\n",
       "\t\t<td>0.08132</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>872608</td>\n",
       "\t\t<td>9.904</td>\n",
       "\t\t<td>18.06</td>\n",
       "\t\t<td>64.6</td>\n",
       "\t\t<td>302.4</td>\n",
       "\t\t<td>0.09699</td>\n",
       "\t\t<td>0.1294</td>\n",
       "\t\t<td>0.1307</td>\n",
       "\t\t<td>0.03716</td>\n",
       "\t\t<td>0.1669</td>\n",
       "\t\t<td>0.08116</td>\n",
       "\t\t<td>0.4311</td>\n",
       "\t\t<td>2.261</td>\n",
       "\t\t<td>3.132</td>\n",
       "\t\t<td>27.48</td>\n",
       "\t\t<td>0.01286</td>\n",
       "\t\t<td>0.08808</td>\n",
       "\t\t<td>0.1197</td>\n",
       "\t\t<td>0.0246</td>\n",
       "\t\t<td>0.0388</td>\n",
       "\t\t<td>0.01792</td>\n",
       "\t\t<td>11.26</td>\n",
       "\t\t<td>24.39</td>\n",
       "\t\t<td>73.07</td>\n",
       "\t\t<td>390.2</td>\n",
       "\t\t<td>0.1301</td>\n",
       "\t\t<td>0.295</td>\n",
       "\t\t<td>0.3486</td>\n",
       "\t\t<td>0.0991</td>\n",
       "\t\t<td>0.2614</td>\n",
       "\t\t<td>0.1162</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>858986</td>\n",
       "\t\t<td>14.25</td>\n",
       "\t\t<td>22.15</td>\n",
       "\t\t<td>96.42</td>\n",
       "\t\t<td>645.7</td>\n",
       "\t\t<td>0.1049</td>\n",
       "\t\t<td>0.2008</td>\n",
       "\t\t<td>0.2135</td>\n",
       "\t\t<td>0.08653</td>\n",
       "\t\t<td>0.1949</td>\n",
       "\t\t<td>0.07292</td>\n",
       "\t\t<td>0.7036</td>\n",
       "\t\t<td>1.268</td>\n",
       "\t\t<td>5.373</td>\n",
       "\t\t<td>60.78</td>\n",
       "\t\t<td>0.009407</td>\n",
       "\t\t<td>0.07056</td>\n",
       "\t\t<td>0.06899</td>\n",
       "\t\t<td>0.01848</td>\n",
       "\t\t<td>0.017</td>\n",
       "\t\t<td>0.006113</td>\n",
       "\t\t<td>17.67</td>\n",
       "\t\t<td>29.51</td>\n",
       "\t\t<td>119.1</td>\n",
       "\t\t<td>959.5</td>\n",
       "\t\t<td>0.164</td>\n",
       "\t\t<td>0.6247</td>\n",
       "\t\t<td>0.6922</td>\n",
       "\t\t<td>0.1785</td>\n",
       "\t\t<td>0.2844</td>\n",
       "\t\t<td>0.1132</td>\n",
       "\t\t<td>1  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>90317302</td>\n",
       "\t\t<td>10.26</td>\n",
       "\t\t<td>12.22</td>\n",
       "\t\t<td>65.75</td>\n",
       "\t\t<td>321.6</td>\n",
       "\t\t<td>0.09996</td>\n",
       "\t\t<td>0.07542</td>\n",
       "\t\t<td>0.01923</td>\n",
       "\t\t<td>0.01968</td>\n",
       "\t\t<td>0.18</td>\n",
       "\t\t<td>0.06569</td>\n",
       "\t\t<td>0.1911</td>\n",
       "\t\t<td>0.5477</td>\n",
       "\t\t<td>1.348</td>\n",
       "\t\t<td>11.88</td>\n",
       "\t\t<td>0.005682</td>\n",
       "\t\t<td>0.01365</td>\n",
       "\t\t<td>0.008496</td>\n",
       "\t\t<td>0.006929</td>\n",
       "\t\t<td>0.01938</td>\n",
       "\t\t<td>0.002371</td>\n",
       "\t\t<td>11.38</td>\n",
       "\t\t<td>15.65</td>\n",
       "\t\t<td>73.23</td>\n",
       "\t\t<td>394.5</td>\n",
       "\t\t<td>0.1343</td>\n",
       "\t\t<td>0.165</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.06696</td>\n",
       "\t\t<td>0.2937</td>\n",
       "\t\t<td>0.07722</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>85713702</td>\n",
       "\t\t<td>8.196</td>\n",
       "\t\t<td>16.84</td>\n",
       "\t\t<td>51.71</td>\n",
       "\t\t<td>201.9</td>\n",
       "\t\t<td>0.086</td>\n",
       "\t\t<td>0.05943</td>\n",
       "\t\t<td>0.01588</td>\n",
       "\t\t<td>0.005917</td>\n",
       "\t\t<td>0.1769</td>\n",
       "\t\t<td>0.06503</td>\n",
       "\t\t<td>0.1563</td>\n",
       "\t\t<td>0.9567</td>\n",
       "\t\t<td>1.094</td>\n",
       "\t\t<td>8.205</td>\n",
       "\t\t<td>0.008968</td>\n",
       "\t\t<td>0.01646</td>\n",
       "\t\t<td>0.01588</td>\n",
       "\t\t<td>0.005917</td>\n",
       "\t\t<td>0.02574</td>\n",
       "\t\t<td>0.002582</td>\n",
       "\t\t<td>8.964</td>\n",
       "\t\t<td>21.96</td>\n",
       "\t\t<td>57.26</td>\n",
       "\t\t<td>242.2</td>\n",
       "\t\t<td>0.1297</td>\n",
       "\t\t<td>0.1357</td>\n",
       "\t\t<td>0.0688</td>\n",
       "\t\t<td>0.02564</td>\n",
       "\t\t<td>0.3105</td>\n",
       "\t\t<td>0.07409</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>852973</td>\n",
       "\t\t<td>15.3</td>\n",
       "\t\t<td>25.27</td>\n",
       "\t\t<td>102.4</td>\n",
       "\t\t<td>732.4</td>\n",
       "\t\t<td>0.1082</td>\n",
       "\t\t<td>0.1697</td>\n",
       "\t\t<td>0.1683</td>\n",
       "\t\t<td>0.08751</td>\n",
       "\t\t<td>0.1926</td>\n",
       "\t\t<td>0.0654</td>\n",
       "\t\t<td>0.439</td>\n",
       "\t\t<td>1.012</td>\n",
       "\t\t<td>3.498</td>\n",
       "\t\t<td>43.5</td>\n",
       "\t\t<td>0.005233</td>\n",
       "\t\t<td>0.03057</td>\n",
       "\t\t<td>0.03576</td>\n",
       "\t\t<td>0.01083</td>\n",
       "\t\t<td>0.01768</td>\n",
       "\t\t<td>0.002967</td>\n",
       "\t\t<td>20.27</td>\n",
       "\t\t<td>36.71</td>\n",
       "\t\t<td>149.3</td>\n",
       "\t\t<td>1269.0</td>\n",
       "\t\t<td>0.1641</td>\n",
       "\t\t<td>0.611</td>\n",
       "\t\t<td>0.6335</td>\n",
       "\t\t<td>0.2024</td>\n",
       "\t\t<td>0.4027</td>\n",
       "\t\t<td>0.09876</td>\n",
       "\t\t<td>1  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>869104</td>\n",
       "\t\t<td>16.11</td>\n",
       "\t\t<td>18.05</td>\n",
       "\t\t<td>105.1</td>\n",
       "\t\t<td>813.0</td>\n",
       "\t\t<td>0.09721</td>\n",
       "\t\t<td>0.1137</td>\n",
       "\t\t<td>0.09447</td>\n",
       "\t\t<td>0.05943</td>\n",
       "\t\t<td>0.1861</td>\n",
       "\t\t<td>0.06248</td>\n",
       "\t\t<td>0.7049</td>\n",
       "\t\t<td>1.332</td>\n",
       "\t\t<td>4.533</td>\n",
       "\t\t<td>74.08</td>\n",
       "\t\t<td>0.00677</td>\n",
       "\t\t<td>0.01938</td>\n",
       "\t\t<td>0.03067</td>\n",
       "\t\t<td>0.01167</td>\n",
       "\t\t<td>0.01875</td>\n",
       "\t\t<td>0.003434</td>\n",
       "\t\t<td>19.92</td>\n",
       "\t\t<td>25.27</td>\n",
       "\t\t<td>129.0</td>\n",
       "\t\t<td>1233.0</td>\n",
       "\t\t<td>0.1314</td>\n",
       "\t\t<td>0.2236</td>\n",
       "\t\t<td>0.2802</td>\n",
       "\t\t<td>0.1216</td>\n",
       "\t\t<td>0.2792</td>\n",
       "\t\t<td>0.08158</td>\n",
       "\t\t<td>1  </td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "         id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst diagnosis\n",
       "0    914862       15.040         16.74           98.73      689.4          0.09883           0.13640         0.07721             0.061420         0.1668                 0.06869     0.3720      0.8423         2.304   34.840       0.004123         0.01819      0.019960           0.010040     0.010550              0.003237        16.760          20.43           109.70       856.9           0.11350            0.21760          0.18560               0.10180          0.2177                  0.08549       0  \n",
       "1  88249602       14.030         21.25           89.79      603.4          0.09070           0.06945         0.01462             0.018960         0.1517                 0.05835     0.2589      1.5030         1.667   22.070       0.007389         0.01383      0.007302           0.010040     0.012630              0.002925        15.330          30.28            98.27       715.5           0.12870            0.15130          0.06231               0.07963          0.2226                  0.07617       0  \n",
       "2    855133       14.990         25.20           95.54      698.8          0.09387           0.05131         0.02398             0.028990         0.1565                 0.05504     1.2140      2.1880         8.077  106.000       0.006883         0.01094      0.018180           0.019170     0.007882              0.001754        14.990          25.20            95.54       698.8           0.09387            0.05131          0.02398               0.02899          0.1565                  0.05504       1  \n",
       "3   8711003       12.250         17.94           78.27      460.3          0.08654           0.06679         0.03885             0.023310         0.1970                 0.06228     0.2200      0.9823         1.484   16.510       0.005518         0.01562      0.019940           0.007924     0.017990              0.002484        13.590          25.22            86.60       564.2           0.12170            0.17880          0.19430               0.08211          0.3113                  0.08132       0  \n",
       "4    872608        9.904         18.06           64.60      302.4          0.09699           0.12940         0.13070             0.037160         0.1669                 0.08116     0.4311      2.2610         3.132   27.480       0.012860         0.08808      0.119700           0.024600     0.038800              0.017920        11.260          24.39            73.07       390.2           0.13010            0.29500          0.34860               0.09910          0.2614                  0.11620       0  \n",
       "5    858986       14.250         22.15           96.42      645.7          0.10490           0.20080         0.21350             0.086530         0.1949                 0.07292     0.7036      1.2680         5.373   60.780       0.009407         0.07056      0.068990           0.018480     0.017000              0.006113        17.670          29.51           119.10       959.5           0.16400            0.62470          0.69220               0.17850          0.2844                  0.11320       1  \n",
       "6  90317302       10.260         12.22           65.75      321.6          0.09996           0.07542         0.01923             0.019680         0.1800                 0.06569     0.1911      0.5477         1.348   11.880       0.005682         0.01365      0.008496           0.006929     0.019380              0.002371        11.380          15.65            73.23       394.5           0.13430            0.16500          0.08615               0.06696          0.2937                  0.07722       0  \n",
       "7  85713702        8.196         16.84           51.71      201.9          0.08600           0.05943         0.01588             0.005917         0.1769                 0.06503     0.1563      0.9567         1.094    8.205       0.008968         0.01646      0.015880           0.005917     0.025740              0.002582         8.964          21.96            57.26       242.2           0.12970            0.13570          0.06880               0.02564          0.3105                  0.07409       0  \n",
       "8    852973       15.300         25.27          102.40      732.4          0.10820           0.16970         0.16830             0.087510         0.1926                 0.06540     0.4390      1.0120         3.498   43.500       0.005233         0.03057      0.035760           0.010830     0.017680              0.002967        20.270          36.71           149.30      1269.0           0.16410            0.61100          0.63350               0.20240          0.4027                  0.09876       1  \n",
       "9    869104       16.110         18.05          105.10      813.0          0.09721           0.11370         0.09447             0.059430         0.1861                 0.06248     0.7049      1.3320         4.533   74.080       0.006770         0.01938      0.030670           0.011670     0.018750              0.003434        19.920          25.27           129.00      1233.0           0.13140            0.22360          0.28020               0.12160          0.2792                  0.08158       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = valib.Transform(data=df, label_encode=rc,index_columns=\"id\",unique_index=True,retain=feature_columns_names)\n",
    "df=data.result\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We use the sample function on teradataml dataframe. This function allows to sample few rows from dataframe directly or based on conditions. It creates a new column 'sampleid' which has a unique id for each sample, it helps to uniquely identify each sample.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result data stored in table '\"DEMO_USER\".\"ml__td_sqlmr_persist_out__1718700152370932\"'\n"
     ]
    }
   ],
   "source": [
    "# Create 2 samples of input data - sample 1 will have 80% of total rows and sample 2  will have 20% of total rows.\n",
    "cancer_sample = df.sample(frac=[0.80, 0.20], seed=42, id_column=\"id\")\n",
    "df_train = cancer_sample[cancer_sample.sampleid == \"1\"].drop(\"sampleid\", axis = 1)\n",
    "df_test = cancer_sample[cancer_sample.sampleid == \"2\"].drop(\"sampleid\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>6. Setup TDApiClient and Teradata contexts for Google Vertex AI</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Google Vertex AI teradataml extension library (TDApiClient) uses Vantage DataFrame to train Google Vertex AI models.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Enable users to prepare the training data by leveraging Teradataâs Python based in-DB analytics functions.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Leveraging teradataml and Vertex AI Python SDK capabilities which allow users to create model over Vertex AI directly from Vantage.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Once created models are deployed as endpoint in Google Cloud or over Vantage, business users can get access of Vertex AI analytic services for real-time scoring directly from Vantage.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create the following environment variables before invoking this API. Required environment variables:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GOOGLE_APPLICATION_CREDENTIALS:</b> Specifies the path to the JSON file containing the Google Cloud service account credentials.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_REGION:</b> Specifies the location of the Google Cloud project.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><i><b>**Note :- The region for the VertexAI Service account and the region in which the bucket is created should be same</b></i></li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_PROJECT_ID:</b> Specifies the Project ID of the Google Cloud project.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_TD_AUTH_OBJ:</b> Specifies the name of the Google Cloud authorization object in Vantage.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>**Please enter your valid GCP credentials.</b></p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Name of the json file which has credentials: clearscape-production-99fb6484153e.json\n",
      "GCP Region:  us-central1\n",
      "Enter the GCP project ID:  clearscape-production\n",
      "Enter the Authorization object name along with database name:  gs_tables_db.auth_for_vertext\n"
     ]
    }
   ],
   "source": [
    "credentials_json = input(\"Name of the json file which has credentials:\")\n",
    "region = input(\"GCP Region: \")\n",
    "project_id = input(\"Enter the GCP project ID: \")\n",
    "td_auth_object = input(\"Enter the Authorization object name along with database name: \")\n",
    "\n",
    "# Example of the required values --- these are not valid values \n",
    "# credentials_json = \"path/to/service/account/file.json\"\n",
    "# region = \"us-east1\"\n",
    "# project_id = \"demo-environment\"\n",
    "# td_auth_object = \"demodb.td_auth\" ---demodb is the teradata database where the authorization object td_auth is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>If the credentials entered are not valid or do not have the necessary permissions, we may get an error in the estimator step.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We need to assign values based on the GCP Credentials.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_json\n",
    "os.environ[\"GCP_REGION\"] = region\n",
    "os.environ[\"GCP_PROJECT_ID\"] = project_id\n",
    "os.environ[\"GCP_TD_AUTH_OBJ\"] = td_auth_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the create_tdapi_context method to create a TDAPI context to be used to run TDApiClient functions. Creating TDAPI context object is the first step of using TDApiClient library.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>type:</b> Specifies the cloud type of the TDAPI context.\n",
    "Permitted values are: \"aws\", \"azure\", or \"gcp\".</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If the cloud type is Google Cloud, the only accepted value is \"gcp\".</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>gcp_bucket_name:</b> Specifies the name of the Google Cloud storage bucket within project.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>gcp_bucket_path:</b> Specifies a path within the given bucket name. This acts as parent folder for all files that TDApiClient creates.</li></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Name of the storage bucket in project with same region : clearscape-vertexai-demonow-bucket_trial\n",
      "Path within the given bucket:  custom-demo\n"
     ]
    }
   ],
   "source": [
    "gcp_bucket = input(\"Name of the storage bucket in project with same region :\")\n",
    "gcp_path = input(\"Path within the given bucket: \")\n",
    "# Examples of parameters\n",
    "# gcp_bucket = \"clearscape-*********\"\n",
    "# gcp_path = \"custom-******\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables \n",
    "\n",
    "gcp_context = create_tdapi_context(\n",
    "    \"gcp\",\n",
    "    gcp_bucket_name=gcp_bucket,\n",
    "    gcp_bucket_path=gcp_path\n",
    "    )\n",
    "tdapi_client = TDApiClient(gcp_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Training job and Deploy model</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.1 Create and run training job</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Vertex AI provides Docker container images that you run as prebuilt containers for custom training. These containers, which are organized by machine learning (ML) framework and framework version, include common dependencies that you might want to use in training code. Often, using a prebuilt container is simpler than creating your own custom container for training.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can find the list of all precreated images <a href = 'https://cloud.google.com/vertex-ai/docs/training/pre-built-containers'>here</a>. For our demo we will be using the scikit-learn training and prediction images for our training and prediuction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest\"\n",
    "PREDICTION_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TDApiClient class to create training job objects of Vertex AI Python package. This feature is implemented using getattr method of this class. Exact input for this method is determined by the class name of TrainingJob, such as CustomTrainingJob or AutoMLTabularTrainingJob.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>There are different training job classes of Vertex AI package that can be used. For example:\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CustomTrainingJob:</code> Useful for taking a training implementation as a python script</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CustomPythonPackageTrainingJob:</code> Useful for taking a training implementation as a python package</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CustomContainerTrainingJob:</code> Useful for training on a custom Docker container</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>AutoMLTabularTrainingJob:</code> Useful for training an AutoML model with tabular dataset</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>AutoMLForecastingTrainingJob:</code> Useful for training an AutoML model with time series dataset</li>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here we are using the CustomTrainingJob</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = tdapi_client.CustomTrainingJob(\n",
    "    display_name=\"tdapiclient-custom-demo\",\n",
    "    script_path=\"train.py\",\n",
    "    container_uri=TRAINING_IMAGE,\n",
    "    requirements=[\"gcsfs\", \"nyoka\"],\n",
    "    model_serving_container_image_uri=PREDICTION_IMAGE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.2 Train a model</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TrainingJob.fit method to train a teradataml DataFrame with optional keyword arguments, and return a Google Vertex AI Model object. Below are the different arguments that can be used.</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>LOCATION:</code> The region where the container or Python package will be run.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>JOB_NAME:</code> Required. A display name for the CustomJob.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>MACHINE_TYPE:</code> The type of the machine. Refer to available machine types for training.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>REPLICA_COUNT:</code> The number of worker replicas to use. In most cases, set this to 1 for your first worker pool.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>EXECUTOR_IMAGE_URI:</code> The URI of the container image that runs the provided code. Refer to the available prebuilt containers for training. This image acts as the base image for the new Docker image that you are building with this command.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>WORKING_DIRECTORY:</code> A directory in your local file system containing the entry point script that runs your training code (see the following list item). We can use the parent directory of the script, or a higher-level directory. We can also use a higher-level directory if it contains a requirements.txt or setup.py file. To learn more, see Install dependencies.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>SCRIPT_PATH:</code> The path, relative to WORKING_DIRECTORY on your local file system, to the script that is the entry point for your training code. This can be a Python script (ending in .py) or a Bash script. For example, if you want to run /hello-world/trainer/task.py and WORKING_DIRECTORY is /hello-world, then use trainer/task.py for this value.</li></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TabularDataset\n",
      "Create TabularDataset backing LRO: projects/323844706402/locations/us-central1/datasets/7253287992926666752/operations/5320162142580637696\n",
      "TabularDataset created. Resource name: projects/323844706402/locations/us-central1/datasets/7253287992926666752\n",
      "To use this TabularDataset in another session:\n",
      "ds = aiplatform.TabularDataset('projects/323844706402/locations/us-central1/datasets/7253287992926666752')\n",
      "Training script copied to:\n",
      "gs://clearscape-vertexai-demonow-bucket_trial/custom-demo/aiplatform-2024-06-18-08:51:58.982-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "Training Output directory:\n",
      "gs://clearscape-vertexai-demonow-bucket_trial/custom-demo/aiplatform-custom-training-2024-06-18-08:51:59.113 \n",
      "No dataset split provided. The service will use a default split.\n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7046845648200531968?project=323844706402\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7046845648200531968 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7046845648200531968 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7046845648200531968 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7046845648200531968 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7046845648200531968 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/1128420846486945792?project=323844706402\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7046845648200531968 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob run completed. Resource name: projects/323844706402/locations/us-central1/trainingPipelines/7046845648200531968\n",
      "Model available at projects/323844706402/locations/us-central1/models/2240128497756405760\n"
     ]
    }
   ],
   "source": [
    "model = job.fit(\n",
    "    df_train,\n",
    "    replica_count=1,\n",
    "    model_display_name=\"tdapiclient-custom-demo\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.3 Deploy model to online endpoint</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TrainingJob.deploy method to deploy a trained model in Google Vertex AI environment or in Vantage system. A TDPredictor object is returned which can be used to run prediction.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>For Vertex AI environment, it requires argument format the same as the Model.deploy function in Vertex AI Python SDK.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>For Vantage system, it requires arguments that are required by BYOM and Predictor functions in teradataml.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Required Arguments:</b>\n",
    "    <li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>model:</b> Specifies a Vertex AI model object.\n",
    "platform: Specifies the platform to deploy the given model:</li>\n",
    "    <ul style = 'font-size:14px;font-family:Arial;color:#00233C'>\n",
    "    <li>'vantage'</li>\n",
    "<li>'vx-endpoint'</li></ul></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>model_type:</b> Required if platform is 'vantage'. Specifies the type of the model:</li>\n",
    "<ul style = 'font-size:14px;font-family:Arial;color:#00233C'>\n",
    "<li>'pmml'</li>\n",
    "<li>'onnx'</li>\n",
    "<li>'h2o'</li></ul></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>model_filename:</b> Required if platform is 'vantage'. Specifies the Google Cloud Storage file name of the model artifact.</li></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/323844706402/locations/us-central1/endpoints/8774997792117489664/operations/344247504289660928\n",
      "Endpoint created. Resource name: projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/323844706402/locations/us-central1/endpoints/8774997792117489664')\n",
      "Deploying model to Endpoint : projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n",
      "Deploy Endpoint model backing LRO: projects/323844706402/locations/us-central1/endpoints/8774997792117489664/operations/8778926656401178624\n",
      "Endpoint model deployed. Resource name: projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n"
     ]
    }
   ],
   "source": [
    "predictor = job.deploy(\n",
    "    model,\n",
    "    \"vx-endpoint\",\n",
    "    vertex_kwargs={\"machine_type\": \"n1-standard-4\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>8. Predict using the deployed model</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.1 Prepare test data</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857343</td>\n",
       "\t\t<td>11.76</td>\n",
       "\t\t<td>21.6</td>\n",
       "\t\t<td>74.72</td>\n",
       "\t\t<td>427.9</td>\n",
       "\t\t<td>0.08637</td>\n",
       "\t\t<td>0.04966</td>\n",
       "\t\t<td>0.01657</td>\n",
       "\t\t<td>0.01115</td>\n",
       "\t\t<td>0.1495</td>\n",
       "\t\t<td>0.05888</td>\n",
       "\t\t<td>0.4062</td>\n",
       "\t\t<td>1.21</td>\n",
       "\t\t<td>2.635</td>\n",
       "\t\t<td>28.47</td>\n",
       "\t\t<td>0.005857</td>\n",
       "\t\t<td>0.009758</td>\n",
       "\t\t<td>0.01168</td>\n",
       "\t\t<td>0.007445</td>\n",
       "\t\t<td>0.02406</td>\n",
       "\t\t<td>0.001769</td>\n",
       "\t\t<td>12.98</td>\n",
       "\t\t<td>25.72</td>\n",
       "\t\t<td>82.98</td>\n",
       "\t\t<td>516.5</td>\n",
       "\t\t<td>0.1085</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.05523</td>\n",
       "\t\t<td>0.03715</td>\n",
       "\t\t<td>0.2433</td>\n",
       "\t\t<td>0.06563</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857156</td>\n",
       "\t\t<td>13.49</td>\n",
       "\t\t<td>22.3</td>\n",
       "\t\t<td>86.91</td>\n",
       "\t\t<td>561.0</td>\n",
       "\t\t<td>0.08752</td>\n",
       "\t\t<td>0.07698</td>\n",
       "\t\t<td>0.04751</td>\n",
       "\t\t<td>0.03384</td>\n",
       "\t\t<td>0.1809</td>\n",
       "\t\t<td>0.05718</td>\n",
       "\t\t<td>0.2338</td>\n",
       "\t\t<td>1.353</td>\n",
       "\t\t<td>1.735</td>\n",
       "\t\t<td>20.2</td>\n",
       "\t\t<td>0.004455</td>\n",
       "\t\t<td>0.01382</td>\n",
       "\t\t<td>0.02095</td>\n",
       "\t\t<td>0.01184</td>\n",
       "\t\t<td>0.01641</td>\n",
       "\t\t<td>0.001956</td>\n",
       "\t\t<td>15.15</td>\n",
       "\t\t<td>31.82</td>\n",
       "\t\t<td>99.0</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.1162</td>\n",
       "\t\t<td>0.1711</td>\n",
       "\t\t<td>0.2282</td>\n",
       "\t\t<td>0.1282</td>\n",
       "\t\t<td>0.2871</td>\n",
       "\t\t<td>0.06917</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>864033</td>\n",
       "\t\t<td>9.777</td>\n",
       "\t\t<td>16.99</td>\n",
       "\t\t<td>62.5</td>\n",
       "\t\t<td>290.2</td>\n",
       "\t\t<td>0.1037</td>\n",
       "\t\t<td>0.08404</td>\n",
       "\t\t<td>0.04334</td>\n",
       "\t\t<td>0.01778</td>\n",
       "\t\t<td>0.1584</td>\n",
       "\t\t<td>0.07065</td>\n",
       "\t\t<td>0.403</td>\n",
       "\t\t<td>1.424</td>\n",
       "\t\t<td>2.747</td>\n",
       "\t\t<td>22.87</td>\n",
       "\t\t<td>0.01385</td>\n",
       "\t\t<td>0.02932</td>\n",
       "\t\t<td>0.02722</td>\n",
       "\t\t<td>0.01023</td>\n",
       "\t\t<td>0.03281</td>\n",
       "\t\t<td>0.004638</td>\n",
       "\t\t<td>11.05</td>\n",
       "\t\t<td>21.47</td>\n",
       "\t\t<td>71.68</td>\n",
       "\t\t<td>367.0</td>\n",
       "\t\t<td>0.1467</td>\n",
       "\t\t<td>0.1765</td>\n",
       "\t\t<td>0.13</td>\n",
       "\t\t<td>0.05334</td>\n",
       "\t\t<td>0.2533</td>\n",
       "\t\t<td>0.08468</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86561</td>\n",
       "\t\t<td>13.85</td>\n",
       "\t\t<td>17.21</td>\n",
       "\t\t<td>88.44</td>\n",
       "\t\t<td>588.7</td>\n",
       "\t\t<td>0.08785</td>\n",
       "\t\t<td>0.06136</td>\n",
       "\t\t<td>0.0142</td>\n",
       "\t\t<td>0.01141</td>\n",
       "\t\t<td>0.1614</td>\n",
       "\t\t<td>0.0589</td>\n",
       "\t\t<td>0.2185</td>\n",
       "\t\t<td>0.8561</td>\n",
       "\t\t<td>1.495</td>\n",
       "\t\t<td>17.91</td>\n",
       "\t\t<td>0.004599</td>\n",
       "\t\t<td>0.009169</td>\n",
       "\t\t<td>0.009127</td>\n",
       "\t\t<td>0.004814</td>\n",
       "\t\t<td>0.01247</td>\n",
       "\t\t<td>0.001708</td>\n",
       "\t\t<td>15.49</td>\n",
       "\t\t<td>23.58</td>\n",
       "\t\t<td>100.3</td>\n",
       "\t\t<td>725.9</td>\n",
       "\t\t<td>0.1157</td>\n",
       "\t\t<td>0.135</td>\n",
       "\t\t<td>0.08115</td>\n",
       "\t\t<td>0.05104</td>\n",
       "\t\t<td>0.2364</td>\n",
       "\t\t<td>0.07182</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86408</td>\n",
       "\t\t<td>12.63</td>\n",
       "\t\t<td>20.76</td>\n",
       "\t\t<td>82.15</td>\n",
       "\t\t<td>480.4</td>\n",
       "\t\t<td>0.09933</td>\n",
       "\t\t<td>0.1209</td>\n",
       "\t\t<td>0.1065</td>\n",
       "\t\t<td>0.06021</td>\n",
       "\t\t<td>0.1735</td>\n",
       "\t\t<td>0.0707</td>\n",
       "\t\t<td>0.3424</td>\n",
       "\t\t<td>1.803</td>\n",
       "\t\t<td>2.711</td>\n",
       "\t\t<td>20.48</td>\n",
       "\t\t<td>0.01291</td>\n",
       "\t\t<td>0.04042</td>\n",
       "\t\t<td>0.05101</td>\n",
       "\t\t<td>0.02295</td>\n",
       "\t\t<td>0.02144</td>\n",
       "\t\t<td>0.005891</td>\n",
       "\t\t<td>13.33</td>\n",
       "\t\t<td>25.47</td>\n",
       "\t\t<td>89.0</td>\n",
       "\t\t<td>527.4</td>\n",
       "\t\t<td>0.1287</td>\n",
       "\t\t<td>0.225</td>\n",
       "\t\t<td>0.2216</td>\n",
       "\t\t<td>0.1105</td>\n",
       "\t\t<td>0.2226</td>\n",
       "\t\t<td>0.08486</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>852631</td>\n",
       "\t\t<td>17.14</td>\n",
       "\t\t<td>16.4</td>\n",
       "\t\t<td>116.0</td>\n",
       "\t\t<td>912.7</td>\n",
       "\t\t<td>0.1186</td>\n",
       "\t\t<td>0.2276</td>\n",
       "\t\t<td>0.2229</td>\n",
       "\t\t<td>0.1401</td>\n",
       "\t\t<td>0.304</td>\n",
       "\t\t<td>0.07413</td>\n",
       "\t\t<td>1.046</td>\n",
       "\t\t<td>0.976</td>\n",
       "\t\t<td>7.276</td>\n",
       "\t\t<td>111.4</td>\n",
       "\t\t<td>0.008029</td>\n",
       "\t\t<td>0.03799</td>\n",
       "\t\t<td>0.03732</td>\n",
       "\t\t<td>0.02397</td>\n",
       "\t\t<td>0.02308</td>\n",
       "\t\t<td>0.007444</td>\n",
       "\t\t<td>22.25</td>\n",
       "\t\t<td>21.4</td>\n",
       "\t\t<td>152.4</td>\n",
       "\t\t<td>1461.0</td>\n",
       "\t\t<td>0.1545</td>\n",
       "\t\t<td>0.3949</td>\n",
       "\t\t<td>0.3853</td>\n",
       "\t\t<td>0.255</td>\n",
       "\t\t<td>0.4066</td>\n",
       "\t\t<td>0.1059</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857373</td>\n",
       "\t\t<td>13.64</td>\n",
       "\t\t<td>16.34</td>\n",
       "\t\t<td>87.21</td>\n",
       "\t\t<td>571.8</td>\n",
       "\t\t<td>0.07685</td>\n",
       "\t\t<td>0.06059</td>\n",
       "\t\t<td>0.01857</td>\n",
       "\t\t<td>0.01723</td>\n",
       "\t\t<td>0.1353</td>\n",
       "\t\t<td>0.05953</td>\n",
       "\t\t<td>0.1872</td>\n",
       "\t\t<td>0.9234</td>\n",
       "\t\t<td>1.449</td>\n",
       "\t\t<td>14.55</td>\n",
       "\t\t<td>0.004477</td>\n",
       "\t\t<td>0.01177</td>\n",
       "\t\t<td>0.01079</td>\n",
       "\t\t<td>0.007956</td>\n",
       "\t\t<td>0.01325</td>\n",
       "\t\t<td>0.002551</td>\n",
       "\t\t<td>14.67</td>\n",
       "\t\t<td>23.19</td>\n",
       "\t\t<td>96.08</td>\n",
       "\t\t<td>656.7</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.1582</td>\n",
       "\t\t<td>0.105</td>\n",
       "\t\t<td>0.08586</td>\n",
       "\t\t<td>0.2346</td>\n",
       "\t\t<td>0.08025</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>855167</td>\n",
       "\t\t<td>13.44</td>\n",
       "\t\t<td>21.58</td>\n",
       "\t\t<td>86.18</td>\n",
       "\t\t<td>563.0</td>\n",
       "\t\t<td>0.08162</td>\n",
       "\t\t<td>0.06031</td>\n",
       "\t\t<td>0.0311</td>\n",
       "\t\t<td>0.02031</td>\n",
       "\t\t<td>0.1784</td>\n",
       "\t\t<td>0.05587</td>\n",
       "\t\t<td>0.2385</td>\n",
       "\t\t<td>0.8265</td>\n",
       "\t\t<td>1.572</td>\n",
       "\t\t<td>20.53</td>\n",
       "\t\t<td>0.00328</td>\n",
       "\t\t<td>0.01102</td>\n",
       "\t\t<td>0.0139</td>\n",
       "\t\t<td>0.006881</td>\n",
       "\t\t<td>0.0138</td>\n",
       "\t\t<td>0.001286</td>\n",
       "\t\t<td>15.93</td>\n",
       "\t\t<td>30.25</td>\n",
       "\t\t<td>102.5</td>\n",
       "\t\t<td>787.9</td>\n",
       "\t\t<td>0.1094</td>\n",
       "\t\t<td>0.2043</td>\n",
       "\t\t<td>0.2085</td>\n",
       "\t\t<td>0.1112</td>\n",
       "\t\t<td>0.2994</td>\n",
       "\t\t<td>0.07146</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91550</td>\n",
       "\t\t<td>11.74</td>\n",
       "\t\t<td>14.69</td>\n",
       "\t\t<td>76.31</td>\n",
       "\t\t<td>426.0</td>\n",
       "\t\t<td>0.08099</td>\n",
       "\t\t<td>0.09661</td>\n",
       "\t\t<td>0.06726</td>\n",
       "\t\t<td>0.02639</td>\n",
       "\t\t<td>0.1499</td>\n",
       "\t\t<td>0.06758</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>0.6417</td>\n",
       "\t\t<td>1.345</td>\n",
       "\t\t<td>13.04</td>\n",
       "\t\t<td>0.006982</td>\n",
       "\t\t<td>0.03916</td>\n",
       "\t\t<td>0.04017</td>\n",
       "\t\t<td>0.01528</td>\n",
       "\t\t<td>0.0226</td>\n",
       "\t\t<td>0.006822</td>\n",
       "\t\t<td>12.45</td>\n",
       "\t\t<td>17.6</td>\n",
       "\t\t<td>81.25</td>\n",
       "\t\t<td>473.8</td>\n",
       "\t\t<td>0.1073</td>\n",
       "\t\t<td>0.2793</td>\n",
       "\t\t<td>0.269</td>\n",
       "\t\t<td>0.1056</td>\n",
       "\t\t<td>0.2604</td>\n",
       "\t\t<td>0.09879</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "       id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst\n",
       "0  857343       11.760         21.60           74.72      427.9          0.08637           0.04966         0.01657              0.01115         0.1495                 0.05888     0.4062      1.2100         2.635    28.47       0.005857        0.009758      0.011680           0.007445      0.02406              0.001769         12.98          25.72            82.98       516.5            0.1085            0.08615          0.05523               0.03715          0.2433                  0.06563\n",
       "1  857156       13.490         22.30           86.91      561.0          0.08752           0.07698         0.04751              0.03384         0.1809                 0.05718     0.2338      1.3530         1.735    20.20       0.004455        0.013820      0.020950           0.011840      0.01641              0.001956         15.15          31.82            99.00       698.8            0.1162            0.17110          0.22820               0.12820          0.2871                  0.06917\n",
       "2  864033        9.777         16.99           62.50      290.2          0.10370           0.08404         0.04334              0.01778         0.1584                 0.07065     0.4030      1.4240         2.747    22.87       0.013850        0.029320      0.027220           0.010230      0.03281              0.004638         11.05          21.47            71.68       367.0            0.1467            0.17650          0.13000               0.05334          0.2533                  0.08468\n",
       "3   86561       13.850         17.21           88.44      588.7          0.08785           0.06136         0.01420              0.01141         0.1614                 0.05890     0.2185      0.8561         1.495    17.91       0.004599        0.009169      0.009127           0.004814      0.01247              0.001708         15.49          23.58           100.30       725.9            0.1157            0.13500          0.08115               0.05104          0.2364                  0.07182\n",
       "4  862965       12.180         20.52           77.22      458.7          0.08013           0.04038         0.02383              0.01770         0.1739                 0.05677     0.1924      1.5710         1.183    14.68       0.005080        0.006098      0.010690           0.006797      0.01447              0.001532         13.34          32.84            84.58       547.8            0.1123            0.08862          0.11450               0.07431          0.2694                  0.06878\n",
       "5   86408       12.630         20.76           82.15      480.4          0.09933           0.12090         0.10650              0.06021         0.1735                 0.07070     0.3424      1.8030         2.711    20.48       0.012910        0.040420      0.051010           0.022950      0.02144              0.005891         13.33          25.47            89.00       527.4            0.1287            0.22500          0.22160               0.11050          0.2226                  0.08486\n",
       "6  852631       17.140         16.40          116.00      912.7          0.11860           0.22760         0.22290              0.14010         0.3040                 0.07413     1.0460      0.9760         7.276   111.40       0.008029        0.037990      0.037320           0.023970      0.02308              0.007444         22.25          21.40           152.40      1461.0            0.1545            0.39490          0.38530               0.25500          0.4066                  0.10590\n",
       "7  857373       13.640         16.34           87.21      571.8          0.07685           0.06059         0.01857              0.01723         0.1353                 0.05953     0.1872      0.9234         1.449    14.55       0.004477        0.011770      0.010790           0.007956      0.01325              0.002551         14.67          23.19            96.08       656.7            0.1089            0.15820          0.10500               0.08586          0.2346                  0.08025\n",
       "8  855167       13.440         21.58           86.18      563.0          0.08162           0.06031         0.03110              0.02031         0.1784                 0.05587     0.2385      0.8265         1.572    20.53       0.003280        0.011020      0.013900           0.006881      0.01380              0.001286         15.93          30.25           102.50       787.9            0.1094            0.20430          0.20850               0.11120          0.2994                  0.07146\n",
       "9   91550       11.740         14.69           76.31      426.0          0.08099           0.09661         0.06726              0.02639         0.1499                 0.06758     0.1924      0.6417         1.345    13.04       0.006982        0.039160      0.040170           0.015280      0.02260              0.006822         12.45          17.60            81.25       473.8            0.1073            0.27930          0.26900               0.10560          0.2604                  0.09879"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>852631</td>\n",
       "\t\t<td>17.14</td>\n",
       "\t\t<td>16.4</td>\n",
       "\t\t<td>116.0</td>\n",
       "\t\t<td>912.7</td>\n",
       "\t\t<td>0.1186</td>\n",
       "\t\t<td>0.2276</td>\n",
       "\t\t<td>0.2229</td>\n",
       "\t\t<td>0.1401</td>\n",
       "\t\t<td>0.304</td>\n",
       "\t\t<td>0.07413</td>\n",
       "\t\t<td>1.046</td>\n",
       "\t\t<td>0.976</td>\n",
       "\t\t<td>7.276</td>\n",
       "\t\t<td>111.4</td>\n",
       "\t\t<td>0.008029</td>\n",
       "\t\t<td>0.03799</td>\n",
       "\t\t<td>0.03732</td>\n",
       "\t\t<td>0.02397</td>\n",
       "\t\t<td>0.02308</td>\n",
       "\t\t<td>0.007444</td>\n",
       "\t\t<td>22.25</td>\n",
       "\t\t<td>21.4</td>\n",
       "\t\t<td>152.4</td>\n",
       "\t\t<td>1461.0</td>\n",
       "\t\t<td>0.1545</td>\n",
       "\t\t<td>0.3949</td>\n",
       "\t\t<td>0.3853</td>\n",
       "\t\t<td>0.255</td>\n",
       "\t\t<td>0.4066</td>\n",
       "\t\t<td>0.1059</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857373</td>\n",
       "\t\t<td>13.64</td>\n",
       "\t\t<td>16.34</td>\n",
       "\t\t<td>87.21</td>\n",
       "\t\t<td>571.8</td>\n",
       "\t\t<td>0.07685</td>\n",
       "\t\t<td>0.06059</td>\n",
       "\t\t<td>0.01857</td>\n",
       "\t\t<td>0.01723</td>\n",
       "\t\t<td>0.1353</td>\n",
       "\t\t<td>0.05953</td>\n",
       "\t\t<td>0.1872</td>\n",
       "\t\t<td>0.9234</td>\n",
       "\t\t<td>1.449</td>\n",
       "\t\t<td>14.55</td>\n",
       "\t\t<td>0.004477</td>\n",
       "\t\t<td>0.01177</td>\n",
       "\t\t<td>0.01079</td>\n",
       "\t\t<td>0.007956</td>\n",
       "\t\t<td>0.01325</td>\n",
       "\t\t<td>0.002551</td>\n",
       "\t\t<td>14.67</td>\n",
       "\t\t<td>23.19</td>\n",
       "\t\t<td>96.08</td>\n",
       "\t\t<td>656.7</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.1582</td>\n",
       "\t\t<td>0.105</td>\n",
       "\t\t<td>0.08586</td>\n",
       "\t\t<td>0.2346</td>\n",
       "\t\t<td>0.08025</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86355</td>\n",
       "\t\t<td>22.27</td>\n",
       "\t\t<td>19.67</td>\n",
       "\t\t<td>152.8</td>\n",
       "\t\t<td>1509.0</td>\n",
       "\t\t<td>0.1326</td>\n",
       "\t\t<td>0.2768</td>\n",
       "\t\t<td>0.4264</td>\n",
       "\t\t<td>0.1823</td>\n",
       "\t\t<td>0.2556</td>\n",
       "\t\t<td>0.07039</td>\n",
       "\t\t<td>1.215</td>\n",
       "\t\t<td>1.545</td>\n",
       "\t\t<td>10.05</td>\n",
       "\t\t<td>170.0</td>\n",
       "\t\t<td>0.006515</td>\n",
       "\t\t<td>0.08668</td>\n",
       "\t\t<td>0.104</td>\n",
       "\t\t<td>0.0248</td>\n",
       "\t\t<td>0.03112</td>\n",
       "\t\t<td>0.005037</td>\n",
       "\t\t<td>28.4</td>\n",
       "\t\t<td>28.01</td>\n",
       "\t\t<td>206.8</td>\n",
       "\t\t<td>2360.0</td>\n",
       "\t\t<td>0.1701</td>\n",
       "\t\t<td>0.6997</td>\n",
       "\t\t<td>0.9608</td>\n",
       "\t\t<td>0.291</td>\n",
       "\t\t<td>0.4055</td>\n",
       "\t\t<td>0.09789</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857343</td>\n",
       "\t\t<td>11.76</td>\n",
       "\t\t<td>21.6</td>\n",
       "\t\t<td>74.72</td>\n",
       "\t\t<td>427.9</td>\n",
       "\t\t<td>0.08637</td>\n",
       "\t\t<td>0.04966</td>\n",
       "\t\t<td>0.01657</td>\n",
       "\t\t<td>0.01115</td>\n",
       "\t\t<td>0.1495</td>\n",
       "\t\t<td>0.05888</td>\n",
       "\t\t<td>0.4062</td>\n",
       "\t\t<td>1.21</td>\n",
       "\t\t<td>2.635</td>\n",
       "\t\t<td>28.47</td>\n",
       "\t\t<td>0.005857</td>\n",
       "\t\t<td>0.009758</td>\n",
       "\t\t<td>0.01168</td>\n",
       "\t\t<td>0.007445</td>\n",
       "\t\t<td>0.02406</td>\n",
       "\t\t<td>0.001769</td>\n",
       "\t\t<td>12.98</td>\n",
       "\t\t<td>25.72</td>\n",
       "\t\t<td>82.98</td>\n",
       "\t\t<td>516.5</td>\n",
       "\t\t<td>0.1085</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.05523</td>\n",
       "\t\t<td>0.03715</td>\n",
       "\t\t<td>0.2433</td>\n",
       "\t\t<td>0.06563</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91550</td>\n",
       "\t\t<td>11.74</td>\n",
       "\t\t<td>14.69</td>\n",
       "\t\t<td>76.31</td>\n",
       "\t\t<td>426.0</td>\n",
       "\t\t<td>0.08099</td>\n",
       "\t\t<td>0.09661</td>\n",
       "\t\t<td>0.06726</td>\n",
       "\t\t<td>0.02639</td>\n",
       "\t\t<td>0.1499</td>\n",
       "\t\t<td>0.06758</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>0.6417</td>\n",
       "\t\t<td>1.345</td>\n",
       "\t\t<td>13.04</td>\n",
       "\t\t<td>0.006982</td>\n",
       "\t\t<td>0.03916</td>\n",
       "\t\t<td>0.04017</td>\n",
       "\t\t<td>0.01528</td>\n",
       "\t\t<td>0.0226</td>\n",
       "\t\t<td>0.006822</td>\n",
       "\t\t<td>12.45</td>\n",
       "\t\t<td>17.6</td>\n",
       "\t\t<td>81.25</td>\n",
       "\t\t<td>473.8</td>\n",
       "\t\t<td>0.1073</td>\n",
       "\t\t<td>0.2793</td>\n",
       "\t\t<td>0.269</td>\n",
       "\t\t<td>0.1056</td>\n",
       "\t\t<td>0.2604</td>\n",
       "\t\t<td>0.09879</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857156</td>\n",
       "\t\t<td>13.49</td>\n",
       "\t\t<td>22.3</td>\n",
       "\t\t<td>86.91</td>\n",
       "\t\t<td>561.0</td>\n",
       "\t\t<td>0.08752</td>\n",
       "\t\t<td>0.07698</td>\n",
       "\t\t<td>0.04751</td>\n",
       "\t\t<td>0.03384</td>\n",
       "\t\t<td>0.1809</td>\n",
       "\t\t<td>0.05718</td>\n",
       "\t\t<td>0.2338</td>\n",
       "\t\t<td>1.353</td>\n",
       "\t\t<td>1.735</td>\n",
       "\t\t<td>20.2</td>\n",
       "\t\t<td>0.004455</td>\n",
       "\t\t<td>0.01382</td>\n",
       "\t\t<td>0.02095</td>\n",
       "\t\t<td>0.01184</td>\n",
       "\t\t<td>0.01641</td>\n",
       "\t\t<td>0.001956</td>\n",
       "\t\t<td>15.15</td>\n",
       "\t\t<td>31.82</td>\n",
       "\t\t<td>99.0</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.1162</td>\n",
       "\t\t<td>0.1711</td>\n",
       "\t\t<td>0.2282</td>\n",
       "\t\t<td>0.1282</td>\n",
       "\t\t<td>0.2871</td>\n",
       "\t\t<td>0.06917</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>864033</td>\n",
       "\t\t<td>9.777</td>\n",
       "\t\t<td>16.99</td>\n",
       "\t\t<td>62.5</td>\n",
       "\t\t<td>290.2</td>\n",
       "\t\t<td>0.1037</td>\n",
       "\t\t<td>0.08404</td>\n",
       "\t\t<td>0.04334</td>\n",
       "\t\t<td>0.01778</td>\n",
       "\t\t<td>0.1584</td>\n",
       "\t\t<td>0.07065</td>\n",
       "\t\t<td>0.403</td>\n",
       "\t\t<td>1.424</td>\n",
       "\t\t<td>2.747</td>\n",
       "\t\t<td>22.87</td>\n",
       "\t\t<td>0.01385</td>\n",
       "\t\t<td>0.02932</td>\n",
       "\t\t<td>0.02722</td>\n",
       "\t\t<td>0.01023</td>\n",
       "\t\t<td>0.03281</td>\n",
       "\t\t<td>0.004638</td>\n",
       "\t\t<td>11.05</td>\n",
       "\t\t<td>21.47</td>\n",
       "\t\t<td>71.68</td>\n",
       "\t\t<td>367.0</td>\n",
       "\t\t<td>0.1467</td>\n",
       "\t\t<td>0.1765</td>\n",
       "\t\t<td>0.13</td>\n",
       "\t\t<td>0.05334</td>\n",
       "\t\t<td>0.2533</td>\n",
       "\t\t<td>0.08468</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91485</td>\n",
       "\t\t<td>20.59</td>\n",
       "\t\t<td>21.24</td>\n",
       "\t\t<td>137.8</td>\n",
       "\t\t<td>1320.0</td>\n",
       "\t\t<td>0.1085</td>\n",
       "\t\t<td>0.1644</td>\n",
       "\t\t<td>0.2188</td>\n",
       "\t\t<td>0.1121</td>\n",
       "\t\t<td>0.1848</td>\n",
       "\t\t<td>0.06222</td>\n",
       "\t\t<td>0.5904</td>\n",
       "\t\t<td>1.216</td>\n",
       "\t\t<td>4.206</td>\n",
       "\t\t<td>75.09</td>\n",
       "\t\t<td>0.006666</td>\n",
       "\t\t<td>0.02791</td>\n",
       "\t\t<td>0.04062</td>\n",
       "\t\t<td>0.01479</td>\n",
       "\t\t<td>0.01117</td>\n",
       "\t\t<td>0.003727</td>\n",
       "\t\t<td>23.86</td>\n",
       "\t\t<td>30.76</td>\n",
       "\t\t<td>163.2</td>\n",
       "\t\t<td>1760.0</td>\n",
       "\t\t<td>0.1464</td>\n",
       "\t\t<td>0.3597</td>\n",
       "\t\t<td>0.5179</td>\n",
       "\t\t<td>0.2113</td>\n",
       "\t\t<td>0.248</td>\n",
       "\t\t<td>0.08999</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86408</td>\n",
       "\t\t<td>12.63</td>\n",
       "\t\t<td>20.76</td>\n",
       "\t\t<td>82.15</td>\n",
       "\t\t<td>480.4</td>\n",
       "\t\t<td>0.09933</td>\n",
       "\t\t<td>0.1209</td>\n",
       "\t\t<td>0.1065</td>\n",
       "\t\t<td>0.06021</td>\n",
       "\t\t<td>0.1735</td>\n",
       "\t\t<td>0.0707</td>\n",
       "\t\t<td>0.3424</td>\n",
       "\t\t<td>1.803</td>\n",
       "\t\t<td>2.711</td>\n",
       "\t\t<td>20.48</td>\n",
       "\t\t<td>0.01291</td>\n",
       "\t\t<td>0.04042</td>\n",
       "\t\t<td>0.05101</td>\n",
       "\t\t<td>0.02295</td>\n",
       "\t\t<td>0.02144</td>\n",
       "\t\t<td>0.005891</td>\n",
       "\t\t<td>13.33</td>\n",
       "\t\t<td>25.47</td>\n",
       "\t\t<td>89.0</td>\n",
       "\t\t<td>527.4</td>\n",
       "\t\t<td>0.1287</td>\n",
       "\t\t<td>0.225</td>\n",
       "\t\t<td>0.2216</td>\n",
       "\t\t<td>0.1105</td>\n",
       "\t\t<td>0.2226</td>\n",
       "\t\t<td>0.08486</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "       id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst\n",
       "0  862965       12.180         20.52           77.22      458.7          0.08013           0.04038         0.02383              0.01770         0.1739                 0.05677     0.1924      1.5710         1.183    14.68       0.005080        0.006098       0.01069           0.006797      0.01447              0.001532         13.34          32.84            84.58       547.8            0.1123            0.08862          0.11450               0.07431          0.2694                  0.06878\n",
       "1  852631       17.140         16.40          116.00      912.7          0.11860           0.22760         0.22290              0.14010         0.3040                 0.07413     1.0460      0.9760         7.276   111.40       0.008029        0.037990       0.03732           0.023970      0.02308              0.007444         22.25          21.40           152.40      1461.0            0.1545            0.39490          0.38530               0.25500          0.4066                  0.10590\n",
       "2  857373       13.640         16.34           87.21      571.8          0.07685           0.06059         0.01857              0.01723         0.1353                 0.05953     0.1872      0.9234         1.449    14.55       0.004477        0.011770       0.01079           0.007956      0.01325              0.002551         14.67          23.19            96.08       656.7            0.1089            0.15820          0.10500               0.08586          0.2346                  0.08025\n",
       "3   86355       22.270         19.67          152.80     1509.0          0.13260           0.27680         0.42640              0.18230         0.2556                 0.07039     1.2150      1.5450        10.050   170.00       0.006515        0.086680       0.10400           0.024800      0.03112              0.005037         28.40          28.01           206.80      2360.0            0.1701            0.69970          0.96080               0.29100          0.4055                  0.09789\n",
       "4  857343       11.760         21.60           74.72      427.9          0.08637           0.04966         0.01657              0.01115         0.1495                 0.05888     0.4062      1.2100         2.635    28.47       0.005857        0.009758       0.01168           0.007445      0.02406              0.001769         12.98          25.72            82.98       516.5            0.1085            0.08615          0.05523               0.03715          0.2433                  0.06563\n",
       "5   91550       11.740         14.69           76.31      426.0          0.08099           0.09661         0.06726              0.02639         0.1499                 0.06758     0.1924      0.6417         1.345    13.04       0.006982        0.039160       0.04017           0.015280      0.02260              0.006822         12.45          17.60            81.25       473.8            0.1073            0.27930          0.26900               0.10560          0.2604                  0.09879\n",
       "6  857156       13.490         22.30           86.91      561.0          0.08752           0.07698         0.04751              0.03384         0.1809                 0.05718     0.2338      1.3530         1.735    20.20       0.004455        0.013820       0.02095           0.011840      0.01641              0.001956         15.15          31.82            99.00       698.8            0.1162            0.17110          0.22820               0.12820          0.2871                  0.06917\n",
       "7  864033        9.777         16.99           62.50      290.2          0.10370           0.08404         0.04334              0.01778         0.1584                 0.07065     0.4030      1.4240         2.747    22.87       0.013850        0.029320       0.02722           0.010230      0.03281              0.004638         11.05          21.47            71.68       367.0            0.1467            0.17650          0.13000               0.05334          0.2533                  0.08468\n",
       "8   91485       20.590         21.24          137.80     1320.0          0.10850           0.16440         0.21880              0.11210         0.1848                 0.06222     0.5904      1.2160         4.206    75.09       0.006666        0.027910       0.04062           0.014790      0.01117              0.003727         23.86          30.76           163.20      1760.0            0.1464            0.35970          0.51790               0.21130          0.2480                  0.08999\n",
       "9   86408       12.630         20.76           82.15      480.4          0.09933           0.12090         0.10650              0.06021         0.1735                 0.07070     0.3424      1.8030         2.711    20.48       0.012910        0.040420       0.05101           0.022950      0.02144              0.005891         13.33          25.47            89.00       527.4            0.1287            0.22500          0.22160               0.11050          0.2226                  0.08486"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = df_test.drop([\"diagnosis\"], axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.2 Predict using the TDApiClient predictor object </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TDPredictor.predict method to perform prediction using teradataml DataFrame and VertexAI endpoint represented by this predictor object.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>input:</code> Specifies the teradataml DataFrame used as input for scoring.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>mode:</code> Specifies the mode for scoring.\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>Permitted values include:\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>'UDF':</code> Score in database using a Teradata UDF. This is the default value. For this mode, the return is a teradataml DataFrame. This mode provides faster scoring with the data from Teradata.</li>\n",
    "\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>'CLIENT':</code> Score at client side using a library. For this mode, the return is an array or JSON. When using mode, data is pulled from Teradata and serialized for scoring at client.</li></ol></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional Argument:\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>options: Specifies the predict method with the following key-value arguments:\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>udf_name:</code> Specifies the name of the UDF used to invoke predict with UDF mode. Default value is 'tapidb.API_Request'.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>content_type:</code> Specifies content type required for VertexAI endpoint present in the predictor. Default value is 'csv'.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>key_start_index:</code> Specifies the index in DataFrame columns to be the key for scoring starts. Default value is 0.</li></ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>Output</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857373</td>\n",
       "\t\t<td>13.64</td>\n",
       "\t\t<td>16.34</td>\n",
       "\t\t<td>87.21</td>\n",
       "\t\t<td>571.8</td>\n",
       "\t\t<td>0.07685</td>\n",
       "\t\t<td>0.06059</td>\n",
       "\t\t<td>0.01857</td>\n",
       "\t\t<td>0.01723</td>\n",
       "\t\t<td>0.1353</td>\n",
       "\t\t<td>0.05953</td>\n",
       "\t\t<td>0.1872</td>\n",
       "\t\t<td>0.9234</td>\n",
       "\t\t<td>1.449</td>\n",
       "\t\t<td>14.55</td>\n",
       "\t\t<td>0.004477</td>\n",
       "\t\t<td>0.01177</td>\n",
       "\t\t<td>0.01079</td>\n",
       "\t\t<td>0.007956</td>\n",
       "\t\t<td>0.01325</td>\n",
       "\t\t<td>0.002551</td>\n",
       "\t\t<td>14.67</td>\n",
       "\t\t<td>23.19</td>\n",
       "\t\t<td>96.08</td>\n",
       "\t\t<td>656.7</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.1582</td>\n",
       "\t\t<td>0.105</td>\n",
       "\t\t<td>0.08586</td>\n",
       "\t\t<td>0.2346</td>\n",
       "\t\t<td>0.08025</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857156</td>\n",
       "\t\t<td>13.49</td>\n",
       "\t\t<td>22.3</td>\n",
       "\t\t<td>86.91</td>\n",
       "\t\t<td>561.0</td>\n",
       "\t\t<td>0.08752</td>\n",
       "\t\t<td>0.07698</td>\n",
       "\t\t<td>0.04751</td>\n",
       "\t\t<td>0.03384</td>\n",
       "\t\t<td>0.1809</td>\n",
       "\t\t<td>0.05718</td>\n",
       "\t\t<td>0.2338</td>\n",
       "\t\t<td>1.353</td>\n",
       "\t\t<td>1.735</td>\n",
       "\t\t<td>20.2</td>\n",
       "\t\t<td>0.004455</td>\n",
       "\t\t<td>0.01382</td>\n",
       "\t\t<td>0.02095</td>\n",
       "\t\t<td>0.01184</td>\n",
       "\t\t<td>0.01641</td>\n",
       "\t\t<td>0.001956</td>\n",
       "\t\t<td>15.15</td>\n",
       "\t\t<td>31.82</td>\n",
       "\t\t<td>99.0</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.1162</td>\n",
       "\t\t<td>0.1711</td>\n",
       "\t\t<td>0.2282</td>\n",
       "\t\t<td>0.1282</td>\n",
       "\t\t<td>0.2871</td>\n",
       "\t\t<td>0.06917</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>864033</td>\n",
       "\t\t<td>9.777</td>\n",
       "\t\t<td>16.99</td>\n",
       "\t\t<td>62.5</td>\n",
       "\t\t<td>290.2</td>\n",
       "\t\t<td>0.1037</td>\n",
       "\t\t<td>0.08404</td>\n",
       "\t\t<td>0.04334</td>\n",
       "\t\t<td>0.01778</td>\n",
       "\t\t<td>0.1584</td>\n",
       "\t\t<td>0.07065</td>\n",
       "\t\t<td>0.403</td>\n",
       "\t\t<td>1.424</td>\n",
       "\t\t<td>2.747</td>\n",
       "\t\t<td>22.87</td>\n",
       "\t\t<td>0.01385</td>\n",
       "\t\t<td>0.02932</td>\n",
       "\t\t<td>0.02722</td>\n",
       "\t\t<td>0.01023</td>\n",
       "\t\t<td>0.03281</td>\n",
       "\t\t<td>0.004638</td>\n",
       "\t\t<td>11.05</td>\n",
       "\t\t<td>21.47</td>\n",
       "\t\t<td>71.68</td>\n",
       "\t\t<td>367.0</td>\n",
       "\t\t<td>0.1467</td>\n",
       "\t\t<td>0.1765</td>\n",
       "\t\t<td>0.13</td>\n",
       "\t\t<td>0.05334</td>\n",
       "\t\t<td>0.2533</td>\n",
       "\t\t<td>0.08468</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86561</td>\n",
       "\t\t<td>13.85</td>\n",
       "\t\t<td>17.21</td>\n",
       "\t\t<td>88.44</td>\n",
       "\t\t<td>588.7</td>\n",
       "\t\t<td>0.08785</td>\n",
       "\t\t<td>0.06136</td>\n",
       "\t\t<td>0.0142</td>\n",
       "\t\t<td>0.01141</td>\n",
       "\t\t<td>0.1614</td>\n",
       "\t\t<td>0.0589</td>\n",
       "\t\t<td>0.2185</td>\n",
       "\t\t<td>0.8561</td>\n",
       "\t\t<td>1.495</td>\n",
       "\t\t<td>17.91</td>\n",
       "\t\t<td>0.004599</td>\n",
       "\t\t<td>0.009169</td>\n",
       "\t\t<td>0.009127</td>\n",
       "\t\t<td>0.004814</td>\n",
       "\t\t<td>0.01247</td>\n",
       "\t\t<td>0.001708</td>\n",
       "\t\t<td>15.49</td>\n",
       "\t\t<td>23.58</td>\n",
       "\t\t<td>100.3</td>\n",
       "\t\t<td>725.9</td>\n",
       "\t\t<td>0.1157</td>\n",
       "\t\t<td>0.135</td>\n",
       "\t\t<td>0.08115</td>\n",
       "\t\t<td>0.05104</td>\n",
       "\t\t<td>0.2364</td>\n",
       "\t\t<td>0.07182</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86355</td>\n",
       "\t\t<td>22.27</td>\n",
       "\t\t<td>19.67</td>\n",
       "\t\t<td>152.8</td>\n",
       "\t\t<td>1509.0</td>\n",
       "\t\t<td>0.1326</td>\n",
       "\t\t<td>0.2768</td>\n",
       "\t\t<td>0.4264</td>\n",
       "\t\t<td>0.1823</td>\n",
       "\t\t<td>0.2556</td>\n",
       "\t\t<td>0.07039</td>\n",
       "\t\t<td>1.215</td>\n",
       "\t\t<td>1.545</td>\n",
       "\t\t<td>10.05</td>\n",
       "\t\t<td>170.0</td>\n",
       "\t\t<td>0.006515</td>\n",
       "\t\t<td>0.08668</td>\n",
       "\t\t<td>0.104</td>\n",
       "\t\t<td>0.0248</td>\n",
       "\t\t<td>0.03112</td>\n",
       "\t\t<td>0.005037</td>\n",
       "\t\t<td>28.4</td>\n",
       "\t\t<td>28.01</td>\n",
       "\t\t<td>206.8</td>\n",
       "\t\t<td>2360.0</td>\n",
       "\t\t<td>0.1701</td>\n",
       "\t\t<td>0.6997</td>\n",
       "\t\t<td>0.9608</td>\n",
       "\t\t<td>0.291</td>\n",
       "\t\t<td>0.4055</td>\n",
       "\t\t<td>0.09789</td>\n",
       "\t\t<td>{ \"predictions\": [ 1 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91485</td>\n",
       "\t\t<td>20.59</td>\n",
       "\t\t<td>21.24</td>\n",
       "\t\t<td>137.8</td>\n",
       "\t\t<td>1320.0</td>\n",
       "\t\t<td>0.1085</td>\n",
       "\t\t<td>0.1644</td>\n",
       "\t\t<td>0.2188</td>\n",
       "\t\t<td>0.1121</td>\n",
       "\t\t<td>0.1848</td>\n",
       "\t\t<td>0.06222</td>\n",
       "\t\t<td>0.5904</td>\n",
       "\t\t<td>1.216</td>\n",
       "\t\t<td>4.206</td>\n",
       "\t\t<td>75.09</td>\n",
       "\t\t<td>0.006666</td>\n",
       "\t\t<td>0.02791</td>\n",
       "\t\t<td>0.04062</td>\n",
       "\t\t<td>0.01479</td>\n",
       "\t\t<td>0.01117</td>\n",
       "\t\t<td>0.003727</td>\n",
       "\t\t<td>23.86</td>\n",
       "\t\t<td>30.76</td>\n",
       "\t\t<td>163.2</td>\n",
       "\t\t<td>1760.0</td>\n",
       "\t\t<td>0.1464</td>\n",
       "\t\t<td>0.3597</td>\n",
       "\t\t<td>0.5179</td>\n",
       "\t\t<td>0.2113</td>\n",
       "\t\t<td>0.248</td>\n",
       "\t\t<td>0.08999</td>\n",
       "\t\t<td>{ \"predictions\": [ 1 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857343</td>\n",
       "\t\t<td>11.76</td>\n",
       "\t\t<td>21.6</td>\n",
       "\t\t<td>74.72</td>\n",
       "\t\t<td>427.9</td>\n",
       "\t\t<td>0.08637</td>\n",
       "\t\t<td>0.04966</td>\n",
       "\t\t<td>0.01657</td>\n",
       "\t\t<td>0.01115</td>\n",
       "\t\t<td>0.1495</td>\n",
       "\t\t<td>0.05888</td>\n",
       "\t\t<td>0.4062</td>\n",
       "\t\t<td>1.21</td>\n",
       "\t\t<td>2.635</td>\n",
       "\t\t<td>28.47</td>\n",
       "\t\t<td>0.005857</td>\n",
       "\t\t<td>0.009758</td>\n",
       "\t\t<td>0.01168</td>\n",
       "\t\t<td>0.007445</td>\n",
       "\t\t<td>0.02406</td>\n",
       "\t\t<td>0.001769</td>\n",
       "\t\t<td>12.98</td>\n",
       "\t\t<td>25.72</td>\n",
       "\t\t<td>82.98</td>\n",
       "\t\t<td>516.5</td>\n",
       "\t\t<td>0.1085</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.05523</td>\n",
       "\t\t<td>0.03715</td>\n",
       "\t\t<td>0.2433</td>\n",
       "\t\t<td>0.06563</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>855167</td>\n",
       "\t\t<td>13.44</td>\n",
       "\t\t<td>21.58</td>\n",
       "\t\t<td>86.18</td>\n",
       "\t\t<td>563.0</td>\n",
       "\t\t<td>0.08162</td>\n",
       "\t\t<td>0.06031</td>\n",
       "\t\t<td>0.0311</td>\n",
       "\t\t<td>0.02031</td>\n",
       "\t\t<td>0.1784</td>\n",
       "\t\t<td>0.05587</td>\n",
       "\t\t<td>0.2385</td>\n",
       "\t\t<td>0.8265</td>\n",
       "\t\t<td>1.572</td>\n",
       "\t\t<td>20.53</td>\n",
       "\t\t<td>0.00328</td>\n",
       "\t\t<td>0.01102</td>\n",
       "\t\t<td>0.0139</td>\n",
       "\t\t<td>0.006881</td>\n",
       "\t\t<td>0.0138</td>\n",
       "\t\t<td>0.001286</td>\n",
       "\t\t<td>15.93</td>\n",
       "\t\t<td>30.25</td>\n",
       "\t\t<td>102.5</td>\n",
       "\t\t<td>787.9</td>\n",
       "\t\t<td>0.1094</td>\n",
       "\t\t<td>0.2043</td>\n",
       "\t\t<td>0.2085</td>\n",
       "\t\t<td>0.1112</td>\n",
       "\t\t<td>0.2994</td>\n",
       "\t\t<td>0.07146</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91550</td>\n",
       "\t\t<td>11.74</td>\n",
       "\t\t<td>14.69</td>\n",
       "\t\t<td>76.31</td>\n",
       "\t\t<td>426.0</td>\n",
       "\t\t<td>0.08099</td>\n",
       "\t\t<td>0.09661</td>\n",
       "\t\t<td>0.06726</td>\n",
       "\t\t<td>0.02639</td>\n",
       "\t\t<td>0.1499</td>\n",
       "\t\t<td>0.06758</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>0.6417</td>\n",
       "\t\t<td>1.345</td>\n",
       "\t\t<td>13.04</td>\n",
       "\t\t<td>0.006982</td>\n",
       "\t\t<td>0.03916</td>\n",
       "\t\t<td>0.04017</td>\n",
       "\t\t<td>0.01528</td>\n",
       "\t\t<td>0.0226</td>\n",
       "\t\t<td>0.006822</td>\n",
       "\t\t<td>12.45</td>\n",
       "\t\t<td>17.6</td>\n",
       "\t\t<td>81.25</td>\n",
       "\t\t<td>473.8</td>\n",
       "\t\t<td>0.1073</td>\n",
       "\t\t<td>0.2793</td>\n",
       "\t\t<td>0.269</td>\n",
       "\t\t<td>0.1056</td>\n",
       "\t\t<td>0.2604</td>\n",
       "\t\t<td>0.09879</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "       id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst                                                                                                                                                                                                                           Output\n",
       "0  857373       13.640         16.34           87.21      571.8          0.07685           0.06059         0.01857              0.01723         0.1353                 0.05953     0.1872      0.9234         1.449    14.55       0.004477        0.011770      0.010790           0.007956      0.01325              0.002551         14.67          23.19            96.08       656.7            0.1089            0.15820          0.10500               0.08586          0.2346                  0.08025  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "1  857156       13.490         22.30           86.91      561.0          0.08752           0.07698         0.04751              0.03384         0.1809                 0.05718     0.2338      1.3530         1.735    20.20       0.004455        0.013820      0.020950           0.011840      0.01641              0.001956         15.15          31.82            99.00       698.8            0.1162            0.17110          0.22820               0.12820          0.2871                  0.06917  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "2  864033        9.777         16.99           62.50      290.2          0.10370           0.08404         0.04334              0.01778         0.1584                 0.07065     0.4030      1.4240         2.747    22.87       0.013850        0.029320      0.027220           0.010230      0.03281              0.004638         11.05          21.47            71.68       367.0            0.1467            0.17650          0.13000               0.05334          0.2533                  0.08468  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "3   86561       13.850         17.21           88.44      588.7          0.08785           0.06136         0.01420              0.01141         0.1614                 0.05890     0.2185      0.8561         1.495    17.91       0.004599        0.009169      0.009127           0.004814      0.01247              0.001708         15.49          23.58           100.30       725.9            0.1157            0.13500          0.08115               0.05104          0.2364                  0.07182  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "4  862965       12.180         20.52           77.22      458.7          0.08013           0.04038         0.02383              0.01770         0.1739                 0.05677     0.1924      1.5710         1.183    14.68       0.005080        0.006098      0.010690           0.006797      0.01447              0.001532         13.34          32.84            84.58       547.8            0.1123            0.08862          0.11450               0.07431          0.2694                  0.06878  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "5   86355       22.270         19.67          152.80     1509.0          0.13260           0.27680         0.42640              0.18230         0.2556                 0.07039     1.2150      1.5450        10.050   170.00       0.006515        0.086680      0.104000           0.024800      0.03112              0.005037         28.40          28.01           206.80      2360.0            0.1701            0.69970          0.96080               0.29100          0.4055                  0.09789  { \"predictions\": [ 1 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "6   91485       20.590         21.24          137.80     1320.0          0.10850           0.16440         0.21880              0.11210         0.1848                 0.06222     0.5904      1.2160         4.206    75.09       0.006666        0.027910      0.040620           0.014790      0.01117              0.003727         23.86          30.76           163.20      1760.0            0.1464            0.35970          0.51790               0.21130          0.2480                  0.08999  { \"predictions\": [ 1 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "7  857343       11.760         21.60           74.72      427.9          0.08637           0.04966         0.01657              0.01115         0.1495                 0.05888     0.4062      1.2100         2.635    28.47       0.005857        0.009758      0.011680           0.007445      0.02406              0.001769         12.98          25.72            82.98       516.5            0.1085            0.08615          0.05523               0.03715          0.2433                  0.06563  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "8  855167       13.440         21.58           86.18      563.0          0.08162           0.06031         0.03110              0.02031         0.1784                 0.05587     0.2385      0.8265         1.572    20.53       0.003280        0.011020      0.013900           0.006881      0.01380              0.001286         15.93          30.25           102.50       787.9            0.1094            0.20430          0.20850               0.11120          0.2994                  0.07146  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "9   91550       11.740         14.69           76.31      426.0          0.08099           0.09661         0.06726              0.02639         0.1499                 0.06758     0.1924      0.6417         1.345    13.04       0.006982        0.039160      0.040170           0.015280      0.02260              0.006822         12.45          17.60            81.25       473.8            0.1073            0.27930          0.26900               0.10560          0.2604                  0.09879  { \"predictions\": [ 0 ], \"deployedModelId\": \"978232196697423872\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/2240128497756405760\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(df_test, mode=\"udf\", content_type=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.3 Deploy created model to Vantage </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can use the BYOMPredictor class to hold the name and type of the model teradataml DataFrame obtained using deploy() method. This allows user to export models that are built on VertexAI to Vantage through BYOM, for in-database analysis.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>model_df:</code> Specifies the teradataml DataFrame containing the model data to be used for scoring.\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>model_type:</code> Specifies the type of the model:</li>\n",
    "<ul style = 'font-size:14px;font-family:Arial;color:#00233C'>    \n",
    "<li>'pmml'</li>\n",
    "    <li>'onnx'</li>\n",
    "    <li>'h2o'</li>\n",
    "    </ul>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the model table 'tdapiclient_byom_models' as it does not exist.\n",
      "Model is saved.\n",
      "The model cataloging parameters are set to table_name='tdapiclient_byom_models' and schema_name='DEMO_USER'\n"
     ]
    }
   ],
   "source": [
    "byom_predictor = job.deploy(\n",
    "    model,\n",
    "    \"vantage\",\n",
    "    model_type=\"pmml\",\n",
    "    model_filename=\"model.pmml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>model_id</th>\n",
       "\t\t<th>model</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>tdapiclient_vertex_2240128497756405760</td>\n",
       "\t\t<td>b'3C3F786D6C20766572...'</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                                           model\n",
       "model_id                                                        \n",
       "tdapiclient_vertex_2240128497756405760  b'3C3F786D6C20766572...'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byom_predictor.model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.3 Predict in database using the BYOM Predictor</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can use the BYOMPredictor.predict method to score data in Vantage with a model that has been created outside Vantage and exported to Vantage using the deploy method.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This method supports prediction using models in the following formats:\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>PMML</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>ONNX</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>MOJO (H2O)</li></p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>input:</code> Specifies the teradataml DataFrame containing the input test data.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>input_cols:</code> Specifies the name(s) of input teradataml DataFrame column(s) to copy to the output.</li></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>prediction</th>\n",
       "\t\t<th>json_report</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857343</td>\n",
       "\t\t<td>11.76</td>\n",
       "\t\t<td>21.6</td>\n",
       "\t\t<td>74.72</td>\n",
       "\t\t<td>427.9</td>\n",
       "\t\t<td>0.08637</td>\n",
       "\t\t<td>0.04966</td>\n",
       "\t\t<td>0.01657</td>\n",
       "\t\t<td>0.01115</td>\n",
       "\t\t<td>0.1495</td>\n",
       "\t\t<td>0.05888</td>\n",
       "\t\t<td>0.4062</td>\n",
       "\t\t<td>1.21</td>\n",
       "\t\t<td>2.635</td>\n",
       "\t\t<td>28.47</td>\n",
       "\t\t<td>0.005857</td>\n",
       "\t\t<td>0.009758</td>\n",
       "\t\t<td>0.01168</td>\n",
       "\t\t<td>0.007445</td>\n",
       "\t\t<td>0.02406</td>\n",
       "\t\t<td>0.001769</td>\n",
       "\t\t<td>12.98</td>\n",
       "\t\t<td>25.72</td>\n",
       "\t\t<td>82.98</td>\n",
       "\t\t<td>516.5</td>\n",
       "\t\t<td>0.1085</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.05523</td>\n",
       "\t\t<td>0.03715</td>\n",
       "\t\t<td>0.2433</td>\n",
       "\t\t<td>0.06563</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.97,\"probability_1\":0.03,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>852631</td>\n",
       "\t\t<td>17.14</td>\n",
       "\t\t<td>16.4</td>\n",
       "\t\t<td>116.0</td>\n",
       "\t\t<td>912.7</td>\n",
       "\t\t<td>0.1186</td>\n",
       "\t\t<td>0.2276</td>\n",
       "\t\t<td>0.2229</td>\n",
       "\t\t<td>0.1401</td>\n",
       "\t\t<td>0.304</td>\n",
       "\t\t<td>0.07413</td>\n",
       "\t\t<td>1.046</td>\n",
       "\t\t<td>0.976</td>\n",
       "\t\t<td>7.276</td>\n",
       "\t\t<td>111.4</td>\n",
       "\t\t<td>0.008029</td>\n",
       "\t\t<td>0.03799</td>\n",
       "\t\t<td>0.03732</td>\n",
       "\t\t<td>0.02397</td>\n",
       "\t\t<td>0.02308</td>\n",
       "\t\t<td>0.007444</td>\n",
       "\t\t<td>22.25</td>\n",
       "\t\t<td>21.4</td>\n",
       "\t\t<td>152.4</td>\n",
       "\t\t<td>1461.0</td>\n",
       "\t\t<td>0.1545</td>\n",
       "\t\t<td>0.3949</td>\n",
       "\t\t<td>0.3853</td>\n",
       "\t\t<td>0.255</td>\n",
       "\t\t<td>0.4066</td>\n",
       "\t\t<td>0.1059</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.11,\"probability_1\":0.89,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857373</td>\n",
       "\t\t<td>13.64</td>\n",
       "\t\t<td>16.34</td>\n",
       "\t\t<td>87.21</td>\n",
       "\t\t<td>571.8</td>\n",
       "\t\t<td>0.07685</td>\n",
       "\t\t<td>0.06059</td>\n",
       "\t\t<td>0.01857</td>\n",
       "\t\t<td>0.01723</td>\n",
       "\t\t<td>0.1353</td>\n",
       "\t\t<td>0.05953</td>\n",
       "\t\t<td>0.1872</td>\n",
       "\t\t<td>0.9234</td>\n",
       "\t\t<td>1.449</td>\n",
       "\t\t<td>14.55</td>\n",
       "\t\t<td>0.004477</td>\n",
       "\t\t<td>0.01177</td>\n",
       "\t\t<td>0.01079</td>\n",
       "\t\t<td>0.007956</td>\n",
       "\t\t<td>0.01325</td>\n",
       "\t\t<td>0.002551</td>\n",
       "\t\t<td>14.67</td>\n",
       "\t\t<td>23.19</td>\n",
       "\t\t<td>96.08</td>\n",
       "\t\t<td>656.7</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.1582</td>\n",
       "\t\t<td>0.105</td>\n",
       "\t\t<td>0.08586</td>\n",
       "\t\t<td>0.2346</td>\n",
       "\t\t<td>0.08025</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.97,\"probability_1\":0.03,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91550</td>\n",
       "\t\t<td>11.74</td>\n",
       "\t\t<td>14.69</td>\n",
       "\t\t<td>76.31</td>\n",
       "\t\t<td>426.0</td>\n",
       "\t\t<td>0.08099</td>\n",
       "\t\t<td>0.09661</td>\n",
       "\t\t<td>0.06726</td>\n",
       "\t\t<td>0.02639</td>\n",
       "\t\t<td>0.1499</td>\n",
       "\t\t<td>0.06758</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>0.6417</td>\n",
       "\t\t<td>1.345</td>\n",
       "\t\t<td>13.04</td>\n",
       "\t\t<td>0.006982</td>\n",
       "\t\t<td>0.03916</td>\n",
       "\t\t<td>0.04017</td>\n",
       "\t\t<td>0.01528</td>\n",
       "\t\t<td>0.0226</td>\n",
       "\t\t<td>0.006822</td>\n",
       "\t\t<td>12.45</td>\n",
       "\t\t<td>17.6</td>\n",
       "\t\t<td>81.25</td>\n",
       "\t\t<td>473.8</td>\n",
       "\t\t<td>0.1073</td>\n",
       "\t\t<td>0.2793</td>\n",
       "\t\t<td>0.269</td>\n",
       "\t\t<td>0.1056</td>\n",
       "\t\t<td>0.2604</td>\n",
       "\t\t<td>0.09879</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>864033</td>\n",
       "\t\t<td>9.777</td>\n",
       "\t\t<td>16.99</td>\n",
       "\t\t<td>62.5</td>\n",
       "\t\t<td>290.2</td>\n",
       "\t\t<td>0.1037</td>\n",
       "\t\t<td>0.08404</td>\n",
       "\t\t<td>0.04334</td>\n",
       "\t\t<td>0.01778</td>\n",
       "\t\t<td>0.1584</td>\n",
       "\t\t<td>0.07065</td>\n",
       "\t\t<td>0.403</td>\n",
       "\t\t<td>1.424</td>\n",
       "\t\t<td>2.747</td>\n",
       "\t\t<td>22.87</td>\n",
       "\t\t<td>0.01385</td>\n",
       "\t\t<td>0.02932</td>\n",
       "\t\t<td>0.02722</td>\n",
       "\t\t<td>0.01023</td>\n",
       "\t\t<td>0.03281</td>\n",
       "\t\t<td>0.004638</td>\n",
       "\t\t<td>11.05</td>\n",
       "\t\t<td>21.47</td>\n",
       "\t\t<td>71.68</td>\n",
       "\t\t<td>367.0</td>\n",
       "\t\t<td>0.1467</td>\n",
       "\t\t<td>0.1765</td>\n",
       "\t\t<td>0.13</td>\n",
       "\t\t<td>0.05334</td>\n",
       "\t\t<td>0.2533</td>\n",
       "\t\t<td>0.08468</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.98,\"probability_1\":0.02,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86561</td>\n",
       "\t\t<td>13.85</td>\n",
       "\t\t<td>17.21</td>\n",
       "\t\t<td>88.44</td>\n",
       "\t\t<td>588.7</td>\n",
       "\t\t<td>0.08785</td>\n",
       "\t\t<td>0.06136</td>\n",
       "\t\t<td>0.0142</td>\n",
       "\t\t<td>0.01141</td>\n",
       "\t\t<td>0.1614</td>\n",
       "\t\t<td>0.0589</td>\n",
       "\t\t<td>0.2185</td>\n",
       "\t\t<td>0.8561</td>\n",
       "\t\t<td>1.495</td>\n",
       "\t\t<td>17.91</td>\n",
       "\t\t<td>0.004599</td>\n",
       "\t\t<td>0.009169</td>\n",
       "\t\t<td>0.009127</td>\n",
       "\t\t<td>0.004814</td>\n",
       "\t\t<td>0.01247</td>\n",
       "\t\t<td>0.001708</td>\n",
       "\t\t<td>15.49</td>\n",
       "\t\t<td>23.58</td>\n",
       "\t\t<td>100.3</td>\n",
       "\t\t<td>725.9</td>\n",
       "\t\t<td>0.1157</td>\n",
       "\t\t<td>0.135</td>\n",
       "\t\t<td>0.08115</td>\n",
       "\t\t<td>0.05104</td>\n",
       "\t\t<td>0.2364</td>\n",
       "\t\t<td>0.07182</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.94,\"probability_1\":0.06,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>855167</td>\n",
       "\t\t<td>13.44</td>\n",
       "\t\t<td>21.58</td>\n",
       "\t\t<td>86.18</td>\n",
       "\t\t<td>563.0</td>\n",
       "\t\t<td>0.08162</td>\n",
       "\t\t<td>0.06031</td>\n",
       "\t\t<td>0.0311</td>\n",
       "\t\t<td>0.02031</td>\n",
       "\t\t<td>0.1784</td>\n",
       "\t\t<td>0.05587</td>\n",
       "\t\t<td>0.2385</td>\n",
       "\t\t<td>0.8265</td>\n",
       "\t\t<td>1.572</td>\n",
       "\t\t<td>20.53</td>\n",
       "\t\t<td>0.00328</td>\n",
       "\t\t<td>0.01102</td>\n",
       "\t\t<td>0.0139</td>\n",
       "\t\t<td>0.006881</td>\n",
       "\t\t<td>0.0138</td>\n",
       "\t\t<td>0.001286</td>\n",
       "\t\t<td>15.93</td>\n",
       "\t\t<td>30.25</td>\n",
       "\t\t<td>102.5</td>\n",
       "\t\t<td>787.9</td>\n",
       "\t\t<td>0.1094</td>\n",
       "\t\t<td>0.2043</td>\n",
       "\t\t<td>0.2085</td>\n",
       "\t\t<td>0.1112</td>\n",
       "\t\t<td>0.2994</td>\n",
       "\t\t<td>0.07146</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.93,\"probability_1\":0.07,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857156</td>\n",
       "\t\t<td>13.49</td>\n",
       "\t\t<td>22.3</td>\n",
       "\t\t<td>86.91</td>\n",
       "\t\t<td>561.0</td>\n",
       "\t\t<td>0.08752</td>\n",
       "\t\t<td>0.07698</td>\n",
       "\t\t<td>0.04751</td>\n",
       "\t\t<td>0.03384</td>\n",
       "\t\t<td>0.1809</td>\n",
       "\t\t<td>0.05718</td>\n",
       "\t\t<td>0.2338</td>\n",
       "\t\t<td>1.353</td>\n",
       "\t\t<td>1.735</td>\n",
       "\t\t<td>20.2</td>\n",
       "\t\t<td>0.004455</td>\n",
       "\t\t<td>0.01382</td>\n",
       "\t\t<td>0.02095</td>\n",
       "\t\t<td>0.01184</td>\n",
       "\t\t<td>0.01641</td>\n",
       "\t\t<td>0.001956</td>\n",
       "\t\t<td>15.15</td>\n",
       "\t\t<td>31.82</td>\n",
       "\t\t<td>99.0</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.1162</td>\n",
       "\t\t<td>0.1711</td>\n",
       "\t\t<td>0.2282</td>\n",
       "\t\t<td>0.1282</td>\n",
       "\t\t<td>0.2871</td>\n",
       "\t\t<td>0.06917</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>86408</td>\n",
       "\t\t<td>12.63</td>\n",
       "\t\t<td>20.76</td>\n",
       "\t\t<td>82.15</td>\n",
       "\t\t<td>480.4</td>\n",
       "\t\t<td>0.09933</td>\n",
       "\t\t<td>0.1209</td>\n",
       "\t\t<td>0.1065</td>\n",
       "\t\t<td>0.06021</td>\n",
       "\t\t<td>0.1735</td>\n",
       "\t\t<td>0.0707</td>\n",
       "\t\t<td>0.3424</td>\n",
       "\t\t<td>1.803</td>\n",
       "\t\t<td>2.711</td>\n",
       "\t\t<td>20.48</td>\n",
       "\t\t<td>0.01291</td>\n",
       "\t\t<td>0.04042</td>\n",
       "\t\t<td>0.05101</td>\n",
       "\t\t<td>0.02295</td>\n",
       "\t\t<td>0.02144</td>\n",
       "\t\t<td>0.005891</td>\n",
       "\t\t<td>13.33</td>\n",
       "\t\t<td>25.47</td>\n",
       "\t\t<td>89.0</td>\n",
       "\t\t<td>527.4</td>\n",
       "\t\t<td>0.1287</td>\n",
       "\t\t<td>0.225</td>\n",
       "\t\t<td>0.2216</td>\n",
       "\t\t<td>0.1105</td>\n",
       "\t\t<td>0.2226</td>\n",
       "\t\t<td>0.08486</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.77,\"probability_1\":0.23,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "       id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst prediction                                                          json_report\n",
       "0  857343       11.760         21.60           74.72      427.9          0.08637           0.04966         0.01657              0.01115         0.1495                 0.05888     0.4062      1.2100         2.635    28.47       0.005857        0.009758      0.011680           0.007445      0.02406              0.001769         12.98          25.72            82.98       516.5            0.1085            0.08615          0.05523               0.03715          0.2433                  0.06563          0  {\"probability_0\":0.97,\"probability_1\":0.03,\"predicted_diagnosis\":0}\n",
       "1  852631       17.140         16.40          116.00      912.7          0.11860           0.22760         0.22290              0.14010         0.3040                 0.07413     1.0460      0.9760         7.276   111.40       0.008029        0.037990      0.037320           0.023970      0.02308              0.007444         22.25          21.40           152.40      1461.0            0.1545            0.39490          0.38530               0.25500          0.4066                  0.10590          1  {\"probability_0\":0.11,\"probability_1\":0.89,\"predicted_diagnosis\":1}\n",
       "2  857373       13.640         16.34           87.21      571.8          0.07685           0.06059         0.01857              0.01723         0.1353                 0.05953     0.1872      0.9234         1.449    14.55       0.004477        0.011770      0.010790           0.007956      0.01325              0.002551         14.67          23.19            96.08       656.7            0.1089            0.15820          0.10500               0.08586          0.2346                  0.08025          0  {\"probability_0\":0.97,\"probability_1\":0.03,\"predicted_diagnosis\":0}\n",
       "3   91550       11.740         14.69           76.31      426.0          0.08099           0.09661         0.06726              0.02639         0.1499                 0.06758     0.1924      0.6417         1.345    13.04       0.006982        0.039160      0.040170           0.015280      0.02260              0.006822         12.45          17.60            81.25       473.8            0.1073            0.27930          0.26900               0.10560          0.2604                  0.09879          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "4  864033        9.777         16.99           62.50      290.2          0.10370           0.08404         0.04334              0.01778         0.1584                 0.07065     0.4030      1.4240         2.747    22.87       0.013850        0.029320      0.027220           0.010230      0.03281              0.004638         11.05          21.47            71.68       367.0            0.1467            0.17650          0.13000               0.05334          0.2533                  0.08468          0  {\"probability_0\":0.98,\"probability_1\":0.02,\"predicted_diagnosis\":0}\n",
       "5   86561       13.850         17.21           88.44      588.7          0.08785           0.06136         0.01420              0.01141         0.1614                 0.05890     0.2185      0.8561         1.495    17.91       0.004599        0.009169      0.009127           0.004814      0.01247              0.001708         15.49          23.58           100.30       725.9            0.1157            0.13500          0.08115               0.05104          0.2364                  0.07182          0  {\"probability_0\":0.94,\"probability_1\":0.06,\"predicted_diagnosis\":0}\n",
       "6  855167       13.440         21.58           86.18      563.0          0.08162           0.06031         0.03110              0.02031         0.1784                 0.05587     0.2385      0.8265         1.572    20.53       0.003280        0.011020      0.013900           0.006881      0.01380              0.001286         15.93          30.25           102.50       787.9            0.1094            0.20430          0.20850               0.11120          0.2994                  0.07146          0  {\"probability_0\":0.93,\"probability_1\":0.07,\"predicted_diagnosis\":0}\n",
       "7  862965       12.180         20.52           77.22      458.7          0.08013           0.04038         0.02383              0.01770         0.1739                 0.05677     0.1924      1.5710         1.183    14.68       0.005080        0.006098      0.010690           0.006797      0.01447              0.001532         13.34          32.84            84.58       547.8            0.1123            0.08862          0.11450               0.07431          0.2694                  0.06878          0  {\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}\n",
       "8  857156       13.490         22.30           86.91      561.0          0.08752           0.07698         0.04751              0.03384         0.1809                 0.05718     0.2338      1.3530         1.735    20.20       0.004455        0.013820      0.020950           0.011840      0.01641              0.001956         15.15          31.82            99.00       698.8            0.1162            0.17110          0.22820               0.12820          0.2871                  0.06917          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "9   86408       12.630         20.76           82.15      480.4          0.09933           0.12090         0.10650              0.06021         0.1735                 0.07070     0.3424      1.8030         2.711    20.48       0.012910        0.040420      0.051010           0.022950      0.02144              0.005891         13.33          25.47            89.00       527.4            0.1287            0.22500          0.22160               0.11050          0.2226                  0.08486          0  {\"probability_0\":0.77,\"probability_1\":0.23,\"predicted_diagnosis\":0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = byom_predictor.predict(df_test, df_test.columns)\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id_t1</th>\n",
       "\t\t<th>id_t2</th>\n",
       "\t\t<th>diagnosis</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>prediction</th>\n",
       "\t\t<th>json_report</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>871201</td>\n",
       "\t\t<td>871201</td>\n",
       "\t\t<td>1  </td>\n",
       "\t\t<td>19.59</td>\n",
       "\t\t<td>18.15</td>\n",
       "\t\t<td>130.7</td>\n",
       "\t\t<td>1214.0</td>\n",
       "\t\t<td>0.112</td>\n",
       "\t\t<td>0.1666</td>\n",
       "\t\t<td>0.2508</td>\n",
       "\t\t<td>0.1286</td>\n",
       "\t\t<td>0.2027</td>\n",
       "\t\t<td>0.06082</td>\n",
       "\t\t<td>0.7364</td>\n",
       "\t\t<td>1.048</td>\n",
       "\t\t<td>4.792</td>\n",
       "\t\t<td>97.07</td>\n",
       "\t\t<td>0.004057</td>\n",
       "\t\t<td>0.02277</td>\n",
       "\t\t<td>0.04029</td>\n",
       "\t\t<td>0.01303</td>\n",
       "\t\t<td>0.01686</td>\n",
       "\t\t<td>0.003318</td>\n",
       "\t\t<td>26.73</td>\n",
       "\t\t<td>26.39</td>\n",
       "\t\t<td>174.9</td>\n",
       "\t\t<td>2232.0</td>\n",
       "\t\t<td>0.1438</td>\n",
       "\t\t<td>0.3846</td>\n",
       "\t\t<td>0.681</td>\n",
       "\t\t<td>0.2247</td>\n",
       "\t\t<td>0.3643</td>\n",
       "\t\t<td>0.09223</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.02,\"probability_1\":0.98,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>858477</td>\n",
       "\t\t<td>858477</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>8.618</td>\n",
       "\t\t<td>11.79</td>\n",
       "\t\t<td>54.34</td>\n",
       "\t\t<td>224.5</td>\n",
       "\t\t<td>0.09752</td>\n",
       "\t\t<td>0.05272</td>\n",
       "\t\t<td>0.02061</td>\n",
       "\t\t<td>0.007799</td>\n",
       "\t\t<td>0.1683</td>\n",
       "\t\t<td>0.07187</td>\n",
       "\t\t<td>0.1559</td>\n",
       "\t\t<td>0.5796</td>\n",
       "\t\t<td>1.046</td>\n",
       "\t\t<td>8.322</td>\n",
       "\t\t<td>0.01011</td>\n",
       "\t\t<td>0.01055</td>\n",
       "\t\t<td>0.01981</td>\n",
       "\t\t<td>0.005742</td>\n",
       "\t\t<td>0.0209</td>\n",
       "\t\t<td>0.002788</td>\n",
       "\t\t<td>9.507</td>\n",
       "\t\t<td>15.4</td>\n",
       "\t\t<td>59.9</td>\n",
       "\t\t<td>274.9</td>\n",
       "\t\t<td>0.1733</td>\n",
       "\t\t<td>0.1239</td>\n",
       "\t\t<td>0.1168</td>\n",
       "\t\t<td>0.04419</td>\n",
       "\t\t<td>0.322</td>\n",
       "\t\t<td>0.09026</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857373</td>\n",
       "\t\t<td>857373</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>13.64</td>\n",
       "\t\t<td>16.34</td>\n",
       "\t\t<td>87.21</td>\n",
       "\t\t<td>571.8</td>\n",
       "\t\t<td>0.07685</td>\n",
       "\t\t<td>0.06059</td>\n",
       "\t\t<td>0.01857</td>\n",
       "\t\t<td>0.01723</td>\n",
       "\t\t<td>0.1353</td>\n",
       "\t\t<td>0.05953</td>\n",
       "\t\t<td>0.1872</td>\n",
       "\t\t<td>0.9234</td>\n",
       "\t\t<td>1.449</td>\n",
       "\t\t<td>14.55</td>\n",
       "\t\t<td>0.004477</td>\n",
       "\t\t<td>0.01177</td>\n",
       "\t\t<td>0.01079</td>\n",
       "\t\t<td>0.007956</td>\n",
       "\t\t<td>0.01325</td>\n",
       "\t\t<td>0.002551</td>\n",
       "\t\t<td>14.67</td>\n",
       "\t\t<td>23.19</td>\n",
       "\t\t<td>96.08</td>\n",
       "\t\t<td>656.7</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.1582</td>\n",
       "\t\t<td>0.105</td>\n",
       "\t\t<td>0.08586</td>\n",
       "\t\t<td>0.2346</td>\n",
       "\t\t<td>0.08025</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.97,\"probability_1\":0.03,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9012315</td>\n",
       "\t\t<td>9012315</td>\n",
       "\t\t<td>1  </td>\n",
       "\t\t<td>16.35</td>\n",
       "\t\t<td>23.29</td>\n",
       "\t\t<td>109.0</td>\n",
       "\t\t<td>840.4</td>\n",
       "\t\t<td>0.09742</td>\n",
       "\t\t<td>0.1497</td>\n",
       "\t\t<td>0.1811</td>\n",
       "\t\t<td>0.08773</td>\n",
       "\t\t<td>0.2175</td>\n",
       "\t\t<td>0.06218</td>\n",
       "\t\t<td>0.4312</td>\n",
       "\t\t<td>1.022</td>\n",
       "\t\t<td>2.972</td>\n",
       "\t\t<td>45.5</td>\n",
       "\t\t<td>0.005635</td>\n",
       "\t\t<td>0.03917</td>\n",
       "\t\t<td>0.06072</td>\n",
       "\t\t<td>0.01656</td>\n",
       "\t\t<td>0.03197</td>\n",
       "\t\t<td>0.004085</td>\n",
       "\t\t<td>19.38</td>\n",
       "\t\t<td>31.03</td>\n",
       "\t\t<td>129.3</td>\n",
       "\t\t<td>1165.0</td>\n",
       "\t\t<td>0.1415</td>\n",
       "\t\t<td>0.4665</td>\n",
       "\t\t<td>0.7087</td>\n",
       "\t\t<td>0.2248</td>\n",
       "\t\t<td>0.4824</td>\n",
       "\t\t<td>0.09614</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.03,\"probability_1\":0.97,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>85713702</td>\n",
       "\t\t<td>85713702</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>8.196</td>\n",
       "\t\t<td>16.84</td>\n",
       "\t\t<td>51.71</td>\n",
       "\t\t<td>201.9</td>\n",
       "\t\t<td>0.086</td>\n",
       "\t\t<td>0.05943</td>\n",
       "\t\t<td>0.01588</td>\n",
       "\t\t<td>0.005917</td>\n",
       "\t\t<td>0.1769</td>\n",
       "\t\t<td>0.06503</td>\n",
       "\t\t<td>0.1563</td>\n",
       "\t\t<td>0.9567</td>\n",
       "\t\t<td>1.094</td>\n",
       "\t\t<td>8.205</td>\n",
       "\t\t<td>0.008968</td>\n",
       "\t\t<td>0.01646</td>\n",
       "\t\t<td>0.01588</td>\n",
       "\t\t<td>0.005917</td>\n",
       "\t\t<td>0.02574</td>\n",
       "\t\t<td>0.002582</td>\n",
       "\t\t<td>8.964</td>\n",
       "\t\t<td>21.96</td>\n",
       "\t\t<td>57.26</td>\n",
       "\t\t<td>242.2</td>\n",
       "\t\t<td>0.1297</td>\n",
       "\t\t<td>0.1357</td>\n",
       "\t\t<td>0.0688</td>\n",
       "\t\t<td>0.02564</td>\n",
       "\t\t<td>0.3105</td>\n",
       "\t\t<td>0.07409</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>911320501</td>\n",
       "\t\t<td>911320501</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>11.6</td>\n",
       "\t\t<td>18.36</td>\n",
       "\t\t<td>73.88</td>\n",
       "\t\t<td>412.7</td>\n",
       "\t\t<td>0.08508</td>\n",
       "\t\t<td>0.05855</td>\n",
       "\t\t<td>0.03367</td>\n",
       "\t\t<td>0.01777</td>\n",
       "\t\t<td>0.1516</td>\n",
       "\t\t<td>0.05859</td>\n",
       "\t\t<td>0.1816</td>\n",
       "\t\t<td>0.7656</td>\n",
       "\t\t<td>1.303</td>\n",
       "\t\t<td>12.89</td>\n",
       "\t\t<td>0.006709</td>\n",
       "\t\t<td>0.01701</td>\n",
       "\t\t<td>0.0208</td>\n",
       "\t\t<td>0.007497</td>\n",
       "\t\t<td>0.02124</td>\n",
       "\t\t<td>0.002768</td>\n",
       "\t\t<td>12.77</td>\n",
       "\t\t<td>24.02</td>\n",
       "\t\t<td>82.68</td>\n",
       "\t\t<td>495.1</td>\n",
       "\t\t<td>0.1342</td>\n",
       "\t\t<td>0.1808</td>\n",
       "\t\t<td>0.186</td>\n",
       "\t\t<td>0.08288</td>\n",
       "\t\t<td>0.321</td>\n",
       "\t\t<td>0.07863</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>8812877</td>\n",
       "\t\t<td>8812877</td>\n",
       "\t\t<td>1  </td>\n",
       "\t\t<td>15.75</td>\n",
       "\t\t<td>20.25</td>\n",
       "\t\t<td>102.6</td>\n",
       "\t\t<td>761.3</td>\n",
       "\t\t<td>0.1025</td>\n",
       "\t\t<td>0.1204</td>\n",
       "\t\t<td>0.1147</td>\n",
       "\t\t<td>0.06462</td>\n",
       "\t\t<td>0.1935</td>\n",
       "\t\t<td>0.06303</td>\n",
       "\t\t<td>0.3473</td>\n",
       "\t\t<td>0.9209</td>\n",
       "\t\t<td>2.244</td>\n",
       "\t\t<td>32.19</td>\n",
       "\t\t<td>0.004766</td>\n",
       "\t\t<td>0.02374</td>\n",
       "\t\t<td>0.02384</td>\n",
       "\t\t<td>0.008637</td>\n",
       "\t\t<td>0.01772</td>\n",
       "\t\t<td>0.003131</td>\n",
       "\t\t<td>19.56</td>\n",
       "\t\t<td>30.29</td>\n",
       "\t\t<td>125.9</td>\n",
       "\t\t<td>1088.0</td>\n",
       "\t\t<td>0.1552</td>\n",
       "\t\t<td>0.448</td>\n",
       "\t\t<td>0.3976</td>\n",
       "\t\t<td>0.1479</td>\n",
       "\t\t<td>0.3993</td>\n",
       "\t\t<td>0.1064</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.12,\"probability_1\":0.88,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>863270</td>\n",
       "\t\t<td>863270</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>12.36</td>\n",
       "\t\t<td>18.54</td>\n",
       "\t\t<td>79.01</td>\n",
       "\t\t<td>466.7</td>\n",
       "\t\t<td>0.08477</td>\n",
       "\t\t<td>0.06815</td>\n",
       "\t\t<td>0.02643</td>\n",
       "\t\t<td>0.01921</td>\n",
       "\t\t<td>0.1602</td>\n",
       "\t\t<td>0.06066</td>\n",
       "\t\t<td>0.1199</td>\n",
       "\t\t<td>0.8944</td>\n",
       "\t\t<td>0.8484</td>\n",
       "\t\t<td>9.227</td>\n",
       "\t\t<td>0.003457</td>\n",
       "\t\t<td>0.01047</td>\n",
       "\t\t<td>0.01167</td>\n",
       "\t\t<td>0.005558</td>\n",
       "\t\t<td>0.01251</td>\n",
       "\t\t<td>0.001356</td>\n",
       "\t\t<td>13.29</td>\n",
       "\t\t<td>27.49</td>\n",
       "\t\t<td>85.56</td>\n",
       "\t\t<td>544.1</td>\n",
       "\t\t<td>0.1184</td>\n",
       "\t\t<td>0.1963</td>\n",
       "\t\t<td>0.1937</td>\n",
       "\t\t<td>0.08442</td>\n",
       "\t\t<td>0.2983</td>\n",
       "\t\t<td>0.07185</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>889719</td>\n",
       "\t\t<td>889719</td>\n",
       "\t\t<td>1  </td>\n",
       "\t\t<td>17.19</td>\n",
       "\t\t<td>22.07</td>\n",
       "\t\t<td>111.6</td>\n",
       "\t\t<td>928.3</td>\n",
       "\t\t<td>0.09726</td>\n",
       "\t\t<td>0.08995</td>\n",
       "\t\t<td>0.09061</td>\n",
       "\t\t<td>0.06527</td>\n",
       "\t\t<td>0.1867</td>\n",
       "\t\t<td>0.0558</td>\n",
       "\t\t<td>0.4203</td>\n",
       "\t\t<td>0.7383</td>\n",
       "\t\t<td>2.819</td>\n",
       "\t\t<td>45.42</td>\n",
       "\t\t<td>0.004493</td>\n",
       "\t\t<td>0.01206</td>\n",
       "\t\t<td>0.02048</td>\n",
       "\t\t<td>0.009875</td>\n",
       "\t\t<td>0.01144</td>\n",
       "\t\t<td>0.001575</td>\n",
       "\t\t<td>21.58</td>\n",
       "\t\t<td>29.33</td>\n",
       "\t\t<td>140.5</td>\n",
       "\t\t<td>1436.0</td>\n",
       "\t\t<td>0.1558</td>\n",
       "\t\t<td>0.2567</td>\n",
       "\t\t<td>0.3889</td>\n",
       "\t\t<td>0.1984</td>\n",
       "\t\t<td>0.3216</td>\n",
       "\t\t<td>0.0757</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.02,\"probability_1\":0.98,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "       id_t1      id_t2 diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst prediction                                                          json_report\n",
       "0     871201     871201       1         19.590         18.15          130.70     1214.0          0.11200           0.16660         0.25080             0.128600         0.2027                 0.06082     0.7364      1.0480        4.7920   97.070       0.004057        0.022770       0.04029           0.013030      0.01686              0.003318        26.730          26.39           174.90      2232.0            0.1438            0.38460           0.6810               0.22470          0.3643                  0.09223          1  {\"probability_0\":0.02,\"probability_1\":0.98,\"predicted_diagnosis\":1}\n",
       "1     858477     858477       0          8.618         11.79           54.34      224.5          0.09752           0.05272         0.02061             0.007799         0.1683                 0.07187     0.1559      0.5796        1.0460    8.322       0.010110        0.010550       0.01981           0.005742      0.02090              0.002788         9.507          15.40            59.90       274.9            0.1733            0.12390           0.1168               0.04419          0.3220                  0.09026          0  {\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}\n",
       "2     857373     857373       0         13.640         16.34           87.21      571.8          0.07685           0.06059         0.01857             0.017230         0.1353                 0.05953     0.1872      0.9234        1.4490   14.550       0.004477        0.011770       0.01079           0.007956      0.01325              0.002551        14.670          23.19            96.08       656.7            0.1089            0.15820           0.1050               0.08586          0.2346                  0.08025          0  {\"probability_0\":0.97,\"probability_1\":0.03,\"predicted_diagnosis\":0}\n",
       "3     862965     862965       0         12.180         20.52           77.22      458.7          0.08013           0.04038         0.02383             0.017700         0.1739                 0.05677     0.1924      1.5710        1.1830   14.680       0.005080        0.006098       0.01069           0.006797      0.01447              0.001532        13.340          32.84            84.58       547.8            0.1123            0.08862           0.1145               0.07431          0.2694                  0.06878          0  {\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}\n",
       "4    9012315    9012315       1         16.350         23.29          109.00      840.4          0.09742           0.14970         0.18110             0.087730         0.2175                 0.06218     0.4312      1.0220        2.9720   45.500       0.005635        0.039170       0.06072           0.016560      0.03197              0.004085        19.380          31.03           129.30      1165.0            0.1415            0.46650           0.7087               0.22480          0.4824                  0.09614          1  {\"probability_0\":0.03,\"probability_1\":0.97,\"predicted_diagnosis\":1}\n",
       "5   85713702   85713702       0          8.196         16.84           51.71      201.9          0.08600           0.05943         0.01588             0.005917         0.1769                 0.06503     0.1563      0.9567        1.0940    8.205       0.008968        0.016460       0.01588           0.005917      0.02574              0.002582         8.964          21.96            57.26       242.2            0.1297            0.13570           0.0688               0.02564          0.3105                  0.07409          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "6  911320501  911320501       0         11.600         18.36           73.88      412.7          0.08508           0.05855         0.03367             0.017770         0.1516                 0.05859     0.1816      0.7656        1.3030   12.890       0.006709        0.017010       0.02080           0.007497      0.02124              0.002768        12.770          24.02            82.68       495.1            0.1342            0.18080           0.1860               0.08288          0.3210                  0.07863          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "7    8812877    8812877       1         15.750         20.25          102.60      761.3          0.10250           0.12040         0.11470             0.064620         0.1935                 0.06303     0.3473      0.9209        2.2440   32.190       0.004766        0.023740       0.02384           0.008637      0.01772              0.003131        19.560          30.29           125.90      1088.0            0.1552            0.44800           0.3976               0.14790          0.3993                  0.10640          1  {\"probability_0\":0.12,\"probability_1\":0.88,\"predicted_diagnosis\":1}\n",
       "8     863270     863270       0         12.360         18.54           79.01      466.7          0.08477           0.06815         0.02643             0.019210         0.1602                 0.06066     0.1199      0.8944        0.8484    9.227       0.003457        0.010470       0.01167           0.005558      0.01251              0.001356        13.290          27.49            85.56       544.1            0.1184            0.19630           0.1937               0.08442          0.2983                  0.07185          0  {\"probability_0\":0.96,\"probability_1\":0.04,\"predicted_diagnosis\":0}\n",
       "9     889719     889719       1         17.190         22.07          111.60      928.3          0.09726           0.08995         0.09061             0.065270         0.1867                 0.05580     0.4203      0.7383        2.8190   45.420       0.004493        0.012060       0.02048           0.009875      0.01144              0.001575        21.580          29.33           140.50      1436.0            0.1558            0.25670           0.3889               0.19840          0.3216                  0.07570          1  {\"probability_0\":0.02,\"probability_1\":0.98,\"predicted_diagnosis\":1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join = df.select([\"id\",\"diagnosis\"])\n",
    "df_final = df_join.merge(right=df_predict, how='inner', on=\"id\", lsuffix = 't1', rsuffix='t2')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>9. Evaluate the model</b></p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>9.1 Classification Evaluator</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ClassificationEvaluator() function evaluate and emits various metrics of classification model based on its predictions on the data. Apart from accuracy, the secondary output data returns micro, macro, and weighted-averaged metrics of precision, recall, and F1-score values.</p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = df_final.assign(drop_columns=True,\n",
    "                          id = df_final.id_t1,\n",
    "                          diagnosis = df_final.diagnosis.cast(type_=INTEGER),\n",
    "                          prediction = df_final.prediction.cast(type_=INTEGER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>SeqNum</th>\n",
       "\t\t<th>Metric</th>\n",
       "\t\t<th>MetricValue</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>3</td>\n",
       "\t\t<td>Micro-Recall</td>\n",
       "\t\t<td>0.9210526315789473</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>5</td>\n",
       "\t\t<td>Macro-Precision</td>\n",
       "\t\t<td>0.9153846153846155</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6</td>\n",
       "\t\t<td>Macro-Recall</td>\n",
       "\t\t<td>0.910472972972973</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>7</td>\n",
       "\t\t<td>Macro-F1</td>\n",
       "\t\t<td>0.9128366324016651</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9</td>\n",
       "\t\t<td>Weighted-Recall</td>\n",
       "\t\t<td>0.9210526315789473</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>10</td>\n",
       "\t\t<td>Weighted-F1</td>\n",
       "\t\t<td>0.9208178887453108</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>8</td>\n",
       "\t\t<td>Weighted-Precision</td>\n",
       "\t\t<td>0.9207377417903734</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>4</td>\n",
       "\t\t<td>Micro-F1</td>\n",
       "\t\t<td>0.9210526315789473</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>2</td>\n",
       "\t\t<td>Micro-Precision</td>\n",
       "\t\t<td>0.9210526315789473</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>Accuracy</td>\n",
       "\t\t<td>0.9210526315789473</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "   SeqNum              Metric  MetricValue\n",
       "0       3        Micro-Recall     0.921053\n",
       "1       5     Macro-Precision     0.915385\n",
       "2       6        Macro-Recall     0.910473\n",
       "3       7            Macro-F1     0.912837\n",
       "4       9     Weighted-Recall     0.921053\n",
       "5      10         Weighted-F1     0.920818\n",
       "6       8  Weighted-Precision     0.920738\n",
       "7       4            Micro-F1     0.921053\n",
       "8       2     Micro-Precision     0.921053\n",
       "9       1            Accuracy     0.921053"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassificationEvaluator_obj = ClassificationEvaluator(data=df_final,\n",
    "                                                          observation_column='diagnosis',\n",
    "                                                          prediction_column='prediction',\n",
    "                                                          labels=['0', '1'])\n",
    "classeval_df = ClassificationEvaluator_obj.output_data\n",
    "classeval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>9.2 Show AUC-ROC Curve</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The <a href = 'https://docs.teradata.com/search/all?query=TD_ROC&content-lang=en-US'>ROC</a> curve shows the performance of a binary classification model as its discrimination threshold varies. For a range of thresholds, the curve plots the true positive rate against false-positive rate.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This function accepts a set of prediction-actual pairs as input and calculates the following values for a range of discrimination thresholds.</p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>True-positive rate (TPR)</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>False-positive rate (FPR)</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>The area under the ROC curve (AUC)</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>Gini coefficient</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>Other details are mentioned in the documentation</li>\n",
    "    </ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>threshold_value</th>\n",
       "\t\t<th>tpr</th>\n",
       "\t\t<th>fpr</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.04081632653061224</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.08163265306122448</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.1020408163265306</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.12244897959183673</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.16326530612244897</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.18367346938775508</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.14285714285714285</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.061224489795918366</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.02040816326530612</td>\n",
       "\t\t<td>0.875</td>\n",
       "\t\t<td>0.05405405405405406</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>1.0</td>\n",
       "\t\t<td>1.0</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "   threshold_value    tpr       fpr\n",
       "0         0.040816  0.875  0.054054\n",
       "1         0.081633  0.875  0.054054\n",
       "2         0.102041  0.875  0.054054\n",
       "3         0.122449  0.875  0.054054\n",
       "4         0.163265  0.875  0.054054\n",
       "5         0.183673  0.875  0.054054\n",
       "6         0.142857  0.875  0.054054\n",
       "7         0.061224  0.875  0.054054\n",
       "8         0.020408  0.875  0.054054\n",
       "9         0.000000  1.000  1.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from teradataml import ROC \n",
    "roc_df = ROC(data = pred_df, \n",
    "                    probability_column = \"prediction\",\n",
    "                    observation_column = \"diagnosis\",\n",
    "                    positive_class=\"1\"\n",
    "                    )\n",
    "roc_df.output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868243243243243"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_df.result.get_values()[0][0]\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Plot ROC Curves</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm=pred_df.to_pandas(all_rows=True)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_cm['diagnosis'], df_cm['prediction'])\n",
    "# auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The closer the ROC curve is to the upper left corner of the graph, the higher the accuracy of the test because in the upper left corner, the sensitivity = 1 and the false positive rate = 0 (specificity = 1). The ideal ROC curve thus has an AUC = 1.0. As seen in the above graph the AUC for both the models is close to 1 so the accuracy of both models is very good. </p>\n",
    "\n",
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>9.3 Show Confusion Matrix</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Confusion Matrix is a performance measurement for machine learning classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Confusion matrices represent counts from predicted and actual values. The output âTNâ stands for True Negative which shows the number of negative examples classified accurately. Similarly, âTPâ stands for True Positive which indicates the number of positive examples classified accurately. The term âFPâ shows False Positive value, i.e., the number of actual negative examples classified as positive; and âFNâ means a False Negative value which is the number of actual positive examples classified as negative.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_df = pred_df.to_pandas(all_rows=True)\n",
    "cm = confusion_matrix(confusion_matrix_df['diagnosis'], confusion_matrix_df['prediction'])\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['DoesNotHaveCancer', 'HasCancer'],)\n",
    "cmd.plot(cmap='Blues', colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Conclusion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Thus we have seen that with the Teradata Vantage API_Request feature, we can connect to VertexAI endpoints through a function to do real-time scoring on data. A VertexAI endpoint was used to orchestrate model training and deploy the solutionâs ML model. Also the model can be stored in Vantage and then used to score in Vantage. Vantage and ClearScape Anlaytics has helped drastically reduce data preparation, model development, and testing time, while allowing for much more frequent and iterative testing and tuning to ensure maximum life-critical accuracy.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>10. Cleanup</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the following code to clean up tables and databases created for this demonstration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed objects related to DEMO_CancerPrediction. That ran for 0:00:02.86\n"
     ]
    }
   ],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_CancerPrediction');\" \n",
    "#Takes 40 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>**Note: </b><i>Please make sure to delete the VertexAI model and endpoints after use using the code in below cell. If these are not deleted the cost will keep increasing till the time it is not deleted.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n",
      "Undeploy Endpoint model backing LRO: projects/323844706402/locations/us-central1/endpoints/8774997792117489664/operations/6220319118101315584\n",
      "Endpoint model undeployed. Resource name: projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n",
      "Deleting Endpoint : projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n",
      "Endpoint deleted. . Resource name: projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n",
      "Deleting Endpoint resource: projects/323844706402/locations/us-central1/endpoints/8774997792117489664\n",
      "Delete Endpoint backing LRO: projects/323844706402/locations/us-central1/operations/8971455540471267328\n",
      "Endpoint resource projects/323844706402/locations/us-central1/endpoints/8774997792117489664 deleted.\n"
     ]
    }
   ],
   "source": [
    "predictor.cloudObj.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_tdapi_context(\n",
    "    gcp_context,\n",
    "    delete_byom_models=True,\n",
    "    table_name=\"tdapiclient_byom_models\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>Required Materials</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Letâs look at the elements we have available for reference for this notebook:</p>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Dataset:</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The dataset for this analysis has been taken from \n",
    "<a href = 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic'>Breast Cancer Wisconsin (Diagnostic) - UCI Machine Learning Repository.</a>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Filters:</b> \n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Industry:</b> Healthcare</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Functionality:</b> Machine Learning</li> \n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Use Case:</b> Prediction Analysis</li></p>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Related Resources:</b>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://usc-word-edit.officeapps.live.com/we/%E2%80%A2%09https:/www.teradata.com/Blogs/Predicting-Heart-Failure-with-Teradata'>Saving Lives, Saving Costs: Predicting Heart Failure with Teradata</a> </li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://www.teradata.com/Blogs/Hyper-scale-time-series-forecasting-done-right'>Hyper-scale time series forecasting done right</a></li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://www.teradata.com/Blogs/Forecasting-COVID-19-Using-Teradata-Vantage'>Forecasting COVID-19 Using Teradata Vantage</a></li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analyticsâ¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Â© 2023, 2024 Teradata. All rights reserved.\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
