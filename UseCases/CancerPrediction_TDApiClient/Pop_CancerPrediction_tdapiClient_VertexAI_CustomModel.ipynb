{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial;color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Cancer Prediction using Google Vertex AI with TDApiClient using Custom Model\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://storage.googleapis.com/clearscape_analytics_demo_data/DEMO_Logo/teradata.svg\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>This is a Beta Release of this notebook!</b></p>   \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>   \n",
    "This should be considered a Beta Release.  Every effort has been made to ensure it's functionality and completeness.  If you discover any issue with any part of this notebook, your suggestions will be reviewed and, if approved, merged in the next round of notebook commits.   \n",
    "<br>   \n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>How to submit a Review of this Notebook</b></p>   \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>   \n",
    "First, please read through and execute the notebook.   \n",
    "<br> \n",
    "If you think the notebook is fine as it is, great.  Please send us a quick email and let us know. When the notebook is taken out of beta, this paragraph will be removed and the Beta designation the index page will be removed.   \n",
    "<br> \n",
    "If you find something that you question or you think needs to be changed or if you think it's great as it is:   \n",
    "</p>       \n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>   \n",
    "  <li>Send us an email: <a href=\"mailto:ClearScapeAnalyticsNotebookReviews@Teradata.com?subject=Beta Notebook Review\">Click here.</a></li>   \n",
    "  <li>Please include the name of the notebook in email.</li>   \n",
    "  <li>Include a screen shot or a clear description of the section in the notebook you would like us to look at.</li>   \n",
    "  <li>Paste the screen shot or enter the description of the section into the email.</li>   \n",
    "  <li>Describe how you would change it.</li>   \n",
    "  <li>Send It!</li>   \n",
    "</ol>   \n",
    "</p>   \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If we have any follow-up questions, we'll reach out to you at the return email address. </p>   \n",
    "<hr style=\"height:4px;border:none;background-color:#00233C;\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Introduction</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Worldwide, breast cancer is the most common type of cancer in women and the second highest in terms of mortality rates. Diagnosis of breast cancer is performed when an abnormal lump is found (from self-examination or x-ray) or a tiny speck of calcium is seen (on an x-ray). After a suspicious lump is found, the doctor will conduct a diagnosis to determine whether it is cancerous and, if so, whether it has spread to other parts of the body. Vantage Clearscape Analytics provides us various machine learning techniques to develop predictive models for cancer diagnosis. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass, using descriptions that define the characteristics of the cell nuclei.</p> \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Vertex AI empowers machine learning developers, data scientists, and data engineers to take their projects from ideation to deployment, quickly and cost-effectively. With the Teradata Vantage API_Request feature directly from Vantage, we can connect to these Vertex AI endpoints through a function to do real-time scoring on data. Google provides the Vertex AI Python SDK, which includes TrainingJob classes for training models on the Vertex AI platform. For the workflow, training runs on the Vertex AI platform. The model is then deployed on a Vertex AI online endpoint and on Teradata Vantage.</p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Business Values</b></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Comprehensive health predictions and a reduced number of false positive and false negative results.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Reduced cost to patients and hospitals caused by cancer.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Identify patterns and symptoms leading to breast cancer to ensure early intervention.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Advanced research and development stemming from the results of the data and models produced.</li></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Why Vantage?</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Machine Learning and AI have a proven track record of improving patient outcomes and well-being across the entire healthcare industry. Traditional approaches to data preparation, model development, and deployment rely on manual, error-prone processes that prevent enterprises from realizing the true value of these tools and techniques.</p>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>However, Vantage provides these same proven data preparation and machine learning capabilities, integrated as native ClearScape Analytic functions.  This allows organizations to drastically reduce data preparation, model development, and testing time, while allowing for much more frequent and iterative testing and tuning to ensure maximum life-critical accuracy.</p>\n",
    " \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Furthermore, the exact same development pipeline can be deployed seamlessly to production, eliminating the traditional development-to-deployment gap in the ML and AI industry.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>1. Initial setup</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Install packages</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the section, we will install the TDApiClient packages along with the necessary packages needed for the TDApiClient package.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# # '%%capture' suppresses the display of installation steps of the following packages\n",
    "!pip install TDApiClient\n",
    "!pip install --upgrade numpy pyopenssl\n",
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>The above statements may need to be uncommented if you run the notebooks on a platform other than ClearScape Analytics Experience that does not have the libraries installed.Â If you uncomment those installs, be sure to restart the kernel after executing those lines to bring the installed libraries into memory. The simplest way to restart the Kernel is by typing zero zero: <b> 0 0</b></i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Setting up Google Cloud Vertex AI credentials</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>This notebook cannot be executed if you do not have a Vertex AI service account with the necessary permissions. Information regarding the Vertex AI account and the necessary permissions is given below</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Required Vertex AI Credentials:</b>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GOOGLE_APPLICATION_CREDENTIALS:</b> The json file which has credentials for the service account.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_REGION:</b> Region for the service account and the storage bucket.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_PROJECT_ID:</b> Project ID</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_TD_AUTH_OBJ:</b> Authorization object created in the database for Google Cloud</li>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>How to Get These Inputs:</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>GOOGLE_APPLICATION_CREDENTIALS, GCP_REGION, GCP_PROJECT_ID and GCP_TD_AUTH_OBJ: These credentials are related to your Google account and subscription. If you already have an Google account and an active subscription for the Vertex AI service account, you can find these credentials in the Google cloud portal. Here's how:\n",
    "    \n",
    "<ul style=\"font-size: 16px; font-family: Arial;;color:#00233C\">\n",
    "            <li><a href=\"https://developers.google.com/workspace/guides/create-credentials#:~:text=Click%20Keys%20%3E%20Add%20key%20%3E%20Create,json%20in%20your%20working%20directory.\">Download json with GCP Application credentials</a></li>\n",
    "            <li><a href=\"https://cloud.google.com/compute/docs/regions-zones\">Find your GCP Region</a></li>\n",
    "            <li><a href=\"https://cloud.google.com/resource-manager/docs/creating-managing-projects\">Find your Project ID</a></li>\n",
    "    <li><a href=\"https://docs.teradata.com/r/Enterprise_IntelliFlex_VMware/SQL-Data-Definition-Language-Syntax-and-Examples/Authorization-Statements-for-External-Routines/CREATE-AUTHORIZATION-and-REPLACE-AUTHORIZATION/CREATE-AUTHORIZATION-and-REPLACE-AUTHORIZATION-Syntax\">GCP Authorization object in Teradata database</a></li>\n",
    "        </ul>\n",
    "</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Below is the sample SQL for creation of the GCP Authorization object in Teradata database</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CREATE AUTHORIZATION Auth_S3_USR_IVO\n",
    "USER 'service-account-name@project-id.iam.gserviceaccount.com'\n",
    "PASSWORD '-----BEGIN PRIVATE KEY-----\\n\n",
    "MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQCyfg3398iOxjt...almSAvk9SqPoyZ\n",
    "R7JJFs=\\n -----END PRIVATE KEY-----\\n';\n",
    "</code>\n",
    "</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will also have to create a Google cloud bucket where we will be uploading our code and artifacts when using the Vertex AI models. If you already have a bucket created you can use the same else to create a new bucket check this <a href=\"https://cloud.google.com/storage/docs/creating-buckets?_gl=1*lboq4y*_ga*MTQyNzA2MDA1OC4xNzEwMzEzMTcw*_ga_WH2QY8WWF5*MTcxMTA4MDY3MC4xOS4xLjE3MTEwODIzMzguMC4wLjA.&_ga=2.269165169.-1427060058.1710313170\">link</a>. We also need to check the permissions needed for these buckets to be used by the Vertex AI API calls ad mentioned <a href=\"https://cloud.google.com/vertex-ai/docs/general/access-control\"> here.</a></p> \n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Since we are going to use the Vertex AI Pre Built Containers and access them using the APIs, we will have to Enable the API as mentioned <a href= \"https://cloud.google.com/vertex-ai/docs/start/cloud-environment\">here</a></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can also create a new service account using the<a href= \" https://cloud.google.com/vertex-ai/docs/general/custom-service-account\"> Vertex AI custom service account </a></p>    \n",
    "   \n",
    "</p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In case you do not have a Google cloud account you can create one by following the steps mentioned <a href=\"https://cloud.google.com/free/?utm_source=google&utm_medium=cpc&utm_campaign=japac-IN-all-en-dr-BKWS-all-cloud-trial-EXA-dr-1605216&utm_content=text-ad-none-none-DEV_c-CRE_634320416384-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt+-GCP-General-google+cloud+account-how-KWID_43700074200360382-kwd-310570337956&userloc_9062101-network_g&utm_term=KW_how+to+create+google+cloud+account&gad_source=1&gclid=Cj0KCQjw2PSvBhDjARIsAKc2cgOOL7cfu4LRkX9-nIT7sVizw8ubKIl2aYUXkAdbxxFnXpHo6lYk7CAaAiTNEALw_wcB&gclsrc=aw.ds&hl=en\">here</a>.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>2. Connect to Vantage</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the section, we import the required libraries and set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/jovyan/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from teradataml import *\n",
    "from tdapiclient import create_tdapi_context, TDApiClient, remove_tdapi_context\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "configure.byom_install_location = \"mldb\"\n",
    "configure.val_install_location = \"val\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will be prompted to provide the password. We will enter the password, press the Enter key, and then use the down arrow to go to the next cell. Begin running steps with Shift + Enter keys.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing setup ...\n",
      "Setup complete\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter password:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Logon successful\n",
      "Connected as: xxxxxsql://demo_user:xxxxx@host.docker.internal/dbc\n",
      "Engine(teradatasql://demo_user:***@host.docker.internal)\n"
     ]
    }
   ],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "execute_sql('''SET query_band='DEMO=CancerPrediction_TDApiClient_VertexAI_CustomModel.ipynb;' UPDATE FOR SESSION; ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>3. Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We have provided data for this demo on cloud storage. We have the option of either running the demo using foreign tables to access the data without using any storage on our environment or downloading the data to local storage, which may yield somewhat faster execution. However, we need to consider available storage. There are two statements in the following cell, and one is commented out. We may switch which mode we choose by changing the comment string.</p>   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That ran for   0:00:21.98 with 10 statements and 0 errors. \n"
     ]
    }
   ],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_CancerPrediction_cloud');\"\n",
    " # Takes about 50 seconds\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_CancerPrediction_local');\"\n",
    " # Takes about 2 minute 30 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional step â We should execute the below step only if we want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have:  #databases=2 #tables=11 #views=4  You have used 31.1 MB of 30,677.9 MB available - 0.1%  ... Space Usage OK\n",
      " \n",
      "   Database Name                  #tables  #views     Avail MB      Used MB\n",
      "   demo_user                           10       3  30,143.0 MB      30.9 MB \n",
      "   DEMO_CancerPrediction                0       1       0.0 MB       0.0 MB \n",
      "   DEMO_CancerPrediction_db             1       0     534.9 MB       0.3 MB \n"
     ]
    }
   ],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>4. Analyze the raw data set</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Let us start by creating a teradataml dataframe. A \"Virtual DataFrame\" that points directly to the dataset in Vantage.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>diagnosis</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>914862</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>15.04</td>\n",
       "\t\t<td>16.74</td>\n",
       "\t\t<td>98.73</td>\n",
       "\t\t<td>689.4</td>\n",
       "\t\t<td>0.09883</td>\n",
       "\t\t<td>0.1364</td>\n",
       "\t\t<td>0.07721</td>\n",
       "\t\t<td>0.06142</td>\n",
       "\t\t<td>0.1668</td>\n",
       "\t\t<td>0.06869</td>\n",
       "\t\t<td>0.372</td>\n",
       "\t\t<td>0.8423</td>\n",
       "\t\t<td>2.304</td>\n",
       "\t\t<td>34.84</td>\n",
       "\t\t<td>0.004123</td>\n",
       "\t\t<td>0.01819</td>\n",
       "\t\t<td>0.01996</td>\n",
       "\t\t<td>0.01004</td>\n",
       "\t\t<td>0.01055</td>\n",
       "\t\t<td>0.003237</td>\n",
       "\t\t<td>16.76</td>\n",
       "\t\t<td>20.43</td>\n",
       "\t\t<td>109.7</td>\n",
       "\t\t<td>856.9</td>\n",
       "\t\t<td>0.1135</td>\n",
       "\t\t<td>0.2176</td>\n",
       "\t\t<td>0.1856</td>\n",
       "\t\t<td>0.1018</td>\n",
       "\t\t<td>0.2177</td>\n",
       "\t\t<td>0.08549</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>88249602</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>14.03</td>\n",
       "\t\t<td>21.25</td>\n",
       "\t\t<td>89.79</td>\n",
       "\t\t<td>603.4</td>\n",
       "\t\t<td>0.0907</td>\n",
       "\t\t<td>0.06945</td>\n",
       "\t\t<td>0.01462</td>\n",
       "\t\t<td>0.01896</td>\n",
       "\t\t<td>0.1517</td>\n",
       "\t\t<td>0.05835</td>\n",
       "\t\t<td>0.2589</td>\n",
       "\t\t<td>1.503</td>\n",
       "\t\t<td>1.667</td>\n",
       "\t\t<td>22.07</td>\n",
       "\t\t<td>0.007389</td>\n",
       "\t\t<td>0.01383</td>\n",
       "\t\t<td>0.007302</td>\n",
       "\t\t<td>0.01004</td>\n",
       "\t\t<td>0.01263</td>\n",
       "\t\t<td>0.002925</td>\n",
       "\t\t<td>15.33</td>\n",
       "\t\t<td>30.28</td>\n",
       "\t\t<td>98.27</td>\n",
       "\t\t<td>715.5</td>\n",
       "\t\t<td>0.1287</td>\n",
       "\t\t<td>0.1513</td>\n",
       "\t\t<td>0.06231</td>\n",
       "\t\t<td>0.07963</td>\n",
       "\t\t<td>0.2226</td>\n",
       "\t\t<td>0.07617</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>855133</td>\n",
       "\t\t<td>M </td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t\t<td>1.214</td>\n",
       "\t\t<td>2.188</td>\n",
       "\t\t<td>8.077</td>\n",
       "\t\t<td>106.0</td>\n",
       "\t\t<td>0.006883</td>\n",
       "\t\t<td>0.01094</td>\n",
       "\t\t<td>0.01818</td>\n",
       "\t\t<td>0.01917</td>\n",
       "\t\t<td>0.007882</td>\n",
       "\t\t<td>0.001754</td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>8711003</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>12.25</td>\n",
       "\t\t<td>17.94</td>\n",
       "\t\t<td>78.27</td>\n",
       "\t\t<td>460.3</td>\n",
       "\t\t<td>0.08654</td>\n",
       "\t\t<td>0.06679</td>\n",
       "\t\t<td>0.03885</td>\n",
       "\t\t<td>0.02331</td>\n",
       "\t\t<td>0.197</td>\n",
       "\t\t<td>0.06228</td>\n",
       "\t\t<td>0.22</td>\n",
       "\t\t<td>0.9823</td>\n",
       "\t\t<td>1.484</td>\n",
       "\t\t<td>16.51</td>\n",
       "\t\t<td>0.005518</td>\n",
       "\t\t<td>0.01562</td>\n",
       "\t\t<td>0.01994</td>\n",
       "\t\t<td>0.007924</td>\n",
       "\t\t<td>0.01799</td>\n",
       "\t\t<td>0.002484</td>\n",
       "\t\t<td>13.59</td>\n",
       "\t\t<td>25.22</td>\n",
       "\t\t<td>86.6</td>\n",
       "\t\t<td>564.2</td>\n",
       "\t\t<td>0.1217</td>\n",
       "\t\t<td>0.1788</td>\n",
       "\t\t<td>0.1943</td>\n",
       "\t\t<td>0.08211</td>\n",
       "\t\t<td>0.3113</td>\n",
       "\t\t<td>0.08132</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>872608</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>9.904</td>\n",
       "\t\t<td>18.06</td>\n",
       "\t\t<td>64.6</td>\n",
       "\t\t<td>302.4</td>\n",
       "\t\t<td>0.09699</td>\n",
       "\t\t<td>0.1294</td>\n",
       "\t\t<td>0.1307</td>\n",
       "\t\t<td>0.03716</td>\n",
       "\t\t<td>0.1669</td>\n",
       "\t\t<td>0.08116</td>\n",
       "\t\t<td>0.4311</td>\n",
       "\t\t<td>2.261</td>\n",
       "\t\t<td>3.132</td>\n",
       "\t\t<td>27.48</td>\n",
       "\t\t<td>0.01286</td>\n",
       "\t\t<td>0.08808</td>\n",
       "\t\t<td>0.1197</td>\n",
       "\t\t<td>0.0246</td>\n",
       "\t\t<td>0.0388</td>\n",
       "\t\t<td>0.01792</td>\n",
       "\t\t<td>11.26</td>\n",
       "\t\t<td>24.39</td>\n",
       "\t\t<td>73.07</td>\n",
       "\t\t<td>390.2</td>\n",
       "\t\t<td>0.1301</td>\n",
       "\t\t<td>0.295</td>\n",
       "\t\t<td>0.3486</td>\n",
       "\t\t<td>0.0991</td>\n",
       "\t\t<td>0.2614</td>\n",
       "\t\t<td>0.1162</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>858986</td>\n",
       "\t\t<td>M </td>\n",
       "\t\t<td>14.25</td>\n",
       "\t\t<td>22.15</td>\n",
       "\t\t<td>96.42</td>\n",
       "\t\t<td>645.7</td>\n",
       "\t\t<td>0.1049</td>\n",
       "\t\t<td>0.2008</td>\n",
       "\t\t<td>0.2135</td>\n",
       "\t\t<td>0.08653</td>\n",
       "\t\t<td>0.1949</td>\n",
       "\t\t<td>0.07292</td>\n",
       "\t\t<td>0.7036</td>\n",
       "\t\t<td>1.268</td>\n",
       "\t\t<td>5.373</td>\n",
       "\t\t<td>60.78</td>\n",
       "\t\t<td>0.009407</td>\n",
       "\t\t<td>0.07056</td>\n",
       "\t\t<td>0.06899</td>\n",
       "\t\t<td>0.01848</td>\n",
       "\t\t<td>0.017</td>\n",
       "\t\t<td>0.006113</td>\n",
       "\t\t<td>17.67</td>\n",
       "\t\t<td>29.51</td>\n",
       "\t\t<td>119.1</td>\n",
       "\t\t<td>959.5</td>\n",
       "\t\t<td>0.164</td>\n",
       "\t\t<td>0.6247</td>\n",
       "\t\t<td>0.6922</td>\n",
       "\t\t<td>0.1785</td>\n",
       "\t\t<td>0.2844</td>\n",
       "\t\t<td>0.1132</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>90317302</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>10.26</td>\n",
       "\t\t<td>12.22</td>\n",
       "\t\t<td>65.75</td>\n",
       "\t\t<td>321.6</td>\n",
       "\t\t<td>0.09996</td>\n",
       "\t\t<td>0.07542</td>\n",
       "\t\t<td>0.01923</td>\n",
       "\t\t<td>0.01968</td>\n",
       "\t\t<td>0.18</td>\n",
       "\t\t<td>0.06569</td>\n",
       "\t\t<td>0.1911</td>\n",
       "\t\t<td>0.5477</td>\n",
       "\t\t<td>1.348</td>\n",
       "\t\t<td>11.88</td>\n",
       "\t\t<td>0.005682</td>\n",
       "\t\t<td>0.01365</td>\n",
       "\t\t<td>0.008496</td>\n",
       "\t\t<td>0.006929</td>\n",
       "\t\t<td>0.01938</td>\n",
       "\t\t<td>0.002371</td>\n",
       "\t\t<td>11.38</td>\n",
       "\t\t<td>15.65</td>\n",
       "\t\t<td>73.23</td>\n",
       "\t\t<td>394.5</td>\n",
       "\t\t<td>0.1343</td>\n",
       "\t\t<td>0.165</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.06696</td>\n",
       "\t\t<td>0.2937</td>\n",
       "\t\t<td>0.07722</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>85713702</td>\n",
       "\t\t<td>B </td>\n",
       "\t\t<td>8.196</td>\n",
       "\t\t<td>16.84</td>\n",
       "\t\t<td>51.71</td>\n",
       "\t\t<td>201.9</td>\n",
       "\t\t<td>0.086</td>\n",
       "\t\t<td>0.05943</td>\n",
       "\t\t<td>0.01588</td>\n",
       "\t\t<td>0.005917</td>\n",
       "\t\t<td>0.1769</td>\n",
       "\t\t<td>0.06503</td>\n",
       "\t\t<td>0.1563</td>\n",
       "\t\t<td>0.9567</td>\n",
       "\t\t<td>1.094</td>\n",
       "\t\t<td>8.205</td>\n",
       "\t\t<td>0.008968</td>\n",
       "\t\t<td>0.01646</td>\n",
       "\t\t<td>0.01588</td>\n",
       "\t\t<td>0.005917</td>\n",
       "\t\t<td>0.02574</td>\n",
       "\t\t<td>0.002582</td>\n",
       "\t\t<td>8.964</td>\n",
       "\t\t<td>21.96</td>\n",
       "\t\t<td>57.26</td>\n",
       "\t\t<td>242.2</td>\n",
       "\t\t<td>0.1297</td>\n",
       "\t\t<td>0.1357</td>\n",
       "\t\t<td>0.0688</td>\n",
       "\t\t<td>0.02564</td>\n",
       "\t\t<td>0.3105</td>\n",
       "\t\t<td>0.07409</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>852973</td>\n",
       "\t\t<td>M </td>\n",
       "\t\t<td>15.3</td>\n",
       "\t\t<td>25.27</td>\n",
       "\t\t<td>102.4</td>\n",
       "\t\t<td>732.4</td>\n",
       "\t\t<td>0.1082</td>\n",
       "\t\t<td>0.1697</td>\n",
       "\t\t<td>0.1683</td>\n",
       "\t\t<td>0.08751</td>\n",
       "\t\t<td>0.1926</td>\n",
       "\t\t<td>0.0654</td>\n",
       "\t\t<td>0.439</td>\n",
       "\t\t<td>1.012</td>\n",
       "\t\t<td>3.498</td>\n",
       "\t\t<td>43.5</td>\n",
       "\t\t<td>0.005233</td>\n",
       "\t\t<td>0.03057</td>\n",
       "\t\t<td>0.03576</td>\n",
       "\t\t<td>0.01083</td>\n",
       "\t\t<td>0.01768</td>\n",
       "\t\t<td>0.002967</td>\n",
       "\t\t<td>20.27</td>\n",
       "\t\t<td>36.71</td>\n",
       "\t\t<td>149.3</td>\n",
       "\t\t<td>1269.0</td>\n",
       "\t\t<td>0.1641</td>\n",
       "\t\t<td>0.611</td>\n",
       "\t\t<td>0.6335</td>\n",
       "\t\t<td>0.2024</td>\n",
       "\t\t<td>0.4027</td>\n",
       "\t\t<td>0.09876</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>869104</td>\n",
       "\t\t<td>M </td>\n",
       "\t\t<td>16.11</td>\n",
       "\t\t<td>18.05</td>\n",
       "\t\t<td>105.1</td>\n",
       "\t\t<td>813.0</td>\n",
       "\t\t<td>0.09721</td>\n",
       "\t\t<td>0.1137</td>\n",
       "\t\t<td>0.09447</td>\n",
       "\t\t<td>0.05943</td>\n",
       "\t\t<td>0.1861</td>\n",
       "\t\t<td>0.06248</td>\n",
       "\t\t<td>0.7049</td>\n",
       "\t\t<td>1.332</td>\n",
       "\t\t<td>4.533</td>\n",
       "\t\t<td>74.08</td>\n",
       "\t\t<td>0.00677</td>\n",
       "\t\t<td>0.01938</td>\n",
       "\t\t<td>0.03067</td>\n",
       "\t\t<td>0.01167</td>\n",
       "\t\t<td>0.01875</td>\n",
       "\t\t<td>0.003434</td>\n",
       "\t\t<td>19.92</td>\n",
       "\t\t<td>25.27</td>\n",
       "\t\t<td>129.0</td>\n",
       "\t\t<td>1233.0</td>\n",
       "\t\t<td>0.1314</td>\n",
       "\t\t<td>0.2236</td>\n",
       "\t\t<td>0.2802</td>\n",
       "\t\t<td>0.1216</td>\n",
       "\t\t<td>0.2792</td>\n",
       "\t\t<td>0.08158</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "914862          B        15.040         16.74           98.73      689.4          0.09883           0.13640         0.07721             0.061420         0.1668                 0.06869     0.3720      0.8423         2.304   34.840       0.004123         0.01819      0.019960           0.010040     0.010550              0.003237        16.760          20.43           109.70       856.9           0.11350            0.21760          0.18560               0.10180          0.2177                  0.08549\n",
       "88249602        B        14.030         21.25           89.79      603.4          0.09070           0.06945         0.01462             0.018960         0.1517                 0.05835     0.2589      1.5030         1.667   22.070       0.007389         0.01383      0.007302           0.010040     0.012630              0.002925        15.330          30.28            98.27       715.5           0.12870            0.15130          0.06231               0.07963          0.2226                  0.07617\n",
       "855133          M        14.990         25.20           95.54      698.8          0.09387           0.05131         0.02398             0.028990         0.1565                 0.05504     1.2140      2.1880         8.077  106.000       0.006883         0.01094      0.018180           0.019170     0.007882              0.001754        14.990          25.20            95.54       698.8           0.09387            0.05131          0.02398               0.02899          0.1565                  0.05504\n",
       "8711003         B        12.250         17.94           78.27      460.3          0.08654           0.06679         0.03885             0.023310         0.1970                 0.06228     0.2200      0.9823         1.484   16.510       0.005518         0.01562      0.019940           0.007924     0.017990              0.002484        13.590          25.22            86.60       564.2           0.12170            0.17880          0.19430               0.08211          0.3113                  0.08132\n",
       "872608          B         9.904         18.06           64.60      302.4          0.09699           0.12940         0.13070             0.037160         0.1669                 0.08116     0.4311      2.2610         3.132   27.480       0.012860         0.08808      0.119700           0.024600     0.038800              0.017920        11.260          24.39            73.07       390.2           0.13010            0.29500          0.34860               0.09910          0.2614                  0.11620\n",
       "858986          M        14.250         22.15           96.42      645.7          0.10490           0.20080         0.21350             0.086530         0.1949                 0.07292     0.7036      1.2680         5.373   60.780       0.009407         0.07056      0.068990           0.018480     0.017000              0.006113        17.670          29.51           119.10       959.5           0.16400            0.62470          0.69220               0.17850          0.2844                  0.11320\n",
       "90317302        B        10.260         12.22           65.75      321.6          0.09996           0.07542         0.01923             0.019680         0.1800                 0.06569     0.1911      0.5477         1.348   11.880       0.005682         0.01365      0.008496           0.006929     0.019380              0.002371        11.380          15.65            73.23       394.5           0.13430            0.16500          0.08615               0.06696          0.2937                  0.07722\n",
       "85713702        B         8.196         16.84           51.71      201.9          0.08600           0.05943         0.01588             0.005917         0.1769                 0.06503     0.1563      0.9567         1.094    8.205       0.008968         0.01646      0.015880           0.005917     0.025740              0.002582         8.964          21.96            57.26       242.2           0.12970            0.13570          0.06880               0.02564          0.3105                  0.07409\n",
       "852973          M        15.300         25.27          102.40      732.4          0.10820           0.16970         0.16830             0.087510         0.1926                 0.06540     0.4390      1.0120         3.498   43.500       0.005233         0.03057      0.035760           0.010830     0.017680              0.002967        20.270          36.71           149.30      1269.0           0.16410            0.61100          0.63350               0.20240          0.4027                  0.09876\n",
       "869104          M        16.110         18.05          105.10      813.0          0.09721           0.11370         0.09447             0.059430         0.1861                 0.06248     0.7049      1.3320         4.533   74.080       0.006770         0.01938      0.030670           0.011670     0.018750              0.003434        19.920          25.27           129.00      1233.0           0.13140            0.22360          0.28020               0.12160          0.2792                  0.08158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a teradataml dataframe using the table.\n",
    "df = DataFrame(in_schema(\"DEMO_CancerPrediction\",\"Patient_Data\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>5. Data Preparation</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Label encoding a categorical data column is done to re-express existing values of a column (variable) into a new coding scheme or to correct data quality problems and focus an analysis of a particular value. It allows\n",
    "    for mapping individual values, NULL values, or any number of remaining values (ELSE option) to a new value, a NULL value or the same value. Label encoding supports charter, numeric, and date type columns.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Output of this function is passed to \"label_encode\" argument of \"Transform\" function from Vantage Analytic Library.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target column using label encoder.\n",
    "from teradataml import LabelEncoder \n",
    "rc = LabelEncoder(values=(\"M\", 1), columns=[\"diagnosis\"], default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns_names= Retain(columns=[\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\"smoothness_mean\",\n",
    "                                       \"compactness_mean\",\"concavity_mean\",\"concave_points_mean\",\"symmetry_mean\",\n",
    "                                       \"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\"area_se\",\n",
    "                                       \"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave_points_se\",\n",
    "                                       \"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\n",
    "                                       \"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\n",
    "                                       \"concavity_worst\",\"concave_points_worst\",\"symmetry_worst\",\n",
    "                                       \"fractal_dimension_worst\" ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'> The Variable Transformation analysis reads a teradataml DataFrame and produces an output containing transformed columns. This is useful when preparing data for input to an analytic algorithm. For example, a K-Means Clustering algorithm typically produces better results when the input columns are first converted to their Z-Score values to put all input variables on an equal footing, regardless of their magnitude.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Function supports following transformations:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Binning</code> - Binning replaces a continuous numeric column with a categorical one to produce ordinal values (for example, numeric categorical values where order is meaningful).</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Derive</code> - The Derive transformation requires the free-form transformation be specified as a formula.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>One Hot Encoding</code> - One Hot Encoding is useful when a categorical data element must be re-expressed as one or more numeric data elements, creating a binary numeric field for each categorical data value.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Missing Value</code> Treatment or Null Replacement.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Label Encoding</code> - Allows to re-express existing values of a categorical data column (variable) into a new coding scheme or to correct data quality problems and focus an analysis on a value.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Min-Max Scaling</code> - Limits the upper and lower boundaries of the data in a continuous numeric column using a linear rescaling function based on maximum and minimum data values.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Retain</code> - Allows copying of one or more columns into the final analytic data set.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>Sigmoid</code> - Provides rescaling of continuous numeric data using a type of sigmoid or s-shaped function.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>ZScore</code> - Provides rescaling of continuous numeric data using Z-Scores.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we will be using the Lable Encode option for the diagnosis column</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>diagnosis</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>91544002</td>\n",
       "\t\t<td>11.06</td>\n",
       "\t\t<td>17.12</td>\n",
       "\t\t<td>71.25</td>\n",
       "\t\t<td>366.5</td>\n",
       "\t\t<td>0.1194</td>\n",
       "\t\t<td>0.1071</td>\n",
       "\t\t<td>0.04063</td>\n",
       "\t\t<td>0.04268</td>\n",
       "\t\t<td>0.1954</td>\n",
       "\t\t<td>0.07976</td>\n",
       "\t\t<td>0.1779</td>\n",
       "\t\t<td>1.03</td>\n",
       "\t\t<td>1.318</td>\n",
       "\t\t<td>12.3</td>\n",
       "\t\t<td>0.01262</td>\n",
       "\t\t<td>0.02348</td>\n",
       "\t\t<td>0.018</td>\n",
       "\t\t<td>0.01285</td>\n",
       "\t\t<td>0.0222</td>\n",
       "\t\t<td>0.008313</td>\n",
       "\t\t<td>11.69</td>\n",
       "\t\t<td>20.74</td>\n",
       "\t\t<td>76.08</td>\n",
       "\t\t<td>411.1</td>\n",
       "\t\t<td>0.1662</td>\n",
       "\t\t<td>0.2031</td>\n",
       "\t\t<td>0.1256</td>\n",
       "\t\t<td>0.09514</td>\n",
       "\t\t<td>0.278</td>\n",
       "\t\t<td>0.1168</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>905686</td>\n",
       "\t\t<td>11.89</td>\n",
       "\t\t<td>21.17</td>\n",
       "\t\t<td>76.39</td>\n",
       "\t\t<td>433.8</td>\n",
       "\t\t<td>0.09773</td>\n",
       "\t\t<td>0.0812</td>\n",
       "\t\t<td>0.02555</td>\n",
       "\t\t<td>0.02179</td>\n",
       "\t\t<td>0.2019</td>\n",
       "\t\t<td>0.0629</td>\n",
       "\t\t<td>0.2747</td>\n",
       "\t\t<td>1.203</td>\n",
       "\t\t<td>1.93</td>\n",
       "\t\t<td>19.53</td>\n",
       "\t\t<td>0.009895</td>\n",
       "\t\t<td>0.03053</td>\n",
       "\t\t<td>0.0163</td>\n",
       "\t\t<td>0.009276</td>\n",
       "\t\t<td>0.02258</td>\n",
       "\t\t<td>0.002272</td>\n",
       "\t\t<td>13.05</td>\n",
       "\t\t<td>27.21</td>\n",
       "\t\t<td>85.09</td>\n",
       "\t\t<td>522.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2187</td>\n",
       "\t\t<td>0.1164</td>\n",
       "\t\t<td>0.08263</td>\n",
       "\t\t<td>0.3075</td>\n",
       "\t\t<td>0.07351</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>863270</td>\n",
       "\t\t<td>12.36</td>\n",
       "\t\t<td>18.54</td>\n",
       "\t\t<td>79.01</td>\n",
       "\t\t<td>466.7</td>\n",
       "\t\t<td>0.08477</td>\n",
       "\t\t<td>0.06815</td>\n",
       "\t\t<td>0.02643</td>\n",
       "\t\t<td>0.01921</td>\n",
       "\t\t<td>0.1602</td>\n",
       "\t\t<td>0.06066</td>\n",
       "\t\t<td>0.1199</td>\n",
       "\t\t<td>0.8944</td>\n",
       "\t\t<td>0.8484</td>\n",
       "\t\t<td>9.227</td>\n",
       "\t\t<td>0.003457</td>\n",
       "\t\t<td>0.01047</td>\n",
       "\t\t<td>0.01167</td>\n",
       "\t\t<td>0.005558</td>\n",
       "\t\t<td>0.01251</td>\n",
       "\t\t<td>0.001356</td>\n",
       "\t\t<td>13.29</td>\n",
       "\t\t<td>27.49</td>\n",
       "\t\t<td>85.56</td>\n",
       "\t\t<td>544.1</td>\n",
       "\t\t<td>0.1184</td>\n",
       "\t\t<td>0.1963</td>\n",
       "\t\t<td>0.1937</td>\n",
       "\t\t<td>0.08442</td>\n",
       "\t\t<td>0.2983</td>\n",
       "\t\t<td>0.07185</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>89742801</td>\n",
       "\t\t<td>17.06</td>\n",
       "\t\t<td>21.0</td>\n",
       "\t\t<td>111.8</td>\n",
       "\t\t<td>918.6</td>\n",
       "\t\t<td>0.1119</td>\n",
       "\t\t<td>0.1056</td>\n",
       "\t\t<td>0.1508</td>\n",
       "\t\t<td>0.09934</td>\n",
       "\t\t<td>0.1727</td>\n",
       "\t\t<td>0.06071</td>\n",
       "\t\t<td>0.8161</td>\n",
       "\t\t<td>2.129</td>\n",
       "\t\t<td>6.076</td>\n",
       "\t\t<td>87.17</td>\n",
       "\t\t<td>0.006455</td>\n",
       "\t\t<td>0.01797</td>\n",
       "\t\t<td>0.04502</td>\n",
       "\t\t<td>0.01744</td>\n",
       "\t\t<td>0.01829</td>\n",
       "\t\t<td>0.003733</td>\n",
       "\t\t<td>20.99</td>\n",
       "\t\t<td>33.15</td>\n",
       "\t\t<td>143.2</td>\n",
       "\t\t<td>1362.0</td>\n",
       "\t\t<td>0.1449</td>\n",
       "\t\t<td>0.2053</td>\n",
       "\t\t<td>0.392</td>\n",
       "\t\t<td>0.1827</td>\n",
       "\t\t<td>0.2623</td>\n",
       "\t\t<td>0.07599</td>\n",
       "\t\t<td>1  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>869224</td>\n",
       "\t\t<td>12.9</td>\n",
       "\t\t<td>15.92</td>\n",
       "\t\t<td>83.74</td>\n",
       "\t\t<td>512.2</td>\n",
       "\t\t<td>0.08677</td>\n",
       "\t\t<td>0.09509</td>\n",
       "\t\t<td>0.04894</td>\n",
       "\t\t<td>0.03088</td>\n",
       "\t\t<td>0.1778</td>\n",
       "\t\t<td>0.06235</td>\n",
       "\t\t<td>0.2143</td>\n",
       "\t\t<td>0.7712</td>\n",
       "\t\t<td>1.689</td>\n",
       "\t\t<td>16.64</td>\n",
       "\t\t<td>0.005324</td>\n",
       "\t\t<td>0.01563</td>\n",
       "\t\t<td>0.0151</td>\n",
       "\t\t<td>0.007584</td>\n",
       "\t\t<td>0.02104</td>\n",
       "\t\t<td>0.001887</td>\n",
       "\t\t<td>14.48</td>\n",
       "\t\t<td>21.82</td>\n",
       "\t\t<td>97.17</td>\n",
       "\t\t<td>643.8</td>\n",
       "\t\t<td>0.1312</td>\n",
       "\t\t<td>0.2548</td>\n",
       "\t\t<td>0.209</td>\n",
       "\t\t<td>0.1012</td>\n",
       "\t\t<td>0.3549</td>\n",
       "\t\t<td>0.08118</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9013579</td>\n",
       "\t\t<td>13.46</td>\n",
       "\t\t<td>28.21</td>\n",
       "\t\t<td>85.89</td>\n",
       "\t\t<td>562.1</td>\n",
       "\t\t<td>0.07517</td>\n",
       "\t\t<td>0.04726</td>\n",
       "\t\t<td>0.01271</td>\n",
       "\t\t<td>0.01117</td>\n",
       "\t\t<td>0.1421</td>\n",
       "\t\t<td>0.05763</td>\n",
       "\t\t<td>0.1689</td>\n",
       "\t\t<td>1.15</td>\n",
       "\t\t<td>1.4</td>\n",
       "\t\t<td>14.91</td>\n",
       "\t\t<td>0.004942</td>\n",
       "\t\t<td>0.01203</td>\n",
       "\t\t<td>0.007508</td>\n",
       "\t\t<td>0.005179</td>\n",
       "\t\t<td>0.01442</td>\n",
       "\t\t<td>0.001684</td>\n",
       "\t\t<td>14.69</td>\n",
       "\t\t<td>35.63</td>\n",
       "\t\t<td>97.11</td>\n",
       "\t\t<td>680.6</td>\n",
       "\t\t<td>0.1108</td>\n",
       "\t\t<td>0.1457</td>\n",
       "\t\t<td>0.07934</td>\n",
       "\t\t<td>0.05781</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.07061</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9012315</td>\n",
       "\t\t<td>16.35</td>\n",
       "\t\t<td>23.29</td>\n",
       "\t\t<td>109.0</td>\n",
       "\t\t<td>840.4</td>\n",
       "\t\t<td>0.09742</td>\n",
       "\t\t<td>0.1497</td>\n",
       "\t\t<td>0.1811</td>\n",
       "\t\t<td>0.08773</td>\n",
       "\t\t<td>0.2175</td>\n",
       "\t\t<td>0.06218</td>\n",
       "\t\t<td>0.4312</td>\n",
       "\t\t<td>1.022</td>\n",
       "\t\t<td>2.972</td>\n",
       "\t\t<td>45.5</td>\n",
       "\t\t<td>0.005635</td>\n",
       "\t\t<td>0.03917</td>\n",
       "\t\t<td>0.06072</td>\n",
       "\t\t<td>0.01656</td>\n",
       "\t\t<td>0.03197</td>\n",
       "\t\t<td>0.004085</td>\n",
       "\t\t<td>19.38</td>\n",
       "\t\t<td>31.03</td>\n",
       "\t\t<td>129.3</td>\n",
       "\t\t<td>1165.0</td>\n",
       "\t\t<td>0.1415</td>\n",
       "\t\t<td>0.4665</td>\n",
       "\t\t<td>0.7087</td>\n",
       "\t\t<td>0.2248</td>\n",
       "\t\t<td>0.4824</td>\n",
       "\t\t<td>0.09614</td>\n",
       "\t\t<td>1  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>901303</td>\n",
       "\t\t<td>16.17</td>\n",
       "\t\t<td>16.07</td>\n",
       "\t\t<td>106.3</td>\n",
       "\t\t<td>788.5</td>\n",
       "\t\t<td>0.0988</td>\n",
       "\t\t<td>0.1438</td>\n",
       "\t\t<td>0.06651</td>\n",
       "\t\t<td>0.05397</td>\n",
       "\t\t<td>0.199</td>\n",
       "\t\t<td>0.06572</td>\n",
       "\t\t<td>0.1745</td>\n",
       "\t\t<td>0.489</td>\n",
       "\t\t<td>1.349</td>\n",
       "\t\t<td>14.91</td>\n",
       "\t\t<td>0.00451</td>\n",
       "\t\t<td>0.01812</td>\n",
       "\t\t<td>0.01951</td>\n",
       "\t\t<td>0.01196</td>\n",
       "\t\t<td>0.01934</td>\n",
       "\t\t<td>0.003696</td>\n",
       "\t\t<td>16.97</td>\n",
       "\t\t<td>19.14</td>\n",
       "\t\t<td>113.1</td>\n",
       "\t\t<td>861.5</td>\n",
       "\t\t<td>0.1235</td>\n",
       "\t\t<td>0.255</td>\n",
       "\t\t<td>0.2114</td>\n",
       "\t\t<td>0.1251</td>\n",
       "\t\t<td>0.3153</td>\n",
       "\t\t<td>0.0896</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>87930</td>\n",
       "\t\t<td>12.47</td>\n",
       "\t\t<td>18.6</td>\n",
       "\t\t<td>81.09</td>\n",
       "\t\t<td>481.9</td>\n",
       "\t\t<td>0.09965</td>\n",
       "\t\t<td>0.1058</td>\n",
       "\t\t<td>0.08005</td>\n",
       "\t\t<td>0.03821</td>\n",
       "\t\t<td>0.1925</td>\n",
       "\t\t<td>0.06373</td>\n",
       "\t\t<td>0.3961</td>\n",
       "\t\t<td>1.044</td>\n",
       "\t\t<td>2.497</td>\n",
       "\t\t<td>30.29</td>\n",
       "\t\t<td>0.006953</td>\n",
       "\t\t<td>0.01911</td>\n",
       "\t\t<td>0.02701</td>\n",
       "\t\t<td>0.01037</td>\n",
       "\t\t<td>0.01782</td>\n",
       "\t\t<td>0.003586</td>\n",
       "\t\t<td>14.97</td>\n",
       "\t\t<td>24.64</td>\n",
       "\t\t<td>96.05</td>\n",
       "\t\t<td>677.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2378</td>\n",
       "\t\t<td>0.2671</td>\n",
       "\t\t<td>0.1015</td>\n",
       "\t\t<td>0.3014</td>\n",
       "\t\t<td>0.0875</td>\n",
       "\t\t<td>0  </td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "        id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst diagnosis\n",
       "0   879830        17.01         20.26          109.70      904.3          0.08772           0.07304         0.06950              0.05390         0.2026                 0.05223     0.5858      0.8554         4.106    68.46       0.005038         0.01503       0.01946           0.011230      0.02294              0.002581         19.80          25.05           130.00      1210.0            0.1111             0.1486           0.1932               0.10960          0.3275                  0.06469       1  \n",
       "1   889719        17.19         22.07          111.60      928.3          0.09726           0.08995         0.09061              0.06527         0.1867                 0.05580     0.4203      0.7383         2.819    45.42       0.004493         0.01206       0.02048           0.009875      0.01144              0.001575         21.58          29.33           140.50      1436.0            0.1558             0.2567           0.3889               0.19840          0.3216                  0.07570       1  \n",
       "2   865432        14.50         10.89           94.28      640.7          0.11010           0.10990         0.08842              0.05778         0.1856                 0.06402     0.2929      0.8570         1.928    24.19       0.003818         0.01276       0.02882           0.012000      0.01910              0.002808         15.70          15.98           102.80       745.5            0.1313             0.1788           0.2560               0.12210          0.2889                  0.08006       0  \n",
       "3  8910988        21.75         20.99          147.30     1491.0          0.09401           0.19610         0.21950              0.10880         0.1721                 0.06194     1.1670      1.3520         8.867   156.80       0.005687         0.04960       0.06329           0.015610      0.01924              0.004614         28.19          28.18           195.90      2384.0            0.1272             0.4725           0.5807               0.18410          0.2833                  0.08858       1  \n",
       "4   911150        14.53         19.34           94.25      659.7          0.08388           0.07800         0.08817              0.02925         0.1473                 0.05746     0.2535      1.3540         1.994    23.04       0.004147         0.02048       0.03379           0.008848      0.01394              0.002327         16.30          28.39           108.10       830.5            0.1089             0.2649           0.3779               0.09594          0.2471                  0.07463       0  \n",
       "5   904971        10.94         18.59           70.39      370.0          0.10040           0.07460         0.04944              0.02932         0.1486                 0.06615     0.3796      1.7430         3.018    25.78       0.009519         0.02134       0.01990           0.011550      0.02079              0.002701         12.40          25.58            82.76       472.4            0.1363             0.1644           0.1412               0.07887          0.2251                  0.07732       0  \n",
       "6   857438        15.10         22.02           97.26      712.8          0.09056           0.07081         0.05253              0.03334         0.1616                 0.05684     0.3105      0.8339         2.097    29.91       0.004675         0.01030       0.01603           0.009222      0.01095              0.001629         18.10          31.69           117.70      1030.0            0.1389             0.2057           0.2712               0.15300          0.2675                  0.07873       1  \n",
       "7   895633        16.26         21.88          107.50      826.8          0.11650           0.12830         0.17990              0.07981         0.1869                 0.06532     0.5706      1.4570         2.961    57.72       0.010560         0.03756       0.05839           0.011860      0.04022              0.006187         17.73          25.21           113.70       975.2            0.1426             0.2116           0.3344               0.10470          0.2736                  0.07953       1  \n",
       "8   902975        12.21         14.09           78.78      462.0          0.08108           0.07823         0.06839              0.02534         0.1646                 0.06154     0.2666      0.8309         2.097    19.96       0.004405         0.03026       0.04344           0.010870      0.01921              0.004622         13.13          19.29            87.65       529.9            0.1026             0.2431           0.3076               0.09140          0.2677                  0.08824       0  \n",
       "9   855625        19.07         24.81          128.30     1104.0          0.09081           0.21900         0.21070              0.09961         0.2310                 0.06343     0.9811      1.6660         8.830   104.90       0.006548         0.10060       0.09723           0.026380      0.05333              0.007646         24.09          33.17           177.40      1651.0            0.1247             0.7444           0.7242               0.24930          0.4670                  0.10380       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = valib.Transform(data=df, label_encode=rc,index_columns=\"id\",unique_index=True,retain=feature_columns_names)\n",
    "df=data.result\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We use the sample function on teradataml dataframe. This function allows to sample few rows from dataframe directly or based on conditions. It creates a new column 'sampleid' which has a unique id for each sample, it helps to uniquely identify each sample.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 samples of input data - sample 1 will have 80% of total rows and sample 2  will have 20% of total rows.\n",
    "cancer_sample = df.sample(frac=[0.80, 0.20], seed=42)\n",
    "df_train = cancer_sample[cancer_sample.sampleid == \"1\"].drop(\"sampleid\", axis = 1)\n",
    "df_test = cancer_sample[cancer_sample.sampleid == \"2\"].drop(\"sampleid\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>6. Setup TDApiClient and Teradata contexts for Google Vertex AI</b></p>\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The Google Vertex AI teradataml extension library (TDApiClient) uses Vantage DataFrame to train Google Vertex AI models.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Enable users to prepare the training data by leveraging Teradataâs Python based in-DB analytics functions.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Leveraging teradataml and Vertex AI Python SDK capabilities which allow users to create model over Vertex AI directly from Vantage.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>Once created models are deployed as endpoint in Google Cloud or over Vantage, business users can get access of Vertex AI analytic services for real-time scoring directly from Vantage.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Create the following environment variables before invoking this API. Required environment variables:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GOOGLE_APPLICATION_CREDENTIALS:</b> Specifies the path to the JSON file containing the Google Cloud service account credentials.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_REGION:</b> Specifies the location of the Google Cloud project.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><i><b>**Note :- The region for the VertexAI Service account and the region in which the bucket is created should be same</b></i></li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_PROJECT_ID:</b> Specifies the Project ID of the Google Cloud project.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>GCP_TD_AUTH_OBJ:</b> Specifies the name of the Google Cloud authorization object in Vantage.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>**Please enter your valid GCP credentials.</b></p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Name of the json file which has credentials: clearscape-production-99fb6484153e.json\n",
      "GCP Region:  us-central1\n",
      "Enter the GCP project ID:  clearscape-production\n",
      "Enter the Authorization object name along with database name:  gs_tables_db.auth_for_vertext\n"
     ]
    }
   ],
   "source": [
    "credentials_json = input(\"Name of the json file which has credentials:\")\n",
    "region = input(\"GCP Region: \")\n",
    "project_id = input(\"Enter the GCP project ID: \")\n",
    "td_auth_object = input(\"Enter the Authorization object name along with database name: \")\n",
    "\n",
    "# Example of the required values --- these are not valid values \n",
    "# credentials_json = \"path/to/service/account/file.json\"\n",
    "# region = \"us-east1\"\n",
    "# project_id = \"demo-environment\"\n",
    "# td_auth_object = \"demodb.td_auth\" ---demodb is the teradata database where the authorization object td_auth is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Note: </b><i>If the credentials entered are not valid or do not have the necessary permissions, we may get an error in the estimator step.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We need to assign values based on the GCP Credentials.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_json\n",
    "os.environ[\"GCP_REGION\"] = region\n",
    "os.environ[\"GCP_PROJECT_ID\"] = project_id\n",
    "os.environ[\"GCP_TD_AUTH_OBJ\"] = td_auth_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the create_tdapi_context method to create a TDAPI context to be used to run TDApiClient functions. Creating TDAPI context object is the first step of using TDApiClient library.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>type:</b> Specifies the cloud type of the TDAPI context.\n",
    "Permitted values are: \"aws\", \"azure\", or \"gcp\".</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>If the cloud type is Google Cloud, the only accepted value is \"gcp\".</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>gcp_bucket_name:</b> Specifies the name of the Google Cloud storage bucket within project.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>gcp_bucket_path:</b> Specifies a path within the given bucket name. This acts as parent folder for all files that TDApiClient creates.</li></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Name of the storage bucket in project with same region : clearscape-vertexai-demonow-bucket_trial\n",
      "Path within the given bucket:  custom-demo\n"
     ]
    }
   ],
   "source": [
    "gcp_bucket = input(\"Name of the storage bucket in project with same region :\")\n",
    "gcp_path = input(\"Path within the given bucket: \")\n",
    "# Examples of parameters\n",
    "# gcp_bucket = \"clearscape-*********\"\n",
    "# gcp_path = \"custom-******\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables \n",
    "\n",
    "gcp_context = create_tdapi_context(\n",
    "    \"gcp\",\n",
    "    gcp_bucket_name=gcp_bucket,\n",
    "    gcp_bucket_path=gcp_path\n",
    "    )\n",
    "tdapi_client = TDApiClient(gcp_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>7. Training job and Deploy model</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.1 Create and run training job</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Vertex AI provides Docker container images that you run as prebuilt containers for custom training. These containers, which are organized by machine learning (ML) framework and framework version, include common dependencies that you might want to use in training code. Often, using a prebuilt container is simpler than creating your own custom container for training.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can find the list of all precreated images <a href = 'https://cloud.google.com/vertex-ai/docs/training/pre-built-containers'>here</a>. For our demo we will be using the scikit-learn training and prediction images for our training and prediuction</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/scikit-learn-cpu.0-23:latest\"\n",
    "PREDICTION_IMAGE = \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TDApiClient class to create training job objects of Vertex AI Python package. This feature is implemented using getattr method of this class. Exact input for this method is determined by the class name of TrainingJob, such as CustomTrainingJob or AutoMLTabularTrainingJob.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>There are different training job classes of Vertex AI package that can be used. For example:\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CustomTrainingJob:</code> Useful for taking a training implementation as a python script</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CustomPythonPackageTrainingJob:</code> Useful for taking a training implementation as a python package</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>CustomContainerTrainingJob:</code> Useful for training on a custom Docker container</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>AutoMLTabularTrainingJob:</code> Useful for training an AutoML model with tabular dataset</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>AutoMLForecastingTrainingJob:</code> Useful for training an AutoML model with time series dataset</li>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here we are using the CustomTrainingJob</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = tdapi_client.CustomTrainingJob(\n",
    "    display_name=\"tdapiclient-custom-demo\",\n",
    "    script_path=\"train.py\",\n",
    "    container_uri=TRAINING_IMAGE,\n",
    "    requirements=[\"gcsfs\", \"nyoka\"],\n",
    "    model_serving_container_image_uri=PREDICTION_IMAGE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.2 Train a model</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TrainingJob.fit method to train a teradataml DataFrame with optional keyword arguments, and return a Google Vertex AI Model object. Below are the different arguments that can be used.</p>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>LOCATION:</code> The region where the container or Python package will be run.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>JOB_NAME:</code> Required. A display name for the CustomJob.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>MACHINE_TYPE:</code> The type of the machine. Refer to available machine types for training.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>REPLICA_COUNT:</code> The number of worker replicas to use. In most cases, set this to 1 for your first worker pool.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>EXECUTOR_IMAGE_URI:</code> The URI of the container image that runs the provided code. Refer to the available prebuilt containers for training. This image acts as the base image for the new Docker image that you are building with this command.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>WORKING_DIRECTORY:</code> A directory in your local file system containing the entry point script that runs your training code (see the following list item). We can use the parent directory of the script, or a higher-level directory. We can also use a higher-level directory if it contains a requirements.txt or setup.py file. To learn more, see Install dependencies.</li>\n",
    "\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>SCRIPT_PATH:</code> The path, relative to WORKING_DIRECTORY on your local file system, to the script that is the entry point for your training code. This can be a Python script (ending in .py) or a Bash script. For example, if you want to run /hello-world/trainer/task.py and WORKING_DIRECTORY is /hello-world, then use trainer/task.py for this value.</li></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TabularDataset\n",
      "Create TabularDataset backing LRO: projects/323844706402/locations/us-central1/datasets/1669361016661606400/operations/990156984416206848\n",
      "TabularDataset created. Resource name: projects/323844706402/locations/us-central1/datasets/1669361016661606400\n",
      "To use this TabularDataset in another session:\n",
      "ds = aiplatform.TabularDataset('projects/323844706402/locations/us-central1/datasets/1669361016661606400')\n",
      "Training script copied to:\n",
      "gs://clearscape-vertexai-demonow-bucket_trial/custom-demo/aiplatform-2024-04-26-11:57:02.399-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "Training Output directory:\n",
      "gs://clearscape-vertexai-demonow-bucket_trial/custom-demo/aiplatform-custom-training-2024-04-26-11:57:02.727 \n",
      "No dataset split provided. The service will use a default split.\n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7331331362625945600?project=323844706402\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7331331362625945600 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7331331362625945600 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7331331362625945600 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7331331362625945600 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7212931552500514816?project=323844706402\n",
      "CustomTrainingJob projects/323844706402/locations/us-central1/trainingPipelines/7331331362625945600 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomTrainingJob run completed. Resource name: projects/323844706402/locations/us-central1/trainingPipelines/7331331362625945600\n",
      "Model available at projects/323844706402/locations/us-central1/models/6783143417959415808\n"
     ]
    }
   ],
   "source": [
    "model = job.fit(\n",
    "    df_train,\n",
    "    replica_count=1,\n",
    "    model_display_name=\"tdapiclient-custom-demo\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>7.3 Deploy model to online endpoint</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TrainingJob.deploy method to deploy a trained model in Google Vertex AI environment or in Vantage system. A TDPredictor object is returned which can be used to run prediction.</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>For Vertex AI environment, it requires argument format the same as the Model.deploy function in Vertex AI Python SDK.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'>For Vantage system, it requires arguments that are required by BYOM and Predictor functions in teradataml.</li></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Required Arguments:</b>\n",
    "    <li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>model:</b> Specifies a Vertex AI model object.\n",
    "platform: Specifies the platform to deploy the given model:</li>\n",
    "    <ul style = 'font-size:14px;font-family:Arial;color:#00233C'>\n",
    "    <li>'vantage'</li>\n",
    "<li>'vx-endpoint'</li></ul></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>model_type:</b> Required if platform is 'vantage'. Specifies the type of the model:</li>\n",
    "<ul style = 'font-size:14px;font-family:Arial;color:#00233C'>\n",
    "<li>'pmml'</li>\n",
    "<li>'onnx'</li>\n",
    "<li>'h2o'</li></ul></p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>model_filename:</b> Required if platform is 'vantage'. Specifies the Google Cloud Storage file name of the model artifact.</li></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/323844706402/locations/us-central1/endpoints/1905134792563752960/operations/2761408644112187392\n",
      "Endpoint created. Resource name: projects/323844706402/locations/us-central1/endpoints/1905134792563752960\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/323844706402/locations/us-central1/endpoints/1905134792563752960')\n",
      "Deploying model to Endpoint : projects/323844706402/locations/us-central1/endpoints/1905134792563752960\n",
      "Deploy Endpoint model backing LRO: projects/323844706402/locations/us-central1/endpoints/1905134792563752960/operations/3497184233233842176\n",
      "Endpoint model deployed. Resource name: projects/323844706402/locations/us-central1/endpoints/1905134792563752960\n"
     ]
    }
   ],
   "source": [
    "predictor = job.deploy(\n",
    "    model,\n",
    "    \"vx-endpoint\",\n",
    "    vertex_kwargs={\"machine_type\": \"n1-standard-4\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>8. Predict using the deployed model</b></p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.1 Prepare test data</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>874158</td>\n",
       "\t\t<td>10.08</td>\n",
       "\t\t<td>15.11</td>\n",
       "\t\t<td>63.76</td>\n",
       "\t\t<td>317.5</td>\n",
       "\t\t<td>0.09267</td>\n",
       "\t\t<td>0.04695</td>\n",
       "\t\t<td>0.001597</td>\n",
       "\t\t<td>0.002404</td>\n",
       "\t\t<td>0.1703</td>\n",
       "\t\t<td>0.06048</td>\n",
       "\t\t<td>0.4245</td>\n",
       "\t\t<td>1.268</td>\n",
       "\t\t<td>2.68</td>\n",
       "\t\t<td>26.43</td>\n",
       "\t\t<td>0.01439</td>\n",
       "\t\t<td>0.012</td>\n",
       "\t\t<td>0.001597</td>\n",
       "\t\t<td>0.002404</td>\n",
       "\t\t<td>0.02538</td>\n",
       "\t\t<td>0.00347</td>\n",
       "\t\t<td>11.87</td>\n",
       "\t\t<td>21.18</td>\n",
       "\t\t<td>75.39</td>\n",
       "\t\t<td>437.0</td>\n",
       "\t\t<td>0.1521</td>\n",
       "\t\t<td>0.1019</td>\n",
       "\t\t<td>0.00692</td>\n",
       "\t\t<td>0.01042</td>\n",
       "\t\t<td>0.2933</td>\n",
       "\t\t<td>0.07697</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>905686</td>\n",
       "\t\t<td>11.89</td>\n",
       "\t\t<td>21.17</td>\n",
       "\t\t<td>76.39</td>\n",
       "\t\t<td>433.8</td>\n",
       "\t\t<td>0.09773</td>\n",
       "\t\t<td>0.0812</td>\n",
       "\t\t<td>0.02555</td>\n",
       "\t\t<td>0.02179</td>\n",
       "\t\t<td>0.2019</td>\n",
       "\t\t<td>0.0629</td>\n",
       "\t\t<td>0.2747</td>\n",
       "\t\t<td>1.203</td>\n",
       "\t\t<td>1.93</td>\n",
       "\t\t<td>19.53</td>\n",
       "\t\t<td>0.009895</td>\n",
       "\t\t<td>0.03053</td>\n",
       "\t\t<td>0.0163</td>\n",
       "\t\t<td>0.009276</td>\n",
       "\t\t<td>0.02258</td>\n",
       "\t\t<td>0.002272</td>\n",
       "\t\t<td>13.05</td>\n",
       "\t\t<td>27.21</td>\n",
       "\t\t<td>85.09</td>\n",
       "\t\t<td>522.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2187</td>\n",
       "\t\t<td>0.1164</td>\n",
       "\t\t<td>0.08263</td>\n",
       "\t\t<td>0.3075</td>\n",
       "\t\t<td>0.07351</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>913535</td>\n",
       "\t\t<td>16.69</td>\n",
       "\t\t<td>20.2</td>\n",
       "\t\t<td>107.1</td>\n",
       "\t\t<td>857.6</td>\n",
       "\t\t<td>0.07497</td>\n",
       "\t\t<td>0.07112</td>\n",
       "\t\t<td>0.03649</td>\n",
       "\t\t<td>0.02307</td>\n",
       "\t\t<td>0.1846</td>\n",
       "\t\t<td>0.05325</td>\n",
       "\t\t<td>0.2473</td>\n",
       "\t\t<td>0.5679</td>\n",
       "\t\t<td>1.775</td>\n",
       "\t\t<td>22.95</td>\n",
       "\t\t<td>0.002667</td>\n",
       "\t\t<td>0.01446</td>\n",
       "\t\t<td>0.01423</td>\n",
       "\t\t<td>0.005297</td>\n",
       "\t\t<td>0.01961</td>\n",
       "\t\t<td>0.0017</td>\n",
       "\t\t<td>19.18</td>\n",
       "\t\t<td>26.56</td>\n",
       "\t\t<td>127.3</td>\n",
       "\t\t<td>1084.0</td>\n",
       "\t\t<td>0.1009</td>\n",
       "\t\t<td>0.292</td>\n",
       "\t\t<td>0.2477</td>\n",
       "\t\t<td>0.08737</td>\n",
       "\t\t<td>0.4677</td>\n",
       "\t\t<td>0.07623</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>865432</td>\n",
       "\t\t<td>14.5</td>\n",
       "\t\t<td>10.89</td>\n",
       "\t\t<td>94.28</td>\n",
       "\t\t<td>640.7</td>\n",
       "\t\t<td>0.1101</td>\n",
       "\t\t<td>0.1099</td>\n",
       "\t\t<td>0.08842</td>\n",
       "\t\t<td>0.05778</td>\n",
       "\t\t<td>0.1856</td>\n",
       "\t\t<td>0.06402</td>\n",
       "\t\t<td>0.2929</td>\n",
       "\t\t<td>0.857</td>\n",
       "\t\t<td>1.928</td>\n",
       "\t\t<td>24.19</td>\n",
       "\t\t<td>0.003818</td>\n",
       "\t\t<td>0.01276</td>\n",
       "\t\t<td>0.02882</td>\n",
       "\t\t<td>0.012</td>\n",
       "\t\t<td>0.0191</td>\n",
       "\t\t<td>0.002808</td>\n",
       "\t\t<td>15.7</td>\n",
       "\t\t<td>15.98</td>\n",
       "\t\t<td>102.8</td>\n",
       "\t\t<td>745.5</td>\n",
       "\t\t<td>0.1313</td>\n",
       "\t\t<td>0.1788</td>\n",
       "\t\t<td>0.256</td>\n",
       "\t\t<td>0.1221</td>\n",
       "\t\t<td>0.2889</td>\n",
       "\t\t<td>0.08006</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>90401602</td>\n",
       "\t\t<td>12.8</td>\n",
       "\t\t<td>17.46</td>\n",
       "\t\t<td>83.05</td>\n",
       "\t\t<td>508.3</td>\n",
       "\t\t<td>0.08044</td>\n",
       "\t\t<td>0.08895</td>\n",
       "\t\t<td>0.0739</td>\n",
       "\t\t<td>0.04083</td>\n",
       "\t\t<td>0.1574</td>\n",
       "\t\t<td>0.0575</td>\n",
       "\t\t<td>0.3639</td>\n",
       "\t\t<td>1.265</td>\n",
       "\t\t<td>2.668</td>\n",
       "\t\t<td>30.57</td>\n",
       "\t\t<td>0.005421</td>\n",
       "\t\t<td>0.03477</td>\n",
       "\t\t<td>0.04545</td>\n",
       "\t\t<td>0.01384</td>\n",
       "\t\t<td>0.01869</td>\n",
       "\t\t<td>0.004067</td>\n",
       "\t\t<td>13.74</td>\n",
       "\t\t<td>21.06</td>\n",
       "\t\t<td>90.72</td>\n",
       "\t\t<td>591.0</td>\n",
       "\t\t<td>0.09534</td>\n",
       "\t\t<td>0.1812</td>\n",
       "\t\t<td>0.1901</td>\n",
       "\t\t<td>0.08296</td>\n",
       "\t\t<td>0.1988</td>\n",
       "\t\t<td>0.07053</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>855133</td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t\t<td>1.214</td>\n",
       "\t\t<td>2.188</td>\n",
       "\t\t<td>8.077</td>\n",
       "\t\t<td>106.0</td>\n",
       "\t\t<td>0.006883</td>\n",
       "\t\t<td>0.01094</td>\n",
       "\t\t<td>0.01818</td>\n",
       "\t\t<td>0.01917</td>\n",
       "\t\t<td>0.007882</td>\n",
       "\t\t<td>0.001754</td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>90317302</td>\n",
       "\t\t<td>10.26</td>\n",
       "\t\t<td>12.22</td>\n",
       "\t\t<td>65.75</td>\n",
       "\t\t<td>321.6</td>\n",
       "\t\t<td>0.09996</td>\n",
       "\t\t<td>0.07542</td>\n",
       "\t\t<td>0.01923</td>\n",
       "\t\t<td>0.01968</td>\n",
       "\t\t<td>0.18</td>\n",
       "\t\t<td>0.06569</td>\n",
       "\t\t<td>0.1911</td>\n",
       "\t\t<td>0.5477</td>\n",
       "\t\t<td>1.348</td>\n",
       "\t\t<td>11.88</td>\n",
       "\t\t<td>0.005682</td>\n",
       "\t\t<td>0.01365</td>\n",
       "\t\t<td>0.008496</td>\n",
       "\t\t<td>0.006929</td>\n",
       "\t\t<td>0.01938</td>\n",
       "\t\t<td>0.002371</td>\n",
       "\t\t<td>11.38</td>\n",
       "\t\t<td>15.65</td>\n",
       "\t\t<td>73.23</td>\n",
       "\t\t<td>394.5</td>\n",
       "\t\t<td>0.1343</td>\n",
       "\t\t<td>0.165</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.06696</td>\n",
       "\t\t<td>0.2937</td>\n",
       "\t\t<td>0.07722</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>894855</td>\n",
       "\t\t<td>12.86</td>\n",
       "\t\t<td>13.32</td>\n",
       "\t\t<td>82.82</td>\n",
       "\t\t<td>504.8</td>\n",
       "\t\t<td>0.1134</td>\n",
       "\t\t<td>0.08834</td>\n",
       "\t\t<td>0.038</td>\n",
       "\t\t<td>0.034</td>\n",
       "\t\t<td>0.1543</td>\n",
       "\t\t<td>0.06476</td>\n",
       "\t\t<td>0.2212</td>\n",
       "\t\t<td>1.042</td>\n",
       "\t\t<td>1.614</td>\n",
       "\t\t<td>16.57</td>\n",
       "\t\t<td>0.00591</td>\n",
       "\t\t<td>0.02016</td>\n",
       "\t\t<td>0.01902</td>\n",
       "\t\t<td>0.01011</td>\n",
       "\t\t<td>0.01202</td>\n",
       "\t\t<td>0.003107</td>\n",
       "\t\t<td>14.04</td>\n",
       "\t\t<td>21.08</td>\n",
       "\t\t<td>92.8</td>\n",
       "\t\t<td>599.5</td>\n",
       "\t\t<td>0.1547</td>\n",
       "\t\t<td>0.2231</td>\n",
       "\t\t<td>0.1791</td>\n",
       "\t\t<td>0.1155</td>\n",
       "\t\t<td>0.2382</td>\n",
       "\t\t<td>0.08553</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>911150</td>\n",
       "\t\t<td>14.53</td>\n",
       "\t\t<td>19.34</td>\n",
       "\t\t<td>94.25</td>\n",
       "\t\t<td>659.7</td>\n",
       "\t\t<td>0.08388</td>\n",
       "\t\t<td>0.078</td>\n",
       "\t\t<td>0.08817</td>\n",
       "\t\t<td>0.02925</td>\n",
       "\t\t<td>0.1473</td>\n",
       "\t\t<td>0.05746</td>\n",
       "\t\t<td>0.2535</td>\n",
       "\t\t<td>1.354</td>\n",
       "\t\t<td>1.994</td>\n",
       "\t\t<td>23.04</td>\n",
       "\t\t<td>0.004147</td>\n",
       "\t\t<td>0.02048</td>\n",
       "\t\t<td>0.03379</td>\n",
       "\t\t<td>0.008848</td>\n",
       "\t\t<td>0.01394</td>\n",
       "\t\t<td>0.002327</td>\n",
       "\t\t<td>16.3</td>\n",
       "\t\t<td>28.39</td>\n",
       "\t\t<td>108.1</td>\n",
       "\t\t<td>830.5</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.2649</td>\n",
       "\t\t<td>0.3779</td>\n",
       "\t\t<td>0.09594</td>\n",
       "\t\t<td>0.2471</td>\n",
       "\t\t<td>0.07463</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>87930</td>\n",
       "\t\t<td>12.47</td>\n",
       "\t\t<td>18.6</td>\n",
       "\t\t<td>81.09</td>\n",
       "\t\t<td>481.9</td>\n",
       "\t\t<td>0.09965</td>\n",
       "\t\t<td>0.1058</td>\n",
       "\t\t<td>0.08005</td>\n",
       "\t\t<td>0.03821</td>\n",
       "\t\t<td>0.1925</td>\n",
       "\t\t<td>0.06373</td>\n",
       "\t\t<td>0.3961</td>\n",
       "\t\t<td>1.044</td>\n",
       "\t\t<td>2.497</td>\n",
       "\t\t<td>30.29</td>\n",
       "\t\t<td>0.006953</td>\n",
       "\t\t<td>0.01911</td>\n",
       "\t\t<td>0.02701</td>\n",
       "\t\t<td>0.01037</td>\n",
       "\t\t<td>0.01782</td>\n",
       "\t\t<td>0.003586</td>\n",
       "\t\t<td>14.97</td>\n",
       "\t\t<td>24.64</td>\n",
       "\t\t<td>96.05</td>\n",
       "\t\t<td>677.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2378</td>\n",
       "\t\t<td>0.2671</td>\n",
       "\t\t<td>0.1015</td>\n",
       "\t\t<td>0.3014</td>\n",
       "\t\t<td>0.0875</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "         id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst\n",
       "0    915186        9.268         12.87           61.49      248.7          0.16340           0.22390         0.09730              0.05252         0.2378                 0.09502     0.4076      1.0930         3.014    20.04       0.009783        0.045420       0.03483           0.021880      0.02542              0.010450         10.28          16.38            69.05       300.2           0.19020            0.34410           0.2099               0.10250          0.3038                  0.12520\n",
       "1    879523       15.120         16.68           98.78      716.6          0.08876           0.09588         0.07550              0.04079         0.1594                 0.05986     0.2711      0.3621         1.974    26.44       0.005472        0.019190       0.02039           0.008260      0.01523              0.002881         17.77          20.24           117.70       989.5           0.14910            0.33310           0.3327               0.12520          0.3415                  0.09740\n",
       "2    921386       14.470         24.99           95.81      656.4          0.08837           0.12300         0.10090              0.03890         0.1872                 0.06341     0.2542      1.0790         2.615    23.11       0.007138        0.046530       0.03829           0.011620      0.02068              0.006111         16.22          31.73           113.50       808.9           0.13400            0.42020           0.4040               0.12050          0.3187                  0.10230\n",
       "3     87930       12.470         18.60           81.09      481.9          0.09965           0.10580         0.08005              0.03821         0.1925                 0.06373     0.3961      1.0440         2.497    30.29       0.006953        0.019110       0.02701           0.010370      0.01782              0.003586         14.97          24.64            96.05       677.9           0.14260            0.23780           0.2671               0.10150          0.3014                  0.08750\n",
       "4    869224       12.900         15.92           83.74      512.2          0.08677           0.09509         0.04894              0.03088         0.1778                 0.06235     0.2143      0.7712         1.689    16.64       0.005324        0.015630       0.01510           0.007584      0.02104              0.001887         14.48          21.82            97.17       643.8           0.13120            0.25480           0.2090               0.10120          0.3549                  0.08118\n",
       "5   8910988       21.750         20.99          147.30     1491.0          0.09401           0.19610         0.21950              0.10880         0.1721                 0.06194     1.1670      1.3520         8.867   156.80       0.005687        0.049600       0.06329           0.015610      0.01924              0.004614         28.19          28.18           195.90      2384.0           0.12720            0.47250           0.5807               0.18410          0.2833                  0.08858\n",
       "6   9113846       12.270         29.97           77.42      465.4          0.07699           0.03398         0.00000              0.00000         0.1701                 0.05960     0.4455      3.6470         2.884    35.13       0.007339        0.008243       0.00000           0.000000      0.03141              0.003136         13.45          38.05            85.08       558.9           0.09422            0.05213           0.0000               0.00000          0.2409                  0.06743\n",
       "7    904357       11.800         17.26           75.26      431.9          0.09087           0.06232         0.02853              0.01638         0.1847                 0.06019     0.3438      1.1400         2.225    25.06       0.005463        0.019640       0.02079           0.005398      0.01477              0.003071         13.45          24.49            86.00       562.0           0.12440            0.17260           0.1449               0.05356          0.2779                  0.08121\n",
       "8    905686       11.890         21.17           76.39      433.8          0.09773           0.08120         0.02555              0.02179         0.2019                 0.06290     0.2747      1.2030         1.930    19.53       0.009895        0.030530       0.01630           0.009276      0.02258              0.002272         13.05          27.21            85.09       522.9           0.14260            0.21870           0.1164               0.08263          0.3075                  0.07351\n",
       "9  84799002       14.540         27.54           96.73      658.8          0.11390           0.15950         0.16390              0.07364         0.2303                 0.07077     0.3700      1.0330         2.879    32.55       0.005607        0.042400       0.04741           0.010900      0.01857              0.005466         17.46          37.13           124.10       943.2           0.16780            0.65770           0.7026               0.17120          0.4218                  0.13410"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.drop([\"diagnosis\"], axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.2 Predict using the TDApiClient predictor object </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the TDPredictor.predict method to perform prediction using teradataml DataFrame and VertexAI endpoint represented by this predictor object.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>input:</code> Specifies the teradataml DataFrame used as input for scoring.</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>mode:</code> Specifies the mode for scoring.\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>Permitted values include:\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>'UDF':</code> Score in database using a Teradata UDF. This is the default value. For this mode, the return is a teradataml DataFrame. This mode provides faster scoring with the data from Teradata.</li>\n",
    "\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>'CLIENT':</code> Score at client side using a library. For this mode, the return is an array or JSON. When using mode, data is pulled from Teradata and serialized for scoring at client.</li></ol></p>\n",
    "\n",
    "\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Optional Argument:\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>options: Specifies the predict method with the following key-value arguments:\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>udf_name:</code> Specifies the name of the UDF used to invoke predict with UDF mode. Default value is 'tapidb.API_Request'.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>content_type:</code> Specifies content type required for VertexAI endpoint present in the predictor. Default value is 'csv'.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>key_start_index:</code> Specifies the index in DataFrame columns to be the key for scoring starts. Default value is 0.</li></ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>Output</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>879523</td>\n",
       "\t\t<td>15.12</td>\n",
       "\t\t<td>16.68</td>\n",
       "\t\t<td>98.78</td>\n",
       "\t\t<td>716.6</td>\n",
       "\t\t<td>0.08876</td>\n",
       "\t\t<td>0.09588</td>\n",
       "\t\t<td>0.0755</td>\n",
       "\t\t<td>0.04079</td>\n",
       "\t\t<td>0.1594</td>\n",
       "\t\t<td>0.05986</td>\n",
       "\t\t<td>0.2711</td>\n",
       "\t\t<td>0.3621</td>\n",
       "\t\t<td>1.974</td>\n",
       "\t\t<td>26.44</td>\n",
       "\t\t<td>0.005472</td>\n",
       "\t\t<td>0.01919</td>\n",
       "\t\t<td>0.02039</td>\n",
       "\t\t<td>0.00826</td>\n",
       "\t\t<td>0.01523</td>\n",
       "\t\t<td>0.002881</td>\n",
       "\t\t<td>17.77</td>\n",
       "\t\t<td>20.24</td>\n",
       "\t\t<td>117.7</td>\n",
       "\t\t<td>989.5</td>\n",
       "\t\t<td>0.1491</td>\n",
       "\t\t<td>0.3331</td>\n",
       "\t\t<td>0.3327</td>\n",
       "\t\t<td>0.1252</td>\n",
       "\t\t<td>0.3415</td>\n",
       "\t\t<td>0.0974</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>862965</td>\n",
       "\t\t<td>12.18</td>\n",
       "\t\t<td>20.52</td>\n",
       "\t\t<td>77.22</td>\n",
       "\t\t<td>458.7</td>\n",
       "\t\t<td>0.08013</td>\n",
       "\t\t<td>0.04038</td>\n",
       "\t\t<td>0.02383</td>\n",
       "\t\t<td>0.0177</td>\n",
       "\t\t<td>0.1739</td>\n",
       "\t\t<td>0.05677</td>\n",
       "\t\t<td>0.1924</td>\n",
       "\t\t<td>1.571</td>\n",
       "\t\t<td>1.183</td>\n",
       "\t\t<td>14.68</td>\n",
       "\t\t<td>0.00508</td>\n",
       "\t\t<td>0.006098</td>\n",
       "\t\t<td>0.01069</td>\n",
       "\t\t<td>0.006797</td>\n",
       "\t\t<td>0.01447</td>\n",
       "\t\t<td>0.001532</td>\n",
       "\t\t<td>13.34</td>\n",
       "\t\t<td>32.84</td>\n",
       "\t\t<td>84.58</td>\n",
       "\t\t<td>547.8</td>\n",
       "\t\t<td>0.1123</td>\n",
       "\t\t<td>0.08862</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.07431</td>\n",
       "\t\t<td>0.2694</td>\n",
       "\t\t<td>0.06878</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>905686</td>\n",
       "\t\t<td>11.89</td>\n",
       "\t\t<td>21.17</td>\n",
       "\t\t<td>76.39</td>\n",
       "\t\t<td>433.8</td>\n",
       "\t\t<td>0.09773</td>\n",
       "\t\t<td>0.0812</td>\n",
       "\t\t<td>0.02555</td>\n",
       "\t\t<td>0.02179</td>\n",
       "\t\t<td>0.2019</td>\n",
       "\t\t<td>0.0629</td>\n",
       "\t\t<td>0.2747</td>\n",
       "\t\t<td>1.203</td>\n",
       "\t\t<td>1.93</td>\n",
       "\t\t<td>19.53</td>\n",
       "\t\t<td>0.009895</td>\n",
       "\t\t<td>0.03053</td>\n",
       "\t\t<td>0.0163</td>\n",
       "\t\t<td>0.009276</td>\n",
       "\t\t<td>0.02258</td>\n",
       "\t\t<td>0.002272</td>\n",
       "\t\t<td>13.05</td>\n",
       "\t\t<td>27.21</td>\n",
       "\t\t<td>85.09</td>\n",
       "\t\t<td>522.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2187</td>\n",
       "\t\t<td>0.1164</td>\n",
       "\t\t<td>0.08263</td>\n",
       "\t\t<td>0.3075</td>\n",
       "\t\t<td>0.07351</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>889719</td>\n",
       "\t\t<td>17.19</td>\n",
       "\t\t<td>22.07</td>\n",
       "\t\t<td>111.6</td>\n",
       "\t\t<td>928.3</td>\n",
       "\t\t<td>0.09726</td>\n",
       "\t\t<td>0.08995</td>\n",
       "\t\t<td>0.09061</td>\n",
       "\t\t<td>0.06527</td>\n",
       "\t\t<td>0.1867</td>\n",
       "\t\t<td>0.0558</td>\n",
       "\t\t<td>0.4203</td>\n",
       "\t\t<td>0.7383</td>\n",
       "\t\t<td>2.819</td>\n",
       "\t\t<td>45.42</td>\n",
       "\t\t<td>0.004493</td>\n",
       "\t\t<td>0.01206</td>\n",
       "\t\t<td>0.02048</td>\n",
       "\t\t<td>0.009875</td>\n",
       "\t\t<td>0.01144</td>\n",
       "\t\t<td>0.001575</td>\n",
       "\t\t<td>21.58</td>\n",
       "\t\t<td>29.33</td>\n",
       "\t\t<td>140.5</td>\n",
       "\t\t<td>1436.0</td>\n",
       "\t\t<td>0.1558</td>\n",
       "\t\t<td>0.2567</td>\n",
       "\t\t<td>0.3889</td>\n",
       "\t\t<td>0.1984</td>\n",
       "\t\t<td>0.3216</td>\n",
       "\t\t<td>0.0757</td>\n",
       "\t\t<td>{ \"predictions\": [ 1 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9113846</td>\n",
       "\t\t<td>12.27</td>\n",
       "\t\t<td>29.97</td>\n",
       "\t\t<td>77.42</td>\n",
       "\t\t<td>465.4</td>\n",
       "\t\t<td>0.07699</td>\n",
       "\t\t<td>0.03398</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.1701</td>\n",
       "\t\t<td>0.0596</td>\n",
       "\t\t<td>0.4455</td>\n",
       "\t\t<td>3.647</td>\n",
       "\t\t<td>2.884</td>\n",
       "\t\t<td>35.13</td>\n",
       "\t\t<td>0.007339</td>\n",
       "\t\t<td>0.008243</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.03141</td>\n",
       "\t\t<td>0.003136</td>\n",
       "\t\t<td>13.45</td>\n",
       "\t\t<td>38.05</td>\n",
       "\t\t<td>85.08</td>\n",
       "\t\t<td>558.9</td>\n",
       "\t\t<td>0.09422</td>\n",
       "\t\t<td>0.05213</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.2409</td>\n",
       "\t\t<td>0.06743</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>90317302</td>\n",
       "\t\t<td>10.26</td>\n",
       "\t\t<td>12.22</td>\n",
       "\t\t<td>65.75</td>\n",
       "\t\t<td>321.6</td>\n",
       "\t\t<td>0.09996</td>\n",
       "\t\t<td>0.07542</td>\n",
       "\t\t<td>0.01923</td>\n",
       "\t\t<td>0.01968</td>\n",
       "\t\t<td>0.18</td>\n",
       "\t\t<td>0.06569</td>\n",
       "\t\t<td>0.1911</td>\n",
       "\t\t<td>0.5477</td>\n",
       "\t\t<td>1.348</td>\n",
       "\t\t<td>11.88</td>\n",
       "\t\t<td>0.005682</td>\n",
       "\t\t<td>0.01365</td>\n",
       "\t\t<td>0.008496</td>\n",
       "\t\t<td>0.006929</td>\n",
       "\t\t<td>0.01938</td>\n",
       "\t\t<td>0.002371</td>\n",
       "\t\t<td>11.38</td>\n",
       "\t\t<td>15.65</td>\n",
       "\t\t<td>73.23</td>\n",
       "\t\t<td>394.5</td>\n",
       "\t\t<td>0.1343</td>\n",
       "\t\t<td>0.165</td>\n",
       "\t\t<td>0.08615</td>\n",
       "\t\t<td>0.06696</td>\n",
       "\t\t<td>0.2937</td>\n",
       "\t\t<td>0.07722</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>858986</td>\n",
       "\t\t<td>14.25</td>\n",
       "\t\t<td>22.15</td>\n",
       "\t\t<td>96.42</td>\n",
       "\t\t<td>645.7</td>\n",
       "\t\t<td>0.1049</td>\n",
       "\t\t<td>0.2008</td>\n",
       "\t\t<td>0.2135</td>\n",
       "\t\t<td>0.08653</td>\n",
       "\t\t<td>0.1949</td>\n",
       "\t\t<td>0.07292</td>\n",
       "\t\t<td>0.7036</td>\n",
       "\t\t<td>1.268</td>\n",
       "\t\t<td>5.373</td>\n",
       "\t\t<td>60.78</td>\n",
       "\t\t<td>0.009407</td>\n",
       "\t\t<td>0.07056</td>\n",
       "\t\t<td>0.06899</td>\n",
       "\t\t<td>0.01848</td>\n",
       "\t\t<td>0.017</td>\n",
       "\t\t<td>0.006113</td>\n",
       "\t\t<td>17.67</td>\n",
       "\t\t<td>29.51</td>\n",
       "\t\t<td>119.1</td>\n",
       "\t\t<td>959.5</td>\n",
       "\t\t<td>0.164</td>\n",
       "\t\t<td>0.6247</td>\n",
       "\t\t<td>0.6922</td>\n",
       "\t\t<td>0.1785</td>\n",
       "\t\t<td>0.2844</td>\n",
       "\t\t<td>0.1132</td>\n",
       "\t\t<td>{ \"predictions\": [ 1 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>842302</td>\n",
       "\t\t<td>17.99</td>\n",
       "\t\t<td>10.38</td>\n",
       "\t\t<td>122.8</td>\n",
       "\t\t<td>1001.0</td>\n",
       "\t\t<td>0.1184</td>\n",
       "\t\t<td>0.2776</td>\n",
       "\t\t<td>0.3001</td>\n",
       "\t\t<td>0.1471</td>\n",
       "\t\t<td>0.2419</td>\n",
       "\t\t<td>0.07871</td>\n",
       "\t\t<td>1.095</td>\n",
       "\t\t<td>0.9053</td>\n",
       "\t\t<td>8.589</td>\n",
       "\t\t<td>153.4</td>\n",
       "\t\t<td>0.006399</td>\n",
       "\t\t<td>0.04904</td>\n",
       "\t\t<td>0.05373</td>\n",
       "\t\t<td>0.01587</td>\n",
       "\t\t<td>0.03003</td>\n",
       "\t\t<td>0.006193</td>\n",
       "\t\t<td>25.38</td>\n",
       "\t\t<td>17.33</td>\n",
       "\t\t<td>184.6</td>\n",
       "\t\t<td>2019.0</td>\n",
       "\t\t<td>0.1622</td>\n",
       "\t\t<td>0.6656</td>\n",
       "\t\t<td>0.7119</td>\n",
       "\t\t<td>0.2654</td>\n",
       "\t\t<td>0.4601</td>\n",
       "\t\t<td>0.1189</td>\n",
       "\t\t<td>{ \"predictions\": [ 1 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>911150</td>\n",
       "\t\t<td>14.53</td>\n",
       "\t\t<td>19.34</td>\n",
       "\t\t<td>94.25</td>\n",
       "\t\t<td>659.7</td>\n",
       "\t\t<td>0.08388</td>\n",
       "\t\t<td>0.078</td>\n",
       "\t\t<td>0.08817</td>\n",
       "\t\t<td>0.02925</td>\n",
       "\t\t<td>0.1473</td>\n",
       "\t\t<td>0.05746</td>\n",
       "\t\t<td>0.2535</td>\n",
       "\t\t<td>1.354</td>\n",
       "\t\t<td>1.994</td>\n",
       "\t\t<td>23.04</td>\n",
       "\t\t<td>0.004147</td>\n",
       "\t\t<td>0.02048</td>\n",
       "\t\t<td>0.03379</td>\n",
       "\t\t<td>0.008848</td>\n",
       "\t\t<td>0.01394</td>\n",
       "\t\t<td>0.002327</td>\n",
       "\t\t<td>16.3</td>\n",
       "\t\t<td>28.39</td>\n",
       "\t\t<td>108.1</td>\n",
       "\t\t<td>830.5</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.2649</td>\n",
       "\t\t<td>0.3779</td>\n",
       "\t\t<td>0.09594</td>\n",
       "\t\t<td>0.2471</td>\n",
       "\t\t<td>0.07463</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>87930</td>\n",
       "\t\t<td>12.47</td>\n",
       "\t\t<td>18.6</td>\n",
       "\t\t<td>81.09</td>\n",
       "\t\t<td>481.9</td>\n",
       "\t\t<td>0.09965</td>\n",
       "\t\t<td>0.1058</td>\n",
       "\t\t<td>0.08005</td>\n",
       "\t\t<td>0.03821</td>\n",
       "\t\t<td>0.1925</td>\n",
       "\t\t<td>0.06373</td>\n",
       "\t\t<td>0.3961</td>\n",
       "\t\t<td>1.044</td>\n",
       "\t\t<td>2.497</td>\n",
       "\t\t<td>30.29</td>\n",
       "\t\t<td>0.006953</td>\n",
       "\t\t<td>0.01911</td>\n",
       "\t\t<td>0.02701</td>\n",
       "\t\t<td>0.01037</td>\n",
       "\t\t<td>0.01782</td>\n",
       "\t\t<td>0.003586</td>\n",
       "\t\t<td>14.97</td>\n",
       "\t\t<td>24.64</td>\n",
       "\t\t<td>96.05</td>\n",
       "\t\t<td>677.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2378</td>\n",
       "\t\t<td>0.2671</td>\n",
       "\t\t<td>0.1015</td>\n",
       "\t\t<td>0.3014</td>\n",
       "\t\t<td>0.0875</td>\n",
       "\t\t<td>{ \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "         id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst                                                                                                                                                                                                                           Output\n",
       "0    894855        12.86         13.32           82.82      504.8          0.11340           0.08834         0.03800              0.03400         0.1543                 0.06476     0.2212      1.0420        1.6140    16.57       0.005910        0.020160      0.019020           0.010110      0.01202              0.003107         14.04          21.08            92.80       599.5           0.15470            0.22310          0.17910               0.11550          0.2382                  0.08553  { \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "1  84799002        14.54         27.54           96.73      658.8          0.11390           0.15950         0.16390              0.07364         0.2303                 0.07077     0.3700      1.0330        2.8790    32.55       0.005607        0.042400      0.047410           0.010900      0.01857              0.005466         17.46          37.13           124.10       943.2           0.16780            0.65770          0.70260               0.17120          0.4218                  0.13410  { \"predictions\": [ 1 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "2   8910721        14.29         16.82           90.30      632.6          0.06429           0.02675         0.00725              0.00625         0.1508                 0.05376     0.1302      0.7198        0.8439    10.77       0.003492        0.003710      0.004826           0.003608      0.01536              0.001381         14.91          20.65            94.44       684.6           0.08567            0.05036          0.03866               0.03333          0.2458                  0.06120  { \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "3    902975        12.21         14.09           78.78      462.0          0.08108           0.07823         0.06839              0.02534         0.1646                 0.06154     0.2666      0.8309        2.0970    19.96       0.004405        0.030260      0.043440           0.010870      0.01921              0.004622         13.13          19.29            87.65       529.9           0.10260            0.24310          0.30760               0.09140          0.2677                  0.08824  { \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "4    857438        15.10         22.02           97.26      712.8          0.09056           0.07081         0.05253              0.03334         0.1616                 0.05684     0.3105      0.8339        2.0970    29.91       0.004675        0.010300      0.016030           0.009222      0.01095              0.001629         18.10          31.69           117.70      1030.0           0.13890            0.20570          0.27120               0.15300          0.2675                  0.07873  { \"predictions\": [ 1 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "5     87930        12.47         18.60           81.09      481.9          0.09965           0.10580         0.08005              0.03821         0.1925                 0.06373     0.3961      1.0440        2.4970    30.29       0.006953        0.019110      0.027010           0.010370      0.01782              0.003586         14.97          24.64            96.05       677.9           0.14260            0.23780          0.26710               0.10150          0.3014                  0.08750  { \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "6  91544002        11.06         17.12           71.25      366.5          0.11940           0.10710         0.04063              0.04268         0.1954                 0.07976     0.1779      1.0300        1.3180    12.30       0.012620        0.023480      0.018000           0.012850      0.02220              0.008313         11.69          20.74            76.08       411.1           0.16620            0.20310          0.12560               0.09514          0.2780                  0.11680  { \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "7    862965        12.18         20.52           77.22      458.7          0.08013           0.04038         0.02383              0.01770         0.1739                 0.05677     0.1924      1.5710        1.1830    14.68       0.005080        0.006098      0.010690           0.006797      0.01447              0.001532         13.34          32.84            84.58       547.8           0.11230            0.08862          0.11450               0.07431          0.2694                  0.06878  { \"predictions\": [ 0 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "8    889719        17.19         22.07          111.60      928.3          0.09726           0.08995         0.09061              0.06527         0.1867                 0.05580     0.4203      0.7383        2.8190    45.42       0.004493        0.012060      0.020480           0.009875      0.01144              0.001575         21.58          29.33           140.50      1436.0           0.15580            0.25670          0.38890               0.19840          0.3216                  0.07570  { \"predictions\": [ 1 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }\n",
       "9  90602302        15.50         21.08          102.90      803.1          0.11200           0.15710         0.15220              0.08481         0.2085                 0.06864     1.3700      1.2130        9.4240   176.50       0.008198        0.038890      0.044930           0.021390      0.02018              0.005815         23.17          27.65           157.10      1748.0           0.15170            0.40020          0.42110               0.21340          0.3003                  0.10480  { \"predictions\": [ 1 ], \"deployedModelId\": \"853218824130920448\", \"model\": \"projects\\/323844706402\\/locations\\/us-central1\\/models\\/6783143417959415808\", \"modelDisplayName\": \"tdapiclient-custom-demo\", \"modelVersionId\": \"1\" }"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(df_test, mode=\"udf\", content_type=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.3 Deploy created model to Vantage </b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can use the BYOMPredictor class to hold the name and type of the model teradataml DataFrame obtained using deploy() method. This allows user to export models that are built on VertexAI to Vantage through BYOM, for in-database analysis.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>model_df:</code> Specifies the teradataml DataFrame containing the model data to be used for scoring.\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><code>model_type:</code> Specifies the type of the model:</li>\n",
    "<ul style = 'font-size:14px;font-family:Arial;color:#00233C'>    \n",
    "<li>'pmml'</li>\n",
    "    <li>'onnx'</li>\n",
    "    <li>'h2o'</li>\n",
    "    </ul>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the model table 'tdapiclient_byom_models' as it does not exist.\n",
      "Model is saved.\n",
      "The model cataloging parameters are set to table_name='tdapiclient_byom_models' and schema_name='DEMO_USER'\n"
     ]
    }
   ],
   "source": [
    "byom_predictor = job.deploy(\n",
    "    model,\n",
    "    \"vantage\",\n",
    "    model_type=\"pmml\",\n",
    "    model_filename=\"model.pmml\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>model_id</th>\n",
       "\t\t<th>model</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>tdapiclient_vertex_6783143417959415808</td>\n",
       "\t\t<td>b'3C3F786D6C20766572...'</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "                                                           model\n",
       "model_id                                                        \n",
       "tdapiclient_vertex_6783143417959415808  b'3C3F786D6C20766572...'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byom_predictor.model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>8.3 Predict in database using the BYOM Predictor</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We can use the BYOMPredictor.predict method to score data in Vantage with a model that has been created outside Vantage and exported to Vantage using the deploy method.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This method supports prediction using models in the following formats:\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>PMML</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'>ONNX</li>\n",
    "    <li style = 'font-size:14px;font-family:Arial;color:#00233C'>MOJO (H2O)</li></p>\n",
    "    \n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Required Arguments:</p>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>input:</code> Specifies the teradataml DataFrame containing the input test data.</li>\n",
    "<li style = 'font-size:14px;font-family:Arial;color:#00233C'><code>input_cols:</code> Specifies the name(s) of input teradataml DataFrame column(s) to copy to the output.</li></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>id</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>prediction</th>\n",
       "\t\t<th>json_report</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>925277</td>\n",
       "\t\t<td>14.59</td>\n",
       "\t\t<td>22.68</td>\n",
       "\t\t<td>96.39</td>\n",
       "\t\t<td>657.1</td>\n",
       "\t\t<td>0.08473</td>\n",
       "\t\t<td>0.133</td>\n",
       "\t\t<td>0.1029</td>\n",
       "\t\t<td>0.03736</td>\n",
       "\t\t<td>0.1454</td>\n",
       "\t\t<td>0.06147</td>\n",
       "\t\t<td>0.2254</td>\n",
       "\t\t<td>1.108</td>\n",
       "\t\t<td>2.224</td>\n",
       "\t\t<td>19.54</td>\n",
       "\t\t<td>0.004242</td>\n",
       "\t\t<td>0.04639</td>\n",
       "\t\t<td>0.06578</td>\n",
       "\t\t<td>0.01606</td>\n",
       "\t\t<td>0.01638</td>\n",
       "\t\t<td>0.004406</td>\n",
       "\t\t<td>15.48</td>\n",
       "\t\t<td>27.27</td>\n",
       "\t\t<td>105.9</td>\n",
       "\t\t<td>733.5</td>\n",
       "\t\t<td>0.1026</td>\n",
       "\t\t<td>0.3171</td>\n",
       "\t\t<td>0.3662</td>\n",
       "\t\t<td>0.1105</td>\n",
       "\t\t<td>0.2258</td>\n",
       "\t\t<td>0.08004</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.87,\"probability_1\":0.13,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>8711003</td>\n",
       "\t\t<td>12.25</td>\n",
       "\t\t<td>17.94</td>\n",
       "\t\t<td>78.27</td>\n",
       "\t\t<td>460.3</td>\n",
       "\t\t<td>0.08654</td>\n",
       "\t\t<td>0.06679</td>\n",
       "\t\t<td>0.03885</td>\n",
       "\t\t<td>0.02331</td>\n",
       "\t\t<td>0.197</td>\n",
       "\t\t<td>0.06228</td>\n",
       "\t\t<td>0.22</td>\n",
       "\t\t<td>0.9823</td>\n",
       "\t\t<td>1.484</td>\n",
       "\t\t<td>16.51</td>\n",
       "\t\t<td>0.005518</td>\n",
       "\t\t<td>0.01562</td>\n",
       "\t\t<td>0.01994</td>\n",
       "\t\t<td>0.007924</td>\n",
       "\t\t<td>0.01799</td>\n",
       "\t\t<td>0.002484</td>\n",
       "\t\t<td>13.59</td>\n",
       "\t\t<td>25.22</td>\n",
       "\t\t<td>86.6</td>\n",
       "\t\t<td>564.2</td>\n",
       "\t\t<td>0.1217</td>\n",
       "\t\t<td>0.1788</td>\n",
       "\t\t<td>0.1943</td>\n",
       "\t\t<td>0.08211</td>\n",
       "\t\t<td>0.3113</td>\n",
       "\t\t<td>0.08132</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>915186</td>\n",
       "\t\t<td>9.268</td>\n",
       "\t\t<td>12.87</td>\n",
       "\t\t<td>61.49</td>\n",
       "\t\t<td>248.7</td>\n",
       "\t\t<td>0.1634</td>\n",
       "\t\t<td>0.2239</td>\n",
       "\t\t<td>0.0973</td>\n",
       "\t\t<td>0.05252</td>\n",
       "\t\t<td>0.2378</td>\n",
       "\t\t<td>0.09502</td>\n",
       "\t\t<td>0.4076</td>\n",
       "\t\t<td>1.093</td>\n",
       "\t\t<td>3.014</td>\n",
       "\t\t<td>20.04</td>\n",
       "\t\t<td>0.009783</td>\n",
       "\t\t<td>0.04542</td>\n",
       "\t\t<td>0.03483</td>\n",
       "\t\t<td>0.02188</td>\n",
       "\t\t<td>0.02542</td>\n",
       "\t\t<td>0.01045</td>\n",
       "\t\t<td>10.28</td>\n",
       "\t\t<td>16.38</td>\n",
       "\t\t<td>69.05</td>\n",
       "\t\t<td>300.2</td>\n",
       "\t\t<td>0.1902</td>\n",
       "\t\t<td>0.3441</td>\n",
       "\t\t<td>0.2099</td>\n",
       "\t\t<td>0.1025</td>\n",
       "\t\t<td>0.3038</td>\n",
       "\t\t<td>0.1252</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.47,\"probability_1\":0.53,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>894329</td>\n",
       "\t\t<td>9.042</td>\n",
       "\t\t<td>18.9</td>\n",
       "\t\t<td>60.07</td>\n",
       "\t\t<td>244.5</td>\n",
       "\t\t<td>0.09968</td>\n",
       "\t\t<td>0.1972</td>\n",
       "\t\t<td>0.1975</td>\n",
       "\t\t<td>0.04908</td>\n",
       "\t\t<td>0.233</td>\n",
       "\t\t<td>0.08743</td>\n",
       "\t\t<td>0.4653</td>\n",
       "\t\t<td>1.911</td>\n",
       "\t\t<td>3.769</td>\n",
       "\t\t<td>24.2</td>\n",
       "\t\t<td>0.009845</td>\n",
       "\t\t<td>0.0659</td>\n",
       "\t\t<td>0.1027</td>\n",
       "\t\t<td>0.02527</td>\n",
       "\t\t<td>0.03491</td>\n",
       "\t\t<td>0.007877</td>\n",
       "\t\t<td>10.06</td>\n",
       "\t\t<td>23.4</td>\n",
       "\t\t<td>68.62</td>\n",
       "\t\t<td>297.1</td>\n",
       "\t\t<td>0.1221</td>\n",
       "\t\t<td>0.3748</td>\n",
       "\t\t<td>0.4609</td>\n",
       "\t\t<td>0.1145</td>\n",
       "\t\t<td>0.3135</td>\n",
       "\t\t<td>0.1055</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.91,\"probability_1\":0.09,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>861598</td>\n",
       "\t\t<td>14.64</td>\n",
       "\t\t<td>15.24</td>\n",
       "\t\t<td>95.77</td>\n",
       "\t\t<td>651.9</td>\n",
       "\t\t<td>0.1132</td>\n",
       "\t\t<td>0.1339</td>\n",
       "\t\t<td>0.09966</td>\n",
       "\t\t<td>0.07064</td>\n",
       "\t\t<td>0.2116</td>\n",
       "\t\t<td>0.06346</td>\n",
       "\t\t<td>0.5115</td>\n",
       "\t\t<td>0.7372</td>\n",
       "\t\t<td>3.814</td>\n",
       "\t\t<td>42.76</td>\n",
       "\t\t<td>0.005508</td>\n",
       "\t\t<td>0.04412</td>\n",
       "\t\t<td>0.04436</td>\n",
       "\t\t<td>0.01623</td>\n",
       "\t\t<td>0.02427</td>\n",
       "\t\t<td>0.004841</td>\n",
       "\t\t<td>16.34</td>\n",
       "\t\t<td>18.24</td>\n",
       "\t\t<td>109.4</td>\n",
       "\t\t<td>803.6</td>\n",
       "\t\t<td>0.1277</td>\n",
       "\t\t<td>0.3089</td>\n",
       "\t\t<td>0.2604</td>\n",
       "\t\t<td>0.1397</td>\n",
       "\t\t<td>0.3151</td>\n",
       "\t\t<td>0.08473</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.77,\"probability_1\":0.23,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>895633</td>\n",
       "\t\t<td>16.26</td>\n",
       "\t\t<td>21.88</td>\n",
       "\t\t<td>107.5</td>\n",
       "\t\t<td>826.8</td>\n",
       "\t\t<td>0.1165</td>\n",
       "\t\t<td>0.1283</td>\n",
       "\t\t<td>0.1799</td>\n",
       "\t\t<td>0.07981</td>\n",
       "\t\t<td>0.1869</td>\n",
       "\t\t<td>0.06532</td>\n",
       "\t\t<td>0.5706</td>\n",
       "\t\t<td>1.457</td>\n",
       "\t\t<td>2.961</td>\n",
       "\t\t<td>57.72</td>\n",
       "\t\t<td>0.01056</td>\n",
       "\t\t<td>0.03756</td>\n",
       "\t\t<td>0.05839</td>\n",
       "\t\t<td>0.01186</td>\n",
       "\t\t<td>0.04022</td>\n",
       "\t\t<td>0.006187</td>\n",
       "\t\t<td>17.73</td>\n",
       "\t\t<td>25.21</td>\n",
       "\t\t<td>113.7</td>\n",
       "\t\t<td>975.2</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2116</td>\n",
       "\t\t<td>0.3344</td>\n",
       "\t\t<td>0.1047</td>\n",
       "\t\t<td>0.2736</td>\n",
       "\t\t<td>0.07953</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.13,\"probability_1\":0.87,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>897137</td>\n",
       "\t\t<td>11.25</td>\n",
       "\t\t<td>14.78</td>\n",
       "\t\t<td>71.38</td>\n",
       "\t\t<td>390.0</td>\n",
       "\t\t<td>0.08306</td>\n",
       "\t\t<td>0.04458</td>\n",
       "\t\t<td>0.0009737</td>\n",
       "\t\t<td>0.002941</td>\n",
       "\t\t<td>0.1773</td>\n",
       "\t\t<td>0.06081</td>\n",
       "\t\t<td>0.2144</td>\n",
       "\t\t<td>0.9961</td>\n",
       "\t\t<td>1.529</td>\n",
       "\t\t<td>15.07</td>\n",
       "\t\t<td>0.005617</td>\n",
       "\t\t<td>0.007124</td>\n",
       "\t\t<td>0.0009737</td>\n",
       "\t\t<td>0.002941</td>\n",
       "\t\t<td>0.017</td>\n",
       "\t\t<td>0.00203</td>\n",
       "\t\t<td>12.76</td>\n",
       "\t\t<td>22.06</td>\n",
       "\t\t<td>82.08</td>\n",
       "\t\t<td>492.7</td>\n",
       "\t\t<td>0.1166</td>\n",
       "\t\t<td>0.09794</td>\n",
       "\t\t<td>0.005518</td>\n",
       "\t\t<td>0.01667</td>\n",
       "\t\t<td>0.2815</td>\n",
       "\t\t<td>0.07418</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>918465</td>\n",
       "\t\t<td>12.07</td>\n",
       "\t\t<td>13.44</td>\n",
       "\t\t<td>77.83</td>\n",
       "\t\t<td>445.2</td>\n",
       "\t\t<td>0.11</td>\n",
       "\t\t<td>0.09009</td>\n",
       "\t\t<td>0.03781</td>\n",
       "\t\t<td>0.02798</td>\n",
       "\t\t<td>0.1657</td>\n",
       "\t\t<td>0.06608</td>\n",
       "\t\t<td>0.2513</td>\n",
       "\t\t<td>0.504</td>\n",
       "\t\t<td>1.714</td>\n",
       "\t\t<td>18.54</td>\n",
       "\t\t<td>0.007327</td>\n",
       "\t\t<td>0.01153</td>\n",
       "\t\t<td>0.01798</td>\n",
       "\t\t<td>0.007986</td>\n",
       "\t\t<td>0.01962</td>\n",
       "\t\t<td>0.002234</td>\n",
       "\t\t<td>13.45</td>\n",
       "\t\t<td>15.77</td>\n",
       "\t\t<td>86.92</td>\n",
       "\t\t<td>549.9</td>\n",
       "\t\t<td>0.1521</td>\n",
       "\t\t<td>0.1632</td>\n",
       "\t\t<td>0.1622</td>\n",
       "\t\t<td>0.07393</td>\n",
       "\t\t<td>0.2781</td>\n",
       "\t\t<td>0.08052</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>927241</td>\n",
       "\t\t<td>20.6</td>\n",
       "\t\t<td>29.33</td>\n",
       "\t\t<td>140.1</td>\n",
       "\t\t<td>1265.0</td>\n",
       "\t\t<td>0.1178</td>\n",
       "\t\t<td>0.277</td>\n",
       "\t\t<td>0.3514</td>\n",
       "\t\t<td>0.152</td>\n",
       "\t\t<td>0.2397</td>\n",
       "\t\t<td>0.07016</td>\n",
       "\t\t<td>0.726</td>\n",
       "\t\t<td>1.595</td>\n",
       "\t\t<td>5.772</td>\n",
       "\t\t<td>86.22</td>\n",
       "\t\t<td>0.006522</td>\n",
       "\t\t<td>0.06158</td>\n",
       "\t\t<td>0.07117</td>\n",
       "\t\t<td>0.01664</td>\n",
       "\t\t<td>0.02324</td>\n",
       "\t\t<td>0.006185</td>\n",
       "\t\t<td>25.74</td>\n",
       "\t\t<td>39.42</td>\n",
       "\t\t<td>184.6</td>\n",
       "\t\t<td>1821.0</td>\n",
       "\t\t<td>0.165</td>\n",
       "\t\t<td>0.8681</td>\n",
       "\t\t<td>0.9387</td>\n",
       "\t\t<td>0.265</td>\n",
       "\t\t<td>0.4087</td>\n",
       "\t\t<td>0.124</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.01,\"probability_1\":0.99,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>855133</td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t\t<td>1.214</td>\n",
       "\t\t<td>2.188</td>\n",
       "\t\t<td>8.077</td>\n",
       "\t\t<td>106.0</td>\n",
       "\t\t<td>0.006883</td>\n",
       "\t\t<td>0.01094</td>\n",
       "\t\t<td>0.01818</td>\n",
       "\t\t<td>0.01917</td>\n",
       "\t\t<td>0.007882</td>\n",
       "\t\t<td>0.001754</td>\n",
       "\t\t<td>14.99</td>\n",
       "\t\t<td>25.2</td>\n",
       "\t\t<td>95.54</td>\n",
       "\t\t<td>698.8</td>\n",
       "\t\t<td>0.09387</td>\n",
       "\t\t<td>0.05131</td>\n",
       "\t\t<td>0.02398</td>\n",
       "\t\t<td>0.02899</td>\n",
       "\t\t<td>0.1565</td>\n",
       "\t\t<td>0.05504</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.12,\"probability_1\":0.88,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "         id  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst prediction                                                          json_report\n",
       "0    897137        11.25         14.78           71.38      390.0          0.08306           0.04458        0.000974             0.002941         0.1773                 0.06081     0.2144      0.9961         1.529    15.07       0.005617        0.007124      0.000974           0.002941     0.017000              0.002030         12.76          22.06            82.08       492.7           0.11660            0.09794         0.005518               0.01667          0.2815                  0.07418          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "1    855133        14.99         25.20           95.54      698.8          0.09387           0.05131        0.023980             0.028990         0.1565                 0.05504     1.2140      2.1880         8.077   106.00       0.006883        0.010940      0.018180           0.019170     0.007882              0.001754         14.99          25.20            95.54       698.8           0.09387            0.05131         0.023980               0.02899          0.1565                  0.05504          1  {\"probability_0\":0.12,\"probability_1\":0.88,\"predicted_diagnosis\":1}\n",
       "2    899667        15.75         19.22          107.10      758.6          0.12430           0.23640        0.291400             0.124200         0.2375                 0.07603     0.5204      1.3240         3.477    51.22       0.009329        0.065590      0.099530           0.022830     0.055430              0.007330         17.36          24.17           119.40       915.3           0.15500            0.50460         0.687200               0.21350          0.4245                  0.10500          1  {\"probability_0\":0.19,\"probability_1\":0.81,\"predicted_diagnosis\":1}\n",
       "3  90602302        15.50         21.08          102.90      803.1          0.11200           0.15710        0.152200             0.084810         0.2085                 0.06864     1.3700      1.2130         9.424   176.50       0.008198        0.038890      0.044930           0.021390     0.020180              0.005815         23.17          27.65           157.10      1748.0           0.15170            0.40020         0.421100               0.21340          0.3003                  0.10480          1    {\"probability_0\":0.0,\"probability_1\":1.0,\"predicted_diagnosis\":1}\n",
       "4    921386        14.47         24.99           95.81      656.4          0.08837           0.12300        0.100900             0.038900         0.1872                 0.06341     0.2542      1.0790         2.615    23.11       0.007138        0.046530      0.038290           0.011620     0.020680              0.006111         16.22          31.73           113.50       808.9           0.13400            0.42020         0.404000               0.12050          0.3187                  0.10230          0  {\"probability_0\":0.75,\"probability_1\":0.25,\"predicted_diagnosis\":0}\n",
       "5  89742801        17.06         21.00          111.80      918.6          0.11190           0.10560        0.150800             0.099340         0.1727                 0.06071     0.8161      2.1290         6.076    87.17       0.006455        0.017970      0.045020           0.017440     0.018290              0.003733         20.99          33.15           143.20      1362.0           0.14490            0.20530         0.392000               0.18270          0.2623                  0.07599          1  {\"probability_0\":0.03,\"probability_1\":0.97,\"predicted_diagnosis\":1}\n",
       "6   9012315        16.35         23.29          109.00      840.4          0.09742           0.14970        0.181100             0.087730         0.2175                 0.06218     0.4312      1.0220         2.972    45.50       0.005635        0.039170      0.060720           0.016560     0.031970              0.004085         19.38          31.03           129.30      1165.0           0.14150            0.46650         0.708700               0.22480          0.4824                  0.09614          1  {\"probability_0\":0.04,\"probability_1\":0.96,\"predicted_diagnosis\":1}\n",
       "7    913535        16.69         20.20          107.10      857.6          0.07497           0.07112        0.036490             0.023070         0.1846                 0.05325     0.2473      0.5679         1.775    22.95       0.002667        0.014460      0.014230           0.005297     0.019610              0.001700         19.18          26.56           127.30      1084.0           0.10090            0.29200         0.247700               0.08737          0.4677                  0.07623          1  {\"probability_0\":0.16,\"probability_1\":0.84,\"predicted_diagnosis\":1}\n",
       "8    861598        14.64         15.24           95.77      651.9          0.11320           0.13390        0.099660             0.070640         0.2116                 0.06346     0.5115      0.7372         3.814    42.76       0.005508        0.044120      0.044360           0.016230     0.024270              0.004841         16.34          18.24           109.40       803.6           0.12770            0.30890         0.260400               0.13970          0.3151                  0.08473          0  {\"probability_0\":0.77,\"probability_1\":0.23,\"predicted_diagnosis\":0}\n",
       "9    852973        15.30         25.27          102.40      732.4          0.10820           0.16970        0.168300             0.087510         0.1926                 0.06540     0.4390      1.0120         3.498    43.50       0.005233        0.030570      0.035760           0.010830     0.017680              0.002967         20.27          36.71           149.30      1269.0           0.16410            0.61100         0.633500               0.20240          0.4027                  0.09876          1    {\"probability_0\":0.0,\"probability_1\":1.0,\"predicted_diagnosis\":1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = byom_predictor.predict(df_test, df_test.columns)\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>t1_id</th>\n",
       "\t\t<th>t2_id</th>\n",
       "\t\t<th>diagnosis</th>\n",
       "\t\t<th>radius_mean</th>\n",
       "\t\t<th>texture_mean</th>\n",
       "\t\t<th>perimeter_mean</th>\n",
       "\t\t<th>area_mean</th>\n",
       "\t\t<th>smoothness_mean</th>\n",
       "\t\t<th>compactness_mean</th>\n",
       "\t\t<th>concavity_mean</th>\n",
       "\t\t<th>concave_points_mean</th>\n",
       "\t\t<th>symmetry_mean</th>\n",
       "\t\t<th>fractal_dimension_mean</th>\n",
       "\t\t<th>radius_se</th>\n",
       "\t\t<th>texture_se</th>\n",
       "\t\t<th>perimeter_se</th>\n",
       "\t\t<th>area_se</th>\n",
       "\t\t<th>smoothness_se</th>\n",
       "\t\t<th>compactness_se</th>\n",
       "\t\t<th>concavity_se</th>\n",
       "\t\t<th>concave_points_se</th>\n",
       "\t\t<th>symmetry_se</th>\n",
       "\t\t<th>fractal_dimension_se</th>\n",
       "\t\t<th>radius_worst</th>\n",
       "\t\t<th>texture_worst</th>\n",
       "\t\t<th>perimeter_worst</th>\n",
       "\t\t<th>area_worst</th>\n",
       "\t\t<th>smoothness_worst</th>\n",
       "\t\t<th>compactness_worst</th>\n",
       "\t\t<th>concavity_worst</th>\n",
       "\t\t<th>concave_points_worst</th>\n",
       "\t\t<th>symmetry_worst</th>\n",
       "\t\t<th>fractal_dimension_worst</th>\n",
       "\t\t<th>prediction</th>\n",
       "\t\t<th>json_report</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>927241</td>\n",
       "\t\t<td>927241</td>\n",
       "\t\t<td>1  </td>\n",
       "\t\t<td>20.6</td>\n",
       "\t\t<td>29.33</td>\n",
       "\t\t<td>140.1</td>\n",
       "\t\t<td>1265.0</td>\n",
       "\t\t<td>0.1178</td>\n",
       "\t\t<td>0.277</td>\n",
       "\t\t<td>0.3514</td>\n",
       "\t\t<td>0.152</td>\n",
       "\t\t<td>0.2397</td>\n",
       "\t\t<td>0.07016</td>\n",
       "\t\t<td>0.726</td>\n",
       "\t\t<td>1.595</td>\n",
       "\t\t<td>5.772</td>\n",
       "\t\t<td>86.22</td>\n",
       "\t\t<td>0.006522</td>\n",
       "\t\t<td>0.06158</td>\n",
       "\t\t<td>0.07117</td>\n",
       "\t\t<td>0.01664</td>\n",
       "\t\t<td>0.02324</td>\n",
       "\t\t<td>0.006185</td>\n",
       "\t\t<td>25.74</td>\n",
       "\t\t<td>39.42</td>\n",
       "\t\t<td>184.6</td>\n",
       "\t\t<td>1821.0</td>\n",
       "\t\t<td>0.165</td>\n",
       "\t\t<td>0.8681</td>\n",
       "\t\t<td>0.9387</td>\n",
       "\t\t<td>0.265</td>\n",
       "\t\t<td>0.4087</td>\n",
       "\t\t<td>0.124</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.01,\"probability_1\":0.99,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>914862</td>\n",
       "\t\t<td>914862</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>15.04</td>\n",
       "\t\t<td>16.74</td>\n",
       "\t\t<td>98.73</td>\n",
       "\t\t<td>689.4</td>\n",
       "\t\t<td>0.09883</td>\n",
       "\t\t<td>0.1364</td>\n",
       "\t\t<td>0.07721</td>\n",
       "\t\t<td>0.06142</td>\n",
       "\t\t<td>0.1668</td>\n",
       "\t\t<td>0.06869</td>\n",
       "\t\t<td>0.372</td>\n",
       "\t\t<td>0.8423</td>\n",
       "\t\t<td>2.304</td>\n",
       "\t\t<td>34.84</td>\n",
       "\t\t<td>0.004123</td>\n",
       "\t\t<td>0.01819</td>\n",
       "\t\t<td>0.01996</td>\n",
       "\t\t<td>0.01004</td>\n",
       "\t\t<td>0.01055</td>\n",
       "\t\t<td>0.003237</td>\n",
       "\t\t<td>16.76</td>\n",
       "\t\t<td>20.43</td>\n",
       "\t\t<td>109.7</td>\n",
       "\t\t<td>856.9</td>\n",
       "\t\t<td>0.1135</td>\n",
       "\t\t<td>0.2176</td>\n",
       "\t\t<td>0.1856</td>\n",
       "\t\t<td>0.1018</td>\n",
       "\t\t<td>0.2177</td>\n",
       "\t\t<td>0.08549</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":0.94,\"probability_1\":0.06,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>8711003</td>\n",
       "\t\t<td>8711003</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>12.25</td>\n",
       "\t\t<td>17.94</td>\n",
       "\t\t<td>78.27</td>\n",
       "\t\t<td>460.3</td>\n",
       "\t\t<td>0.08654</td>\n",
       "\t\t<td>0.06679</td>\n",
       "\t\t<td>0.03885</td>\n",
       "\t\t<td>0.02331</td>\n",
       "\t\t<td>0.197</td>\n",
       "\t\t<td>0.06228</td>\n",
       "\t\t<td>0.22</td>\n",
       "\t\t<td>0.9823</td>\n",
       "\t\t<td>1.484</td>\n",
       "\t\t<td>16.51</td>\n",
       "\t\t<td>0.005518</td>\n",
       "\t\t<td>0.01562</td>\n",
       "\t\t<td>0.01994</td>\n",
       "\t\t<td>0.007924</td>\n",
       "\t\t<td>0.01799</td>\n",
       "\t\t<td>0.002484</td>\n",
       "\t\t<td>13.59</td>\n",
       "\t\t<td>25.22</td>\n",
       "\t\t<td>86.6</td>\n",
       "\t\t<td>564.2</td>\n",
       "\t\t<td>0.1217</td>\n",
       "\t\t<td>0.1788</td>\n",
       "\t\t<td>0.1943</td>\n",
       "\t\t<td>0.08211</td>\n",
       "\t\t<td>0.3113</td>\n",
       "\t\t<td>0.08132</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>87930</td>\n",
       "\t\t<td>87930</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>12.47</td>\n",
       "\t\t<td>18.6</td>\n",
       "\t\t<td>81.09</td>\n",
       "\t\t<td>481.9</td>\n",
       "\t\t<td>0.09965</td>\n",
       "\t\t<td>0.1058</td>\n",
       "\t\t<td>0.08005</td>\n",
       "\t\t<td>0.03821</td>\n",
       "\t\t<td>0.1925</td>\n",
       "\t\t<td>0.06373</td>\n",
       "\t\t<td>0.3961</td>\n",
       "\t\t<td>1.044</td>\n",
       "\t\t<td>2.497</td>\n",
       "\t\t<td>30.29</td>\n",
       "\t\t<td>0.006953</td>\n",
       "\t\t<td>0.01911</td>\n",
       "\t\t<td>0.02701</td>\n",
       "\t\t<td>0.01037</td>\n",
       "\t\t<td>0.01782</td>\n",
       "\t\t<td>0.003586</td>\n",
       "\t\t<td>14.97</td>\n",
       "\t\t<td>24.64</td>\n",
       "\t\t<td>96.05</td>\n",
       "\t\t<td>677.9</td>\n",
       "\t\t<td>0.1426</td>\n",
       "\t\t<td>0.2378</td>\n",
       "\t\t<td>0.2671</td>\n",
       "\t\t<td>0.1015</td>\n",
       "\t\t<td>0.3014</td>\n",
       "\t\t<td>0.0875</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>868999</td>\n",
       "\t\t<td>868999</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>9.738</td>\n",
       "\t\t<td>11.97</td>\n",
       "\t\t<td>61.24</td>\n",
       "\t\t<td>288.5</td>\n",
       "\t\t<td>0.0925</td>\n",
       "\t\t<td>0.04102</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.1903</td>\n",
       "\t\t<td>0.06422</td>\n",
       "\t\t<td>0.1988</td>\n",
       "\t\t<td>0.496</td>\n",
       "\t\t<td>1.218</td>\n",
       "\t\t<td>12.26</td>\n",
       "\t\t<td>0.00604</td>\n",
       "\t\t<td>0.005656</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.02277</td>\n",
       "\t\t<td>0.00322</td>\n",
       "\t\t<td>10.62</td>\n",
       "\t\t<td>14.1</td>\n",
       "\t\t<td>66.53</td>\n",
       "\t\t<td>342.9</td>\n",
       "\t\t<td>0.1234</td>\n",
       "\t\t<td>0.07204</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>0.3105</td>\n",
       "\t\t<td>0.08151</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>857438</td>\n",
       "\t\t<td>857438</td>\n",
       "\t\t<td>1  </td>\n",
       "\t\t<td>15.1</td>\n",
       "\t\t<td>22.02</td>\n",
       "\t\t<td>97.26</td>\n",
       "\t\t<td>712.8</td>\n",
       "\t\t<td>0.09056</td>\n",
       "\t\t<td>0.07081</td>\n",
       "\t\t<td>0.05253</td>\n",
       "\t\t<td>0.03334</td>\n",
       "\t\t<td>0.1616</td>\n",
       "\t\t<td>0.05684</td>\n",
       "\t\t<td>0.3105</td>\n",
       "\t\t<td>0.8339</td>\n",
       "\t\t<td>2.097</td>\n",
       "\t\t<td>29.91</td>\n",
       "\t\t<td>0.004675</td>\n",
       "\t\t<td>0.0103</td>\n",
       "\t\t<td>0.01603</td>\n",
       "\t\t<td>0.009222</td>\n",
       "\t\t<td>0.01095</td>\n",
       "\t\t<td>0.001629</td>\n",
       "\t\t<td>18.1</td>\n",
       "\t\t<td>31.69</td>\n",
       "\t\t<td>117.7</td>\n",
       "\t\t<td>1030.0</td>\n",
       "\t\t<td>0.1389</td>\n",
       "\t\t<td>0.2057</td>\n",
       "\t\t<td>0.2712</td>\n",
       "\t\t<td>0.153</td>\n",
       "\t\t<td>0.2675</td>\n",
       "\t\t<td>0.07873</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.09,\"probability_1\":0.91,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>911150</td>\n",
       "\t\t<td>911150</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>14.53</td>\n",
       "\t\t<td>19.34</td>\n",
       "\t\t<td>94.25</td>\n",
       "\t\t<td>659.7</td>\n",
       "\t\t<td>0.08388</td>\n",
       "\t\t<td>0.078</td>\n",
       "\t\t<td>0.08817</td>\n",
       "\t\t<td>0.02925</td>\n",
       "\t\t<td>0.1473</td>\n",
       "\t\t<td>0.05746</td>\n",
       "\t\t<td>0.2535</td>\n",
       "\t\t<td>1.354</td>\n",
       "\t\t<td>1.994</td>\n",
       "\t\t<td>23.04</td>\n",
       "\t\t<td>0.004147</td>\n",
       "\t\t<td>0.02048</td>\n",
       "\t\t<td>0.03379</td>\n",
       "\t\t<td>0.008848</td>\n",
       "\t\t<td>0.01394</td>\n",
       "\t\t<td>0.002327</td>\n",
       "\t\t<td>16.3</td>\n",
       "\t\t<td>28.39</td>\n",
       "\t\t<td>108.1</td>\n",
       "\t\t<td>830.5</td>\n",
       "\t\t<td>0.1089</td>\n",
       "\t\t<td>0.2649</td>\n",
       "\t\t<td>0.3779</td>\n",
       "\t\t<td>0.09594</td>\n",
       "\t\t<td>0.2471</td>\n",
       "\t\t<td>0.07463</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>904357</td>\n",
       "\t\t<td>904357</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>11.8</td>\n",
       "\t\t<td>17.26</td>\n",
       "\t\t<td>75.26</td>\n",
       "\t\t<td>431.9</td>\n",
       "\t\t<td>0.09087</td>\n",
       "\t\t<td>0.06232</td>\n",
       "\t\t<td>0.02853</td>\n",
       "\t\t<td>0.01638</td>\n",
       "\t\t<td>0.1847</td>\n",
       "\t\t<td>0.06019</td>\n",
       "\t\t<td>0.3438</td>\n",
       "\t\t<td>1.14</td>\n",
       "\t\t<td>2.225</td>\n",
       "\t\t<td>25.06</td>\n",
       "\t\t<td>0.005463</td>\n",
       "\t\t<td>0.01964</td>\n",
       "\t\t<td>0.02079</td>\n",
       "\t\t<td>0.005398</td>\n",
       "\t\t<td>0.01477</td>\n",
       "\t\t<td>0.003071</td>\n",
       "\t\t<td>13.45</td>\n",
       "\t\t<td>24.49</td>\n",
       "\t\t<td>86.0</td>\n",
       "\t\t<td>562.0</td>\n",
       "\t\t<td>0.1244</td>\n",
       "\t\t<td>0.1726</td>\n",
       "\t\t<td>0.1449</td>\n",
       "\t\t<td>0.05356</td>\n",
       "\t\t<td>0.2779</td>\n",
       "\t\t<td>0.08121</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>905501</td>\n",
       "\t\t<td>905501</td>\n",
       "\t\t<td>0  </td>\n",
       "\t\t<td>12.27</td>\n",
       "\t\t<td>17.92</td>\n",
       "\t\t<td>78.41</td>\n",
       "\t\t<td>466.1</td>\n",
       "\t\t<td>0.08685</td>\n",
       "\t\t<td>0.06526</td>\n",
       "\t\t<td>0.03211</td>\n",
       "\t\t<td>0.02653</td>\n",
       "\t\t<td>0.1966</td>\n",
       "\t\t<td>0.05597</td>\n",
       "\t\t<td>0.3342</td>\n",
       "\t\t<td>1.781</td>\n",
       "\t\t<td>2.079</td>\n",
       "\t\t<td>25.79</td>\n",
       "\t\t<td>0.005888</td>\n",
       "\t\t<td>0.0231</td>\n",
       "\t\t<td>0.02059</td>\n",
       "\t\t<td>0.01075</td>\n",
       "\t\t<td>0.02578</td>\n",
       "\t\t<td>0.002267</td>\n",
       "\t\t<td>14.1</td>\n",
       "\t\t<td>28.88</td>\n",
       "\t\t<td>89.0</td>\n",
       "\t\t<td>610.2</td>\n",
       "\t\t<td>0.124</td>\n",
       "\t\t<td>0.1795</td>\n",
       "\t\t<td>0.1377</td>\n",
       "\t\t<td>0.09532</td>\n",
       "\t\t<td>0.3455</td>\n",
       "\t\t<td>0.06896</td>\n",
       "\t\t<td>0</td>\n",
       "\t\t<td>{\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>852973</td>\n",
       "\t\t<td>852973</td>\n",
       "\t\t<td>1  </td>\n",
       "\t\t<td>15.3</td>\n",
       "\t\t<td>25.27</td>\n",
       "\t\t<td>102.4</td>\n",
       "\t\t<td>732.4</td>\n",
       "\t\t<td>0.1082</td>\n",
       "\t\t<td>0.1697</td>\n",
       "\t\t<td>0.1683</td>\n",
       "\t\t<td>0.08751</td>\n",
       "\t\t<td>0.1926</td>\n",
       "\t\t<td>0.0654</td>\n",
       "\t\t<td>0.439</td>\n",
       "\t\t<td>1.012</td>\n",
       "\t\t<td>3.498</td>\n",
       "\t\t<td>43.5</td>\n",
       "\t\t<td>0.005233</td>\n",
       "\t\t<td>0.03057</td>\n",
       "\t\t<td>0.03576</td>\n",
       "\t\t<td>0.01083</td>\n",
       "\t\t<td>0.01768</td>\n",
       "\t\t<td>0.002967</td>\n",
       "\t\t<td>20.27</td>\n",
       "\t\t<td>36.71</td>\n",
       "\t\t<td>149.3</td>\n",
       "\t\t<td>1269.0</td>\n",
       "\t\t<td>0.1641</td>\n",
       "\t\t<td>0.611</td>\n",
       "\t\t<td>0.6335</td>\n",
       "\t\t<td>0.2024</td>\n",
       "\t\t<td>0.4027</td>\n",
       "\t\t<td>0.09876</td>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>{\"probability_0\":0.0,\"probability_1\":1.0,\"predicted_diagnosis\":1}</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "      t1_id     t2_id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  concave_points_se  symmetry_se  fractal_dimension_se  radius_worst  texture_worst  perimeter_worst  area_worst  smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  symmetry_worst  fractal_dimension_worst prediction                                                          json_report\n",
       "0    904357    904357       0          11.80         17.26           75.26      431.9          0.09087           0.06232         0.02853              0.01638         0.1847                 0.06019     0.3438      1.1400         2.225    25.06       0.005463        0.019640       0.02079           0.005398      0.01477              0.003071         13.45          24.49            86.00       562.0           0.12440            0.17260          0.14490               0.05356          0.2779                  0.08121          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "1    842302    842302       1          17.99         10.38          122.80     1001.0          0.11840           0.27760         0.30010              0.14710         0.2419                 0.07871     1.0950      0.9053         8.589   153.40       0.006399        0.049040       0.05373           0.015870      0.03003              0.006193         25.38          17.33           184.60      2019.0           0.16220            0.66560          0.71190               0.26540          0.4601                  0.11890          1  {\"probability_0\":0.01,\"probability_1\":0.99,\"predicted_diagnosis\":1}\n",
       "2    899987    899987       1          25.73         17.46          174.20     2010.0          0.11490           0.23630         0.33680              0.19130         0.1956                 0.06121     0.9948      0.8509         7.222   153.10       0.006369        0.042430       0.04266           0.015080      0.02335              0.003385         33.13          23.58           229.30      3234.0           0.15300            0.59370          0.64510               0.27560          0.3690                  0.08815          1    {\"probability_0\":0.0,\"probability_1\":1.0,\"predicted_diagnosis\":1}\n",
       "3    862965    862965       0          12.18         20.52           77.22      458.7          0.08013           0.04038         0.02383              0.01770         0.1739                 0.05677     0.1924      1.5710         1.183    14.68       0.005080        0.006098       0.01069           0.006797      0.01447              0.001532         13.34          32.84            84.58       547.8           0.11230            0.08862          0.11450               0.07431          0.2694                  0.06878          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "4    905501    905501       0          12.27         17.92           78.41      466.1          0.08685           0.06526         0.03211              0.02653         0.1966                 0.05597     0.3342      1.7810         2.079    25.79       0.005888        0.023100       0.02059           0.010750      0.02578              0.002267         14.10          28.88            89.00       610.2           0.12400            0.17950          0.13770               0.09532          0.3455                  0.06896          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "5  90602302  90602302       1          15.50         21.08          102.90      803.1          0.11200           0.15710         0.15220              0.08481         0.2085                 0.06864     1.3700      1.2130         9.424   176.50       0.008198        0.038890       0.04493           0.021390      0.02018              0.005815         23.17          27.65           157.10      1748.0           0.15170            0.40020          0.42110               0.21340          0.3003                  0.10480          1    {\"probability_0\":0.0,\"probability_1\":1.0,\"predicted_diagnosis\":1}\n",
       "6    861598    861598       0          14.64         15.24           95.77      651.9          0.11320           0.13390         0.09966              0.07064         0.2116                 0.06346     0.5115      0.7372         3.814    42.76       0.005508        0.044120       0.04436           0.016230      0.02427              0.004841         16.34          18.24           109.40       803.6           0.12770            0.30890          0.26040               0.13970          0.3151                  0.08473          0  {\"probability_0\":0.77,\"probability_1\":0.23,\"predicted_diagnosis\":0}\n",
       "7    868202    868202       1          12.77         22.47           81.72      506.3          0.09055           0.05761         0.04711              0.02704         0.1585                 0.06065     0.2367      1.3800         1.457    19.87       0.007499        0.012020       0.02332           0.008920      0.01647              0.002629         14.49          33.37            92.04       653.6           0.14190            0.15230          0.21770               0.09331          0.2829                  0.08067          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}\n",
       "8  89742801  89742801       1          17.06         21.00          111.80      918.6          0.11190           0.10560         0.15080              0.09934         0.1727                 0.06071     0.8161      2.1290         6.076    87.17       0.006455        0.017970       0.04502           0.017440      0.01829              0.003733         20.99          33.15           143.20      1362.0           0.14490            0.20530          0.39200               0.18270          0.2623                  0.07599          1  {\"probability_0\":0.03,\"probability_1\":0.97,\"predicted_diagnosis\":1}\n",
       "9    891936    891936       0          10.91         12.35           69.14      363.7          0.08518           0.04721         0.01236              0.01369         0.1449                 0.06031     0.1753      1.0270         1.267    11.09       0.003478        0.012210       0.01072           0.009393      0.02941              0.003428         11.37          14.82            72.42       392.2           0.09312            0.07506          0.02884               0.03194          0.2143                  0.06643          0    {\"probability_0\":1.0,\"probability_1\":0.0,\"predicted_diagnosis\":0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join = df.select([\"id\",\"diagnosis\"])\n",
    "df_final = df_join.merge(right=df_predict, how='inner', on=\"id\", lsuffix = 't1', rsuffix='t2')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>9. Evaluate the model</b></p>\n",
    "\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>9.1 Classification Evaluator</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The ClassificationEvaluator() function evaluate and emits various metrics of classification model based on its predictions on the data. Apart from accuracy, the secondary output data returns micro, macro, and weighted-averaged metrics of precision, recall, and F1-score values.</p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = df_final.assign(drop_columns=True,\n",
    "                          id = df_final.t1_id,\n",
    "                          diagnosis = df_final.diagnosis.cast(type_=INTEGER),\n",
    "                          prediction = df_final.prediction.cast(type_=INTEGER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>SeqNum</th>\n",
       "\t\t<th>Metric</th>\n",
       "\t\t<th>MetricValue</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>3</td>\n",
       "\t\t<td>Micro-Recall</td>\n",
       "\t\t<td>0.956140350877193</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>5</td>\n",
       "\t\t<td>Macro-Precision</td>\n",
       "\t\t<td>0.9539473684210527</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>6</td>\n",
       "\t\t<td>Macro-Recall</td>\n",
       "\t\t<td>0.9482051282051283</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>7</td>\n",
       "\t\t<td>Macro-F1</td>\n",
       "\t\t<td>0.950976176141739</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>9</td>\n",
       "\t\t<td>Weighted-Recall</td>\n",
       "\t\t<td>0.956140350877193</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>10</td>\n",
       "\t\t<td>Weighted-F1</td>\n",
       "\t\t<td>0.9560007785870456</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>8</td>\n",
       "\t\t<td>Weighted-Precision</td>\n",
       "\t\t<td>0.9560249307479224</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>4</td>\n",
       "\t\t<td>Micro-F1</td>\n",
       "\t\t<td>0.956140350877193</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>2</td>\n",
       "\t\t<td>Micro-Precision</td>\n",
       "\t\t<td>0.956140350877193</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>1</td>\n",
       "\t\t<td>Accuracy</td>\n",
       "\t\t<td>0.956140350877193</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "   SeqNum              Metric  MetricValue\n",
       "0       3        Micro-Recall     0.956140\n",
       "1       5     Macro-Precision     0.953947\n",
       "2       6        Macro-Recall     0.948205\n",
       "3       7            Macro-F1     0.950976\n",
       "4       9     Weighted-Recall     0.956140\n",
       "5      10         Weighted-F1     0.956001\n",
       "6       8  Weighted-Precision     0.956025\n",
       "7       4            Micro-F1     0.956140\n",
       "8       2     Micro-Precision     0.956140\n",
       "9       1            Accuracy     0.956140"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ClassificationEvaluator_obj = ClassificationEvaluator(data=df_final,\n",
    "                                                          observation_column='diagnosis',\n",
    "                                                          prediction_column='prediction',\n",
    "                                                          labels=['0', '1'])\n",
    "classeval_df = ClassificationEvaluator_obj.output_data\n",
    "classeval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>9.2 Show AUC-ROC Curve</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The <a href = 'https://docs.teradata.com/search/all?query=TD_ROC&content-lang=en-US'>ROC</a> curve shows the performance of a binary classification model as its discrimination threshold varies. For a range of thresholds, the curve plots the true positive rate against false-positive rate.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>This function accepts a set of prediction-actual pairs as input and calculates the following values for a range of discrimination thresholds.</p>\n",
    "    <ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>True-positive rate (TPR)</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>False-positive rate (FPR)</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>The area under the ROC curve (AUC)</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>Gini coefficient</li>\n",
    "        <li style = 'font-size:16px;font-family:Arial;color:#00233C'>Other details are mentioned in the documentation</li>\n",
    "    </ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "\ttable {border:ridge 5px;}\n",
       "\ttable td {border:inset 1px;}\n",
       "\ttable tr#HeaderRow {background-color:grey; color:white;}</style>\n",
       "<html><table>\n",
       "\t<tr id=\"HeaderRow\">\n",
       "\t\t<th>threshold_value</th>\n",
       "\t\t<th>tpr</th>\n",
       "\t\t<th>fpr</th>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.04081632653061224</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.08163265306122448</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.1020408163265306</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.12244897959183673</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.16326530612244897</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.18367346938775508</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.14285714285714285</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.061224489795918366</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.02040816326530612</td>\n",
       "\t\t<td>0.9423076923076923</td>\n",
       "\t\t<td>0.016129032258064516</td>\n",
       "\t</tr>\n",
       "\t<tr>\n",
       "\t\t<td>0.0</td>\n",
       "\t\t<td>1.0</td>\n",
       "\t\t<td>1.0</td>\n",
       "\t</tr>\n",
       "</table></html>"
      ],
      "text/plain": [
       "   threshold_value       tpr       fpr\n",
       "0         0.040816  0.942308  0.016129\n",
       "1         0.081633  0.942308  0.016129\n",
       "2         0.102041  0.942308  0.016129\n",
       "3         0.122449  0.942308  0.016129\n",
       "4         0.163265  0.942308  0.016129\n",
       "5         0.183673  0.942308  0.016129\n",
       "6         0.142857  0.942308  0.016129\n",
       "7         0.061224  0.942308  0.016129\n",
       "8         0.020408  0.942308  0.016129\n",
       "9         0.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from teradataml import ROC \n",
    "roc_df = ROC(data = pred_df, \n",
    "                    probability_column = \"prediction\",\n",
    "                    observation_column = \"diagnosis\",\n",
    "                    positive_class=\"1\"\n",
    "                    )\n",
    "roc_df.output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9554900744416873"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_df.result.get_values()[0][0]\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Plot ROC Curves</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvXklEQVR4nO3de5xVdb3/8debmQEUERPIVERA8AKCqCR5KrRjKeL1pAGe8pZmWWr+MNNTpqadtCzLEq9pWhZ4KZUSwzpKaqWAicpFDREFvHDxgmggg5/fH+s7w57NnpkNzN7DzH4/H495zF5rfddan7X23t/PWt/v2mspIjAzs8rVobUDMDOz1uVEYGZW4ZwIzMwqnBOBmVmFcyIwM6twTgRmZhXOiWAzI2m2pANbO47NhaRvSfpFK637Fknfa411tzRJn5f0wEbOu9GfSUl/k7T3xsy7sSSdKekH5VxnW+dE0ARJCyT9W9JKSa+limGrUq4zIgZFxNRSrqOOpE6SLpP0ctrOf0k6V5LKsf4C8RwoaVHuuIj4fkScWqL1SdJZkmZJelfSIkl3ShpcivVtLEkXS7ptU5YREb+JiIOLWNd6yW9jP5OSjgDeiYgn0/DFktak79Nbkv4uaf+8ebaRdG36vr0n6RlJJxdY9n9LmpGW9aqk+yV9Ik2+Efi8pA83EVubeO/LxYmgeUdExFbAUGBv4H9aN5wNJ6m6kUl3AgcBo4CuwPHAacBVJYhBkja3z9tVwNeBs4BtgV2Be4DDWnpFTbwHJdeK6/4K8Ou8cben71MP4CGyzyAAkjoCfwF2BvYHugHnApdLGpdTbhzwU+D7wHZAb+Aa4CiAiFgF3A+c0ERsLfbet+Z722Iiwn+N/AELgE/nDP8QuC9n+GPA34G3gKeAA3OmbQv8EngFeBO4J2fa4cDMNN/fgSH56wR2AP4NbJszbW9gGVCThr8IzE3LnwLsnFM2gK8B/wJeLLBtBwGrgJ3yxg8H1gL90/BU4DJgGrACuDcvpqb2wVTgf4G/pW3pD5ycYn4HmA98OZXtksp8AKxMfzsAFwO3pTJ90nadCLyc9sW3c9a3BXBr2h9zgW8Cixp5bwek7dyviff/FmA8cF+K93Fgl5zpVwEL0355AvhkzrSLgbuA29L0U4H9gH+kffUqcDXQMWeeQcCfgTeA14FvASOB94E1aZ88lcp2A25Ky1kMfA+oStNOSvv8J8DyNO0k4NE0XWnakhTbM8CeZAcBa9L6VgJ/yP8eAFUprhfSPnmCvM9QKtcxvZ+98vbJbTnDA9P72TMNn5Ji6pK3rDEpnq3Tdq8EPtfMd/fzwEOb8N5PBU7NGa7ff4W+X8C1wI/ylnEvMC693gH4HbA0lT+rteu3BrG2dgCb81/eF6BX+sJclYZ3TF+yUWRnVp9Jw3Uf6vuA24EPATXAAWn83unDPjx9qU5M6+lUYJ0PAl/KiecK4Lr0+ihgHrAHUA1cAPw974P6Z7KEtEWBbbsc+Gsj2/0S6yroqWQVzZ5klfXvWFcxN7cPppJV2INSjDVkR1y7kFVGBwDvAfuk8geSV3FTOBHcSFbp7wWsBvbI3aa0z3sBT+cvL2e5XwFeaub9vyVtz34p/t8AE3OmfwHonqadA7wGdM6Jew1wdNo3WwD7kiXO6rQtc4GzU/muZJX6OUDnNDw8fx/krPtu4Pr0nnyYLFHXvWcnAbXAmWldW9AwERxCVoFvk96HPYDtc7b5e018D84l+x7slubdC+heYN8NAt5t4r3smN6vZUB1GjcRuLXAsqrT9hxClhhr6+Zp4r3bB3hjE977qTSfCOq/X8AIsoMCpekfIkuEO6T3/wngwrTd/cgOgg5p7Tqu7m9zO1XfHN0j6R2yN3kJcFEa/wVgckRMjogPIuLPwAxglKTtgUOBr0TEmxGxJiL+muY7Dbg+Ih6PiLURcStZZfaxAuv+LXAcZE0rwNg0DrIP82URMTciaslOk4dK2jln/ssi4o2I+HeBZfcgq3gKeTVNr/PriJgVEe8C3wFGS6pqah/kzHtLRMyOiNq0H+6LiBci81fgAeCTjcTRmO9GxL8j4imys5C90vjRwPfTPl8E/KyJZXRvYvtz3R0R09I+/g1ZEyEAEXFbRCxP2/ZjoBNZBVnnHxFxT9o3/46IJyLisVR+AVlFfkAqezjwWkT8OCJWRcQ7EfF4oYAkbUe2j8+OiHcjYgnZEf7YnGKvRMTP07ry3/81ZIlmd7KKa25EFLMvIDuzuSAinkvv4VMRsbxAuW3IzhjyjZb0Flkl+SXg2LRvoZHPZJq+LE3vDizLmacx75CdPRRS7HvfnNzv1yNkyaHus3ws2fv/CvBRsoOjSyLi/YiYT3YwM7bgUluBE0Hzjo6IrmRHq7uzroLcGfhc6vR6K324PwFsD+xEdjTyZoHl7QyckzffTmRHDvl+B+yfEssIsmaTR3KWc1XOMt4gO0LbMWf+hU1s17IUayHbp+mFlvMS2ZF9D5reBwVjkHSopMckvZHKj6Jh0inGazmv3wPqOvB3yFtfU9u/nMa3v5h1IekbkuZKejttSzcabkv+tu8q6Y+pI3QFWfKuK78TWXNLMXYmew9ezdnv15OdGRRcd66IeJCsWWo8sETSDZK2LnLdxcb5JlmyyXdHRGxD1rY/i+wsqU7Bz2Rqg++Rpi8HehTRLt8VeLuRacW+982p38eRnQZMJB24Af9NduAA2fu1Q9735Ftk+2Cz4ERQpHT0egvwozRqIdmR8jY5f10i4vI0bVtJ2xRY1ELgf/Pm2zIiJhRY55tkR8xjyD5YE9MHrm45X85bzhYR8ffcRTSxSX8BhkvaKXekpOFkX/YHc0bnlulNdkS5rJl9sF4MkjqRJbcfAdulCmEyWQJrLt5ivErWJFQo7nz/B/SSNGxjViTpk2R9EKOBD6VteZt12wLrb8+1wLPAgIjYmqwyqCu/kKzJoJD85SwkO4vskbPft46IQU3M03CBET+LiH3J2ul3JWvyaXa+tO5dmikDWbOlJO1YaGJELCM7O744HehA9pk8VFKXvOLHkG3vY2R9LKvJmtyasgfZ2WIhxbz37wJb5gx/pECZ/H01ATg2nZUPJ/usQ7bPXsz7nnSNiFFsJpwINsxPgc9I2ousE/AISYdIqpLUOV3+2CudZt8PXCPpQ5JqJI1Iy7gR+Iqk4elKmi6SDpNU6OgJsqagE8hONX+bM/464H8kDQKQ1E3S54rdkIj4C9kX4neSBqVt+Fjarmsj4l85xb8gaaCkLYFLgLsiYm1T+6CR1XYkaz5ZCtRKOhTIvaTxdaC7pMZO6ZtzB9k++VCqgM5orGDavmuACSnmjin+sZLOL2JdXcnaqpcC1ZIuJOvMbG6eFcBKSbsDp+dM+yOwvaSzlV3W2zUlZcj2S5+6q67S5+sB4MeStpbUQdIukg6gCJI+mj5/NWQV3iqys826dTWWkAB+AVwqaUD6/A6R1D2/UES8T1axNxpTRDxHdpHDN9OoXwOLgDsl9Unfm0PImvgujoi3I+Jtsrb28ZKOlrRlKneopB/mLP4Asu9gofUW897PBD6blt+frCO7SZFdJrss7aMpEfFWmjQNeEfSeZK2SN+VPSV9tLlllosTwQaIiKXAr4ALI2IhWYftt8gqg4VkR1V1+/R4siPnZ8n6Fs5Oy5hB1jZ6Ndnp8zyyjqjGTCK7yuG11CZeF8vdwA+AiamZYRZZv8SGOIbsEr4/kV2JcRvZlShn5pX7NdnZ0GtkHZlnpRia2wcNRMQ7ad47yLb9v9P21U1/luyoan46hS7UXNaUS8gqkhfJKqG7yI4eG3MW65pI3iJr8vgv4A9FrGsK2X57nqy5bBVNN0UBfINsm98hOyC4vW5C2jefAY4g28//Aj6VJtddYrlc0j/T6xPIEuscsn15F8U3d2yd1v9min052YUIkL3/A9P+v6fAvFeSvX8PkCW1m8g6Swu5nux70JQrgNMkfTgiVpNdMbeQ7AqtFWl9346IuvhI/THjyC6QqPvcnUF2+SeSOpM1Od7axHqbe+9/Qnb11OtpOb9ZfxEF/TZtQ/1BWzpoOpysf+lF1iWLjT3gaXF1PdxmBUmaSnalR6v8undTSDodGBsRRR0pW8uT9DfgjHS0XK51nkl2Ses3my1sQHZZllm7kNqa+5G1Iw8guxTz6lYNqsJFxMdbYZ0/L/c62zonAmtPOpI1R/QlO92fSNYWbGZNcNOQmVmFc2exmVmFa3NNQz169Ig+ffq0dhhmZm3KE088sSwiehaa1uYSQZ8+fZgxY0Zrh2Fm1qZIeqmxaW4aMjOrcE4EZmYVzonAzKzCORGYmVU4JwIzswpXskQg6WZJSyTNamS6JP1M0jxJT0vap1SxmJlZ40p5RnAL2WPlGnMo2f1gBpDdl/zaEsZiZmaNKNnvCCLiYUl9mihyFPCr9KCVxyRtI2n7DXhknpnZZi8ieH/tB7xfm/7WfsDqNR/Uj1tdW/d/bf303PH189R+wEG7f5i9dtqmxWNszR+U7UjD+7cvSuPWSwSSTiM7a6B3795lCc7M2q61H0R9Jbp67dp1r3Mq1tzKd3Uj0/Mr6NX5FXTd9LX54+rWnf1vKR/u2qndJYKiRcQNwA0Aw4YN813yzDYzEUFtqnwbHsmuZdWa/Ip13bTccbmVcHbEXLgCb1hpry14BF37QctUEx0Enaqr6FjdIfur6kCnmvQ/jduyYzXbpGl15eqmdazuQKeqDnSqqWowPXc56+apWjdfgekdqzogqfmgN0JrJoLFNHymbK80zsyK8MEHqckhr6mhwVFszlFpwyPZtQWOjvOPiNeu3zyxJr/8uqPllrqRcU2V1lW+VetXrB2rOrD1FjUNKuPGKtaGlfH6FWtuBd2pwHqqqyrjwsrWTASTgDMkTSR70PPb7h+wzV3t2kJtu4XbeAs1EeRW0MVUroXaiuuWs2Zty9S8ElkFWNWBjjlHpbmVbMfqDnTtXJ0qyUYqzwaVbVXBI+P8Cnq99VR1oEOH0hz1WuNKlggkTQAOBHpIWgRcBNQARMR1wGSy54rOA94DTi5VLNZ25Xe0FT6KXdtoxdqgHbjQcuqbG9ZvhlhdoK24hVocqO6ghkefdRVpTiW5VadqOnVpWBnnN1MUOpLtVJ3XDJFbpmr9Crq6g0rW5GBtQymvGjqumekBfK1U67eNV6ijrXATwdqcyrjwUWv+PKsLNV80UkG3dEdbwwqxQBNCVQe23LI6r1LtsF4zRaGj5QbtuwWmNyjjo17bzLSJzuL2LiJYszbvErNUUa5uULE27IQrfAlaw464QpegrRu3tuARdEt1tFV1UJNtt52q1nW0FapYG1SqTbUBN9HGW9cGXFPlo16zxlRsIqjraGvscrL1rmZopCNu/asYmjnSzVlP7riW6mhrrHMttxLtVtfRVrOu3bbhUWyB9t0Gy6kqeOTbKa+CrvJRr1mbUDGJ4OHnlzLujqf49/u1vL/2gxbraOsg1jv6zO9s61SzrqOt0KVonZo4ym2wnFRJr3f1Q05F7aNeM9tQFZMI5r66gmUrV3Pi/jvTpVP1es0HuZXxhlzjWymXl5lZ+1UxiaDOeYfuzpYdK26zzcwa5cNZM7MK50RgZlbhnAjMzCqcE4GZWYVzIjAzq3BOBGZmFc6JwMyswjkRmJlVOCcCM7MK50RgZlbhnAjMzCqcE4GZWYVzIjAzq3BOBGZmFc6JwMyswjkRmJlVOCcCM7MK50RgZlbhnAjMzCqcE4GZWYVzIjAzq3BOBGZmFc6JwMyswjkRmJlVOCcCM7MK50RgZlbhSpoIJI2U9JykeZLOLzC9t6SHJD0p6WlJo0oZj5mZra9kiUBSFTAeOBQYCBwnaWBesQuAOyJib2AscE2p4jEzs8JKeUawHzAvIuZHxPvAROCovDIBbJ1edwNeKWE8ZmZWQCkTwY7AwpzhRWlcrouBL0haBEwGziy0IEmnSZohacbSpUtLEauZWcVq7c7i44BbIqIXMAr4taT1YoqIGyJiWEQM69mzZ9mDNDNrz0qZCBYDO+UM90rjcp0C3AEQEf8AOgM9ShiTmZnlKWUimA4MkNRXUkeyzuBJeWVeBg4CkLQHWSJw24+ZWRmVLBFERC1wBjAFmEt2ddBsSZdIOjIVOwf4kqSngAnASRERpYrJzMzWV13KhUfEZLJO4NxxF+a8ngN8vJQxmJlZ01q7s9jMzFqZE4GZWYVzIjAzq3BOBGZmFc6JwMyswjkRmJlVOCcCM7MK50RgZlbhnAjMzCqcE4GZWYUrOhFI2rKUgZiZWetoNhFI+g9Jc4Bn0/BekvxISTOzdqKYM4KfAIcAywEi4ilgRCmDMjOz8imqaSgiFuaNWluCWMzMrBUUcxvqhZL+AwhJNcDXyZ4vYGZm7UAxZwRfAb5G9uD5xcBQ4KsljMnMzMqomDOC3SLi87kjJH0c+FtpQjIzs3Iq5ozg50WOMzOzNqjRMwJJ+wP/AfSUNC5n0tZAVakDMzOz8miqaagjsFUq0zVn/Arg2FIGZWZm5dNoIoiIvwJ/lXRLRLxUxpjMzKyMiuksfk/SFcAgoHPdyIj4z5JFZWZmZVNMZ/FvyG4v0Rf4LrAAmF7CmMzMrIyKSQTdI+ImYE1E/DUivgj4bMDMrJ0opmloTfr/qqTDgFeAbUsXkpmZlVMxieB7kroB55D9fmBr4OxSBmVmZuXTbCKIiD+ml28Dn4L6XxabmVk70NQPyqqA0WT3GPpTRMySdDjwLWALYO/yhGhmZqXU1BnBTcBOwDTgZ5JeAYYB50fEPWWIzczMyqCpRDAMGBIRH0jqDLwG7BIRy8sTmpmZlUNTl4++HxEfAETEKmD+hiYBSSMlPSdpnqTzGykzWtIcSbMl/XZDlm9mZpuuqTOC3SU9nV4L2CUNC4iIGNLUglMfw3jgM8AiYLqkSRExJ6fMAOB/gI9HxJuSPrwJ22JmZhuhqUSwxyYuez9gXkTMB5A0ETgKmJNT5kvA+Ih4EyAilmziOs3MbAM1ddO5Tb3R3I5A7rOOFwHD88rsCiDpb2S3tr44Iv6UvyBJpwGnAfTu3XsTwzIzs1xFPby+hKqBAcCBwHHAjZK2yS8UETdExLCIGNazZ8/yRmhm1s6VMhEsJrv8tE6vNC7XImBSRKyJiBeB58kSg5mZlUlRiUDSFpJ228BlTwcGSOorqSMwFpiUV+YesrMBJPUgayqav4HrMTOzTdBsIpB0BDAT+FMaHiopv0JfT0TUAmcAU4C5wB0RMVvSJZKOTMWmAMslzQEeAs717xTMzMqrmJvOXUx2BdBUgIiYKalvMQuPiMnA5LxxF+a8DmBc+jMzs1ZQTNPQmoh4O29clCIYMzMrv2LOCGZL+m+gKv0A7Czg76UNy8zMyqWYM4IzyZ5XvBr4LdntqM8uYUxmZlZGxZwR7B4R3wa+XepgzMys/Io5I/ixpLmSLpW0Z8kjMjOzsmo2EUTEp8ieTLYUuF7SM5IuKHlkZmZWFkX9oCwiXouInwFfIftNwYVNz2FmZm1FMT8o20PSxZKeIXt4/d/JbhdhZmbtQDGdxTcDtwOHRMQrJY7HzMzKrNlEEBH7lyMQMzNrHY0mAkl3RMTo1CSU+0viop5QZmZmbUNTZwRfT/8PL0cgZmbWOhrtLI6IV9PLr0bES7l/wFfLE56ZmZVaMZePfqbAuENbOhAzM2sdTfURnE525N9P0tM5k7oCfyt1YGZmVh5N9RH8FrgfuAw4P2f8OxHxRkmjMjOzsmkqEURELJD0tfwJkrZ1MjAzax+aOyM4HHiC7PJR5UwLoF8J4zIzszJpNBFExOHpf1GPpTQzs7apmHsNfVxSl/T6C5KulNS79KGZmVk5FHP56LXAe5L2As4BXgB+XdKozMysbIpJBLUREcBRwNURMZ7sElIzM2sHirn76DuS/gc4HvikpA5ATWnDMjOzcinmjGAM2YPrvxgRr5E9i+CKkkZlZmZlU8yjKl8DfgN0k3Q4sCoiflXyyMzMrCyKuWpoNDAN+BwwGnhc0rGlDszMzMqjmD6CbwMfjYglAJJ6An8B7iplYGZmVh7F9BF0qEsCyfIi5zMzszagmDOCP0maAkxIw2OAyaULyczMyqmYZxafK+mzwCfSqBsi4u7ShmVmZuXS1PMIBgA/AnYBngG+ERGLyxWYmZmVR1Nt/TcDfwSOIbsD6c83dOGSRkp6TtI8Sec3Ue4YSSFp2Iauw8zMNk1TTUNdI+LG9Po5Sf/ckAVLqgLGkz3qchEwXdKkiJiTV64r8HXg8Q1ZvpmZtYymEkFnSXuz7jkEW+QOR0RziWE/YF5EzAeQNJHsfkVz8spdCvwAOHcDYzczsxbQVCJ4FbgyZ/i1nOEA/rOZZe8ILMwZXgQMzy0gaR9gp4i4T1KjiUDSacBpAL17+w7YZmYtqakH03yqlCtON6+7EjipubIRcQNwA8CwYcOilHGZmVWaUv4wbDGwU85wrzSuTldgT2CqpAXAx4BJ7jA2MyuvUiaC6cAASX0ldQTGApPqJkbE2xHRIyL6REQf4DHgyIiYUcKYzMwsT8kSQUTUAmcAU4C5wB0RMVvSJZKOLNV6zcxswzT7y2JJAj4P9IuIS9Lzij8SEdOamzciJpN3O4qIuLCRsgcWFbGZmbWoYs4IrgH2B45Lw++Q/T7AzMzagWJuOjc8IvaR9CRARLyZ2vzNzKwdKOaMYE36lXBA/fMIPihpVGZmVjbFJIKfAXcDH5b0v8CjwPdLGpWZmZVNMbeh/o2kJ4CDyG4vcXREzC15ZGZmVhbFXDXUG3gP+EPuuIh4uZSBmZlZeRTTWXwfWf+AgM5AX+A5YFAJ4zIzszIppmlocO5wulHcV0sWkZmZldUG/7I43X56eLMFzcysTSimj2BczmAHYB/glZJFZGZmZVVMH0HXnNe1ZH0GvytNOGZmVm5NJoL0Q7KuEfGNMsVjZmZl1mgfgaTqiFgLfLyM8ZiZWZk1dUYwjaw/YKakScCdwLt1EyPi9yWOzczMyqCYPoLOwHKyZxTX/Z4gACcCM7N2oKlE8OF0xdAs1iWAOn5usJlZO9FUIqgCtqJhAqjjRGBm1k40lQhejYhLyhaJmZm1iqZ+WVzoTMDMzNqZphLBQWWLwszMWk2jiSAi3ihnIGZm1jo2+KZzZmbWvjgRmJlVOCcCM7MK50RgZlbhnAjMzCqcE4GZWYVzIjAzq3BOBGZmFc6JwMyswpU0EUgaKek5SfMknV9g+jhJcyQ9Len/JO1cynjMzGx9JUsE6XnH44FDgYHAcZIG5hV7EhgWEUOAu4AflioeMzMrrJRnBPsB8yJifkS8D0wEjsotEBEPRcR7afAxoFcJ4zEzswJKmQh2BBbmDC9K4xpzCnB/oQmSTpM0Q9KMpUuXtmCIZma2WXQWS/oCMAy4otD0iLghIoZFxLCePXuWNzgzs3aumIfXb6zFwE45w73SuAYkfRr4NnBARKwuYTxmZlZAKc8IpgMDJPWV1BEYC0zKLSBpb+B64MiIWFLCWMzMrBElSwQRUQucAUwB5gJ3RMRsSZdIOjIVuwLYCrhT0kxJkxpZnJmZlUgpm4aIiMnA5LxxF+a8/nQp129mZs3bLDqLzcys9TgRmJlVOCcCM7MK50RgZlbhnAjMzCqcE4GZWYVzIjAzq3BOBGZmFc6JwMyswjkRmJlVOCcCM7MK50RgZlbhnAjMzCqcE4GZWYVzIjAzq3BOBGZmFc6JwMyswjkRmJlVOCcCM7MK50RgZlbhnAjMzCpcdWsHYLY5WrNmDYsWLWLVqlWtHYrZBuncuTO9evWipqam6HmcCMwKWLRoEV27dqVPnz5Iau1wzIoSESxfvpxFixbRt2/foudz05BZAatWraJ79+5OAtamSKJ79+4bfCbrRGDWCCcBa4s25nPrRGBmVuGcCMw2Y/fccw+SePbZZwGYOnUqhx9+eIMyJ510EnfddReQdXKff/75DBgwgH322Yf999+f+++/v6h1rV69mjFjxtC/f3+GDx/OggULCpa76qqr2HPPPRk0aBA//elP68dffPHF7LjjjgwdOpShQ4cyefJkABYsWMAWW2xRP/4rX/nKess88sgj2XPPPeuHn3rqKfbff38GDx7MEUccwYoVK+qnXXbZZfTv35/ddtuNKVOm1I//05/+xG677Ub//v25/PLL68d/8pOfrF/3DjvswNFHH91g3dOnT6e6urp+H9ZZsWIFvXr14owzzmg23jvvvJNBgwbRoUMHZsyY0aDs008/zf7778+gQYMYPHhwfbPNhAkTGDx4MEOGDGHkyJEsW7YMgDFjxtTH26dPH4YOHQrAtGnT6sfvtdde3H333evFtdEiok397bvvvrExrps6L3Y+74/x7uo1GzW/VZY5c+a0dggRETF69Oj4xCc+ERdeeGFERDz00ENx2GGHNShz4oknxp133hkREeedd16ccMIJsWrVqoiIeO211+L2228val3jx4+PL3/5yxERMWHChBg9evR6ZZ555pkYNGhQvPvuu7FmzZo46KCD4l//+ldERFx00UVxxRVXrDfPiy++GIMGDWp0vb/73e/iuOOOa1Bm2LBhMXXq1IiIuOmmm+KCCy6IiIjZs2fHkCFDYtWqVTF//vzo169f1NbWRm1tbfTr1y9eeOGFWL16dQwZMiRmz5693ro++9nPxq233lo/XFtbG5/61Kfi0EMPrd+Hdc4666w47rjj4mtf+1qz8c6ZMyeeffbZOOCAA2L69On149esWRODBw+OmTNnRkTEsmXLora2NtasWRM9e/aMpUuXRkTEueeeGxdddNF68Y4bNy6++93vRkTU7/OIiFdeeSV69uxZP5yv0OcXmBGN1Ku+asisGd/9w2zmvLKi+YIbYOAOW3PREYOaLLNy5UoeffRRHnroIY444gi++93vNln+vffe48Ybb+TFF1+kU6dOAGy33XaMHj26qJjuvfdeLr74YgCOPfZYzjjjDCKiQZvz3LlzGT58OFtuuSUABxxwAL///e/55je/WdQ68q1cuZIrr7ySG264oUGczz//PCNGjADgM5/5DIcccgiXXnop9957L2PHjqVTp0707duX/v37M23aNAD69+9Pv379ABg7diz33nsvAwcOrF/mihUrePDBB/nlL39ZP+7nP/85xxxzDNOnT28Q1xNPPMHrr7/OyJEjGxzhNxbvHnvsUXD7HnjgAYYMGcJee+0FQPfu3YHszC0iePfdd+nevTsrVqygf//+DeaNCO644w4efPBBgPp9DtnFDC3Zh+WmIbPN1L333svIkSPZdddd6d69O0888UST5efNm0fv3r3ZeuutC07PbXLI/fvVr34FwOLFi9lpp50AqK6uplu3bixfvrzBMvbcc08eeeQRli9fznvvvcfkyZNZuHBh/fSrr76aIUOG8MUvfpE333yzfvyLL77I3nvvzQEHHMAjjzxSP/473/kO55xzToNKDmDQoEHce++9QNbsUreO3BgBevXqxeLFixsdn+uee+7hoIMOqt8/ixcv5u677+b0009vUO6DDz7gnHPO4Uc/+tF6+7CxeBvz/PPPI4lDDjmEffbZhx/+8IcA1NTUcO211zJ48GB22GEH5syZwymnnNJg3kceeYTtttuOAQMG1I97/PHH65uYrrvuOqqrW+ZY3mcEZs1o7si9VCZMmMDXv/51IDvCnTBhAkcccUTBssUcHd5+++2bHNMee+zBeeedx8EHH0yXLl0YOnQoVVVVAJx++ul85zvfQVJ9hXnzzTez/fbb8/LLL9cns6OPPprZs2czf/58XnjhBX7yk5+s1x9x8803c9ZZZ3HppZdy5JFH0rFjx02OfcKECZx66qn1w2effTY/+MEP6NCh4fHwNddcw6hRo+jVq1eD8TNnzmw03sbU1tby6KOPMn36dLbccksOOugg9t13X0aMGMG1117Lk08+Sb9+/TjzzDO57LLLuOCCCxrEe9xxxzVY3vDhw5k9ezZz587lxBNP5NBDD6Vz584buCfWV9JEIGkkcBVQBfwiIi7Pm94J+BWwL7AcGBMRC0oZk1lb8MYbb/Dggw/yzDPPIIm1a9ciiRNPPLHBkXZd2R49etC/f39efvllVqxYUfCsYMyYMTz33HPrjR83bhwnnHACO+64IwsXLqRXr17U1tby9ttv1zdl5DrllFPqj16/9a1v1VeY2223XX2ZL33pS/Wd2p06dapvqtp3333ZZZddeP7555k+fTozZsygT58+1NbWsmTJEg488ECmTp3K7rvvzgMPPABkR9X33XcfQH2MdRYtWsSOO+4I0Oh4gGXLljFt2rQGHawzZsxg7Nix9dMnT55MdXU1//jHP3jkkUe45pprWLlyJe+//z5bbbUVO++8c6PxNqZXr16MGDGCHj16ADBq1Cj++c9/1r8/u+yyCwCjR49u0MFdW1vL73//+0bPAvfYYw+22morZs2axbBhwxpdf9Ea6zzY1D+yyv8FoB/QEXgKGJhX5qvAden1WOD25pbrzmIrh9buLL7++uvjtNNOazBuxIgRMXXq1OjTp099fAsWLIjevXvHW2+9FRFZp+NJJ50Uq1evjoiIJUuWxB133FHUOq+++uoGncWf+9znCpZ7/fXXIyLipZdeit122y3efPPNiMg6MOtceeWVMWbMmPoYamtrIyLihRdeiB122CGWL1/eYJn5Hcp161i7dm0cf/zxcdNNN0VExKxZsxp0Fvft27e+87Vv374xf/78+s7iWbNm1S/v2muvjRNOOKHRbc/tcM/1y1/+cr3O4kLx1snvLH7jjTdi7733btC5/sc//jEWL14cH/nIR2LJkiUREXHBBRfEuHHj6ue7//77Y8SIEQ2WPX/+/PrO4QULFsT2229f39mcb3PqLN4PmBcR8wEkTQSOAubklDkKuDi9vgu4WpJS0GYVa8KECZx33nkNxh1zzDFMnDiR2267jZNPPplVq1ZRU1PDL37xC7p16wbA9773PS644AIGDhxI586d6dKlC5dccklR6zzllFM4/vjj6d+/P9tuuy0TJ04E4JVXXuHUU0+tvxz0mGOOYfny5dTU1DB+/Hi22WYbAL75zW8yc+ZMJNGnTx+uv/56AB5++GEuvPBCampq6NChA9dddx3bbrtts9s/fvx4AD772c9y8sknA1nfwejRoxk4cCDV1dWMHz++vmnq6quv5pBDDmHt2rV88YtfZNCgdU16EydO5Pzzzy9qP2yMu+++mzPPPJOlS5dy2GGHMXToUKZMmcKHPvQhxo0bx0c/+lEkMWrUKA477DAALrroIkaMGEFNTQ0777wzt9xyS4N485uFHn30US6//PL6/XjNNdfUn2lsKpWqzpV0LDAyIk5Nw8cDwyPijJwys1KZRWn4hVRmWd6yTgNOA+jdu/e+L7300gbH88Ds17hn5mKuHD2UzjVVG7tZViHmzp3b6JUgZpu7Qp9fSU9ERMF2pDbRWRwRNwA3AAwbNmyjMtfBgz7CwYM+0qJxmZm1B6W8fHQxsFPOcK80rmAZSdVAN7JOYzMzK5NSJoLpwABJfSV1JOsMnpRXZhJwYnp9LPCg+wdsc+GPorVFG/O5LVkiiIha4AxgCjAXuCMiZku6RNKRqdhNQHdJ84BxQOl6c8w2QOfOnVm+fLmTgbUpkZ5HsKG/LShZZ3GpDBs2LPJv6mTW0vyEMmurGntCWZvvLDYrt5qamg16wpNZW+Z7DZmZVTgnAjOzCudEYGZW4dpcZ7GkpcCG/7Q40wNY1myp9sXbXBm8zZVhU7Z554joWWhCm0sEm0LSjMZ6zdsrb3Nl8DZXhlJts5uGzMwqnBOBmVmFq7REcENrB9AKvM2VwdtcGUqyzRXVR2BmZuurtDMCMzPL40RgZlbh2mUikDRS0nOS5kla746mkjpJuj1Nf1xSn1YIs0UVsc3jJM2R9LSk/5O0c2vE2ZKa2+accsdICklt/lLDYrZZ0uj0Xs+W9Ntyx9jSivhs95b0kKQn0+d7VGvE2VIk3SxpSXqCY6HpkvSztD+elrTPJq+0sYcZt9U/oAp4AegHdASeAgbmlfkqcF16PRa4vbXjLsM2fwrYMr0+vRK2OZXrCjwMPAYMa+24y/A+DwCeBD6Uhj/c2nGXYZtvAE5PrwcCC1o77k3c5hHAPsCsRqaPAu4HBHwMeHxT19kezwj2A+ZFxPyIeB+YCByVV+Yo4Nb0+i7gIEkqY4wtrdltjoiHIuK9NPgY2RPj2rJi3meAS4EfAO3hftLFbPOXgPER8SZARCwpc4wtrZhtDmDr9Lob8EoZ42txEfEw8EYTRY4CfhWZx4BtJG2/Ketsj4lgR2BhzvCiNK5gmcgeoPM20L0s0ZVGMduc6xSyI4q2rNltTqfMO0XEfeUMrISKeZ93BXaV9DdJj0kaWbboSqOYbb4Y+IKkRcBk4MzyhNZqNvT73iw/j6DCSPoCMAw4oLVjKSVJHYArgZNaOZRyqyZrHjqQ7KzvYUmDI+Kt1gyqxI4DbomIH0vaH/i1pD0j4oPWDqytaI9nBIuBnXKGe6VxBctIqiY7nVxeluhKo5htRtKngW8DR0bE6jLFVirNbXNXYE9gqqQFZG2pk9p4h3Ex7/MiYFJErImIF4HnyRJDW1XMNp8C3AEQEf8AOpPdnK29Kur7viHaYyKYDgyQ1FdSR7LO4El5ZSYBJ6bXxwIPRuqFaaOa3WZJewPXkyWBtt5uDM1sc0S8HRE9IqJPRPQh6xc5MiLa8nNOi/ls30N2NoCkHmRNRfPLGGNLK2abXwYOApC0B1kiWFrWKMtrEnBCunroY8DbEfHqpiyw3TUNRUStpDOAKWRXHNwcEbMlXQLMiIhJwE1kp4/zyDplxrZexJuuyG2+AtgKuDP1i78cEUe2WtCbqMhtbleK3OYpwMGS5gBrgXMjos2e7Ra5zecAN0r6f2Qdxye15QM7SRPIknmP1O9xEVADEBHXkfWDjALmAe8BJ2/yOtvw/jIzsxbQHpuGzMxsAzgRmJlVOCcCM7MK50RgZlbhnAjMzCqcE4FtliStlTQz569PE2VXtsD6bpH0YlrXP9MvVDd0Gb+QNDC9/lbetL9vaoxpOXX7ZZakP0jappnyQ9v63Tit9Hz5qG2WJK2MiK1aumwTy7gF+GNE3CXpYOBHETFkE5a3yTE1t1xJtwLPR8T/NlH+JLK7rp7R0rFY++EzAmsTJG2VnqPwT0nPSFrvTqOStpf0cM4R8yfT+IMl/SPNe6ek5iroh4H+ad5xaVmzJJ2dxnWRdJ+kp9L4MWn8VEnDJF0ObJHi+E2atjL9nyjpsJyYb5F0rKQqSVdImp7uMf/lInbLP0g3G5O0X9rGJyX9XdJu6Ze4lwBjUixjUuw3S5qWyha6Y6tVmta+97b//Ffoj+xXsTPT391kv4LfOk3rQfaryroz2pXp/znAt9PrKrL7DfUgq9i7pPHnARcWWN8twLHp9eeAx4F9gWeALmS/yp4N7A0cA9yYM2+39H8q6ZkHdTHllKmL8b+AW9PrjmR3kdwCOA24II3vBMwA+haIc2XO9t0JjEzDWwPV6fWngd+l1ycBV+fM/33gC+n1NmT3IurS2u+3/1r3r93dYsLajX9HxNC6AUk1wPcljQA+IDsS3g54LWee6cDNqew9ETFT0gFkDyv5W7q1RkeyI+lCrpB0Adl9ak4hu3/N3RHxborh98AngT8BP5b0A7LmpEc2YLvuB66S1AkYCTwcEf9OzVFDJB2bynUju1nci3nzbyFpZtr+ucCfc8rfKmkA2W0WahpZ/8HAkZK+kYY7A73TsqxCORFYW/F5oCewb0SsUXZH0c65BSLi4ZQoDgNukXQl8Cbw54g4roh1nBsRd9UNSDqoUKGIeF7Zsw5GAd+T9H8RcUkxGxERqyRNBQ4BxpA9aAWyp02dGRFTmlnEvyNiqKQtye6/8zXgZ2QP4HkoIv4rdaxPbWR+AcdExHPFxGuVwX0E1lZ0A5akJPApYL1nLit7DvPrEXEj8Auyx/09BnxcUl2bfxdJuxa5zkeAoyVtKakLWbPOI5J2AN6LiNvIbuZX6Jmxa9KZSSG3k90orO7sArJK/fS6eSTtmtZZUGRPmzsLOEfrbqVedyvik3KKvkPWRFZnCnCm0umRsrvSWoVzIrC24jfAMEnPACcAzxYocyDwlKQnyY62r4qIpWQV4wRJT5M1C+1ezAoj4p9kfQfTyPoMfhERTwKDgWmpieYi4HsFZr8BeLquszjPA2QPBvpLZI9fhCxxzQH+qeyh5dfTzBl7iuVpsgez/BC4LG177nwPAQPrOovJzhxqUmyz07BVOF8+amZW4XxGYGZW4ZwIzMwqnBOBmVmFcyIwM6twTgRmZhXOicDMrMI5EZiZVbj/Dy9mbSS9dBAeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm=pred_df.to_pandas(all_rows=True)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df_cm['diagnosis'], df_cm['prediction'])\n",
    "# auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The closer the ROC curve is to the upper left corner of the graph, the higher the accuracy of the test because in the upper left corner, the sensitivity = 1 and the false positive rate = 0 (specificity = 1). The ideal ROC curve thus has an AUC = 1.0. As seen in the above graph the AUC for both the models is close to 1 so the accuracy of both models is very good. </p>\n",
    "\n",
    "<hr style=\"height:1px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>9.3 Show Confusion Matrix</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Confusion Matrix is a performance measurement for machine learning classification problem where output can be two or more classes. It is a table with 4 different combinations of predicted and actual values.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Confusion matrices represent counts from predicted and actual values. The output âTNâ stands for True Negative which shows the number of negative examples classified accurately. Similarly, âTPâ stands for True Positive which indicates the number of positive examples classified accurately. The term âFPâ shows False Positive value, i.e., the number of actual negative examples classified as positive; and âFNâ means a False Negative value which is the number of actual positive examples classified as negative.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_df = pred_df.to_pandas(all_rows=True)\n",
    "cm = confusion_matrix(confusion_matrix_df['diagnosis'], confusion_matrix_df['prediction'])\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['DoesNotHaveCancer', 'HasCancer'],)\n",
    "cmd.plot(cmap='Blues', colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Conclusion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Thus we have seen that with the Teradata Vantage API_Request feature, we can connect to VertexAI endpoints through a function to do real-time scoring on data. A VertexAI endpoint was used to orchestrate model training and deploy the solutionâs ML model. Also the model can be stored in Vantage and then used to score in Vantage. Vantage and ClearScape Anlaytics has helped drastically reduce data preparation, model development, and testing time, while allowing for much more frequent and iterative testing and tuning to ensure maximum life-critical accuracy.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>10. Cleanup</b></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#00233C'><b>Databases and Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We will use the following code to clean up tables and databases created for this demonstration.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed objects related to DEMO_CancerPrediction. That ran for 0:00:03.01\n"
     ]
    }
   ],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_CancerPrediction');\" \n",
    "#Takes 40 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>**Note: </b><i>Please make sure to delete the VertexAI model and endpoints after use using the code in below cell. If these are not deleted the cost will keep increasing till the time it is not deleted.</i></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/323844706402/locations/us-central1/endpoints/1905134792563752960\n",
      "Undeploy Endpoint model backing LRO: projects/323844706402/locations/us-central1/endpoints/1905134792563752960/operations/719941006773977088\n",
      "Endpoint model undeployed. Resource name: projects/323844706402/locations/us-central1/endpoints/1905134792563752960\n",
      "Deleting Endpoint : projects/323844706402/locations/us-central1/endpoints/1905134792563752960\n",
      "Delete Endpoint  backing LRO: projects/323844706402/locations/us-central1/operations/2920723480930418688\n",
      "Endpoint deleted. . Resource name: projects/323844706402/locations/us-central1/endpoints/1905134792563752960\n"
     ]
    }
   ],
   "source": [
    "predictor.cloudObj.delete(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_tdapi_context(\n",
    "    gcp_context,\n",
    "    delete_byom_models=True,\n",
    "    table_name=\"tdapiclient_byom_models\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;border:none;background-color:#00233C;\">\n",
    "<b style = 'font-size:20px;font-family:Arial;color:#00233C'>Required Materials</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Letâs look at the elements we have available for reference for this notebook:</p>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Dataset:</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The dataset for this analysis has been taken from \n",
    "<a href = 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic'>Breast Cancer Wisconsin (Diagnostic) - UCI Machine Learning Repository.</a>\n",
    "\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Filters:</b> \n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Industry:</b> Healthcare</li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Functionality:</b> Machine Learning</li> \n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Use Case:</b> Prediction Analysis</li></p>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>Related Resources:</b>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://usc-word-edit.officeapps.live.com/we/%E2%80%A2%09https:/www.teradata.com/Blogs/Predicting-Heart-Failure-with-Teradata'>Saving Lives, Saving Costs: Predicting Heart Failure with Teradata</a> </li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://www.teradata.com/Blogs/Hyper-scale-time-series-forecasting-done-right'>Hyper-scale time series forecasting done right</a></li>\n",
    "<li style = 'font-size:16px;font-family:Arial;color:#00233C'><a href = 'https://www.teradata.com/Blogs/Forecasting-COVID-19-Using-Teradata-Vantage'>Forecasting COVID-19 Using Teradata Vantage</a></li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<footer style=\"padding-bottom:35px; background:#f9f9f9; border-bottom:3px solid #00233C\">\n",
    "    <div style=\"float:left;margin-top:14px\">ClearScape Analyticsâ¢</div>\n",
    "    <div style=\"float:right;\">\n",
    "        <div style=\"float:left; margin-top:14px\">\n",
    "            Â© 2023, 2024 Teradata. All rights reserved.\n",
    "        </div>\n",
    "    </div>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
