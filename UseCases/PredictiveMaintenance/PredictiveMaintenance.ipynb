{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38bc532d-c78c-4c89-b191-242da0733f39",
   "metadata": {},
   "source": [
    "<header style=\"padding:1px;background:#f9f9f9;border-top:3px solid #00b2b1\"><img id=\"Teradata-logo\" src=\"https://www.teradata.com/Teradata/Images/Rebrand/Teradata_logo-two_color.png\" alt=\"Teradata\" width=\"220\" align=\"right\" />\n",
    "\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Predictive Maintenance using Vantage</b>\n",
    "</header>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71661-19b4-423a-867a-7c815b064c81",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Introduction:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'><b>Y-Machine</b> is a manufacturing company that operates a large fleet of machines across multiple locations. They have been experiencing frequent machine breakdowns, which has been causing significant losses in production time and maintenance costs. To address this issue, <b>Y-Machine</b> is looking for a predictive maintenance solution that can help them identify potential machine failures before they occur, allowing them to proactively schedule maintenance and minimize downtime.</p>\n",
    "\n",
    "<center><img src=\"./images/giphy.gif\" alt=\"Machine GIF\"/><</center>\n",
    "<p><a href=\"https://giphy.com/gifs/Ykga9Kp0xT4GswQAbh\">via GIPHY</a></p>\n",
    "\n",
    "<p style='font-size:16px;font-family:Arial'>To achieve the goal of predictive maintenance, Y-Machine will be leveraging the power of <b>Teradata Vantage</b>, an advanced analytics platform. With Teradata Vantage, we can deploy machine learning algorithms through teradataml, which enable us to identify and mitigate potential machine failures before they even occur.</p>\n",
    "<p style='font-size:16px;font-family:Arial'>Teradata Vantage provides us with the necessary capabilities to analyze the vast amounts of data generated by Y-Machine's machines, such as temperature, rotational speed, and torque. By processing this data and detecting anomalies or patterns, we can take proactive measures to address potential issues, preventing costly downtimes and ensuring the longevity of the machines.</p>\n",
    "<p style='font-size:16px;font-family:Arial'>With Teradata Vantage, we can help Y-Machine stay ahead of the curve, providing them with cutting-edge analytics capabilities to improve the reliability and efficiency of their machines.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833b5bf-74af-42be-8543-3782e1da95dc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we import the required libraries, set environment variables and environment paths (if required).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50a4aa-1211-44fc-8166-317c35253207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from teradataml import *\n",
    "configure.val_install_location = 'val'\n",
    "display.max_rows = 5\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59718f8-7af4-4d1a-abc7-a860eb7cbae3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>1. Initiate a connection to Vantage</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Let's start by connecting to the Teradata system </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>You will be prompted to provide the password. Enter your password, press the Enter key, and then use the down arrow to go to the next cell.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa15590d-c00a-4ecf-a5f1-45eda25153c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../startup.ipynb\n",
    "eng = create_context(host = 'host.docker.internal', username='demo_user', password = password)\n",
    "print(eng)\n",
    "eng.execute('''SET query_band='DEMO=PredictiveMaintenance.ipynb;' UPDATE FOR SESSION;''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22db506-84a7-406b-be9f-9fe69d268ba4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Begin running steps with Shift + Enter keys. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a90d5e-2e0a-4701-9368-adb97f7c9590",
   "metadata": {},
   "source": [
    "<p style = 'font-size:20px;font-family:Arial;color:#E37C4D'><b>Getting Data for This Demo</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>We have provided data for this demo on cloud storage. You can either run the demo using foreign tables to access the data without any storage on your environment or download the data to local storage, which may yield faster execution. Still, there could be considerations of available storage. Two statements are in the following cell, and one is commented out. You may switch which mode you choose by changing the comment string.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2b3c2-f90e-428d-a949-c16294016e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run -i ../run_procedure.py \"call get_data('DEMO_PredictiveMaintenance_cloud');\"        # Takes 1 minute\n",
    "%run -i ../run_procedure.py \"call get_data('DEMO_PredictiveMaintenance_local');\"        # Takes 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670345f-dfd2-440b-919a-ff824c65c2c9",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next is an optional step – if you want to see the status of databases/tables created and space used.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce328a8-e2bf-4b64-98aa-5f8007f86815",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call space_report();\"        # Takes 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f3fe2-ed63-4838-bb19-4c0d0157453d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>2. Read the data from Vantage as a teradataml Dataframe</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9951cf-e2b0-40d7-9a8f-a01c7f48ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(in_schema('DEMO_PredictiveMaintenance', 'Machine_Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566fe34-326a-41f0-9990-0752ce2f2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7178e-0330-4c03-bd2d-c191563f6af5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b><i>*Please scroll down to the end of the notebook for detailed column descriptions of the dataset.</i></b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The dataset above has ten columns, and the 'Target' and 'Failure_Type' columns are dependent columns where the Target column has 1 (Failure) and 0 (No Failure). The Failure_Type column has multiple types of failures.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>3. Data Exploration</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Removing nulls and redundant columns</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the next cell, we'll remove the null values from the dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d2c24-97c8-46fa-8135-707a605a4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of rows before and after removing nulls\n",
    "\n",
    "original_rows = df.shape[0]\n",
    "print(f\"Number of rows in the original DataFrame: {original_rows}\")\n",
    "\n",
    "df = df.dropna()\n",
    "print(f\"Number of rows after removing nulls: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0a8901-891f-4c90-a8f1-3cc8cb8d87bd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>From the above results, we see no null values in the dataset.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the next cell, we'll remove the Product_ID column as we already have a UID column as a unique identifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955720ad-0801-45b0-bb55-27d90726c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column Product_ID\n",
    "df = df.drop(columns=['Product_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16608f3f-8cf0-4d32-905f-f250acc0af4d",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Checking target variable distribution</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the next cell, we'll check the distribution of target variables, i.e., Target and Failure_Type.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f21d79-24e0-4a02-ab21-13230183cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of Failure_Type by Target and create a Pandas DataFrame\n",
    "tdf = df.groupby('Target').assign(count=df.Failure_Type.count()).sort('count', ascending = False).to_pandas()\n",
    "\n",
    "# Create a figure with a larger size\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "tdf = tdf.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Create a bar chart of the counts by Target\n",
    "ax = tdf.plot.bar(x=\"Target\", y=\"count\", rot=45, colormap='summer', ax=ax)\n",
    "\n",
    "# Add the count to the top of each bar\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, label_type='edge', fontsize=10)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "ax.set_title(\"Failure Distribution\")\n",
    "ax.set_xlabel(\"Failure?\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "# Add a grid to the plot\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend(['Count'], loc='best', fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd09a1-25b7-41ed-9487-e67b308c0225",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The distribution here shows that the majority of the products have no failure, and a tiny number of products have some failure.</p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Let's check further w.r.t. Failure_Type</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c595311-78fb-431c-a1b1-d67ff055f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of Failure_Type and create a Pandas DataFrame\n",
    "tdf = df.groupby('Failure_Type').assign(count=df.Failure_Type.count()).sort('count', ascending = False).to_pandas()\n",
    "\n",
    "# Create a figure with a larger size\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Sort the DataFrame by count in descending order\n",
    "tdf = tdf.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Create a bar chart of the counts by Failure_Type\n",
    "ax = tdf.plot.bar(x=\"Failure_Type\", y=\"count\", rot=45, colormap='summer', ax=ax)\n",
    "\n",
    "# Add the count to the top of each bar\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i, label_type='edge', fontsize=10)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "ax.set_title(\"Type of Failure Distribution\")\n",
    "ax.set_xlabel(\"Type of Failure\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "\n",
    "# Add a grid to the plot\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax.legend(['Count'], loc='best', fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fdc1d6-c2fc-4b31-b216-5bb4e7b5c84b",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The distribution here shows that the majority of the products have no failure, and a tiny number of products have different failures.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>There are two target variables: 'Target' and 'Failure_Type'. Let's check if everything is ok.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b08bbf9-af9b-4caf-a1d8-b9b32385c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure = df[df['Target'] == 1]\n",
    "df_failure.groupby('Failure_Type').assign(count=df.Failure_Type.count()).sort('count', ascending = False).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1046e30-22f7-4691-b445-4360edd22a40",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Note:</b> 9 values are classified as failure in the 'Target' variable but as No Failure in the 'Failure_Type' variable. Let's check the dataset:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000f65c-cd38-4b7c-b02d-193b0318433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure[df_failure['Failure_Type'] == 'No Failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3ac79-bff3-48c3-80e5-b7dc274ec5c5",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>It could go both ways, either failure or no failure. It makes sense to remove those instances since we do not know the real target here.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4bd2a-5219-463c-a4c6-15b3c3e8faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_possible_failure = list(df_failure[df_failure['Failure_Type'] == 'No Failure'].get_values()[:, 0])\n",
    "df = df.drop(labels=index_possible_failure, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cd57d-6b16-47f8-b072-6e1f6cff3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure = df[df['Target'] == 0]\n",
    "df_failure.groupby('Failure_Type').assign(count=df.Failure_Type.count()).sort('count', ascending = False).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec86430-029f-444d-af15-d1ea6a52f7ec",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Note:</b> 18 instances are classified as Random Failures by 'Failure_Type', whereas they are classified as No failure by the 'Target'. These 18 instances are, in fact, all instances of 'Random Failures'. Let's check and remove those instances, as we do not know if they belong to the Failure class. Hence, we will end up with four types of failures since 'Random Failures' will be removed altogether.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c85191-6d18-4964-9f1e-29f584c0d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure[df_failure['Failure_Type'] == 'Random Failures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfda96-55cb-4cac-ba8d-cfdc61641602",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_possible_failure = list(df_failure[df_failure['Failure_Type'] == 'Random Failures'].get_values()[:, 0])\n",
    "df = df.drop(labels=index_possible_failure, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f78548-c68b-44a8-8c1b-f7e204ad6bbe",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Checking the correlation</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial'>Here, we'll check the distribution of target variables w.r.t features like torque, rotational speed, air temperature and process temperature.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56234f05-713f-4986-aa2a-4f29ee4a7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f9346-0631-4cc6-b748-32f378796a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "fig, ax = plt.subplots(1, 2, figsize=(22, 8))\n",
    "\n",
    "# Set the titles for each subplot\n",
    "ax[0].set_title('Rot. Speed vs Torque wrt Failure Type (Including class no failure)')\n",
    "ax[1].set_title('Rot. Speed vs Torque wrt Failure Type (Excluding class no failure)')\n",
    "\n",
    "# Set the color palette for the plots\n",
    "palette = ['#E9C0CB', '#39A692', '#976EBD', '#ACBF5C', '#DF8B4E']\n",
    "\n",
    "# Plot the scatterplots\n",
    "sns.scatterplot(data=df1, x='Rotational_speed', y='Torque', hue='Failure_Type', palette=palette, ax=ax[0])\n",
    "sns.scatterplot(data=df1[df1['Target'] == 1], x='Rotational_speed', y='Torque', hue='Failure_Type',\n",
    "                palette=palette[1:], ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb5a4e-9847-4ca0-bb83-2a2dc766f08f",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Some insights:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Power failure happens both for lower and higher rotational speed/torque. It is the type of failure with the highest rotational speed (over 2500rpm) and lowest torque (below around 15Nm). In other words, only power failures occur above and below these thresholds.</li>    \n",
    "    <li>Between torques 16Nm and 41Nm, all failures are tool wear.</li>\n",
    "    <li>Overstrain failures occur with torques ranging from around 47 and 68Nm) and rotational speeds from 1200 to 1500rpm approximately.</li>\n",
    "    <li>The torque range is smaller for heat dissipation failures, and the rotational speed range is higher than for overstrain failures </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24ec1e-3224-4ced-a3ac-f4497ec6247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the figure size\n",
    "fig, ax = plt.subplots(1, 2, figsize=(22, 8))\n",
    "\n",
    "# Set the titles for each subplot\n",
    "ax[0].set_title('Process Temperature vs Air Temperature wrt Failure Type (Including class no failure)')\n",
    "ax[1].set_title('Process Temperature vs Air Temperature wrt Failure Type (Excluding class no failure)')\n",
    "\n",
    "# Set the color palette for the plots\n",
    "palette = ['#E9C0CB', '#39A692', '#976EBD', '#ACBF5C', '#DF8B4E']\n",
    "\n",
    "# Plot the scatterplots\n",
    "sns.scatterplot(data=df1, x='Process_temperature', y='Air_temperature', hue='Failure_Type', palette=palette, ax=ax[0])\n",
    "sns.scatterplot(data=df1[df1['Target'] == 1], x='Process_temperature', y='Air_temperature', hue='Failure_Type',\n",
    "                palette=palette[1:], ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908421a3-fb22-4281-a947-0385e9d84c29",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'><b>Some insights:</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial'>\n",
    "    <li>Heat Dissipation Failure happens when Process Temperature and Air Temperature exceed 300 K.</li>\n",
    "    <li>Other failures have no meaningful insights.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ff7fc-3cce-4281-82b8-2acf12f11225",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>4. Data Transformation</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the next step, we'll use Label Encoder to convert a categorical variable to integer and numerical columns will be scaled using the ZScore function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22bd7c-3b93-4517-8b70-76ac6b749632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bf137-d90f-471c-9f42-e8d70d9cc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label encoders\n",
    "type_encoder = LabelEncoder(values = {\"L\": 1, \"M\": 2, \"H\": 3}, columns = \"Type\", datatype = 'integer')\n",
    "failure_type_encoder = LabelEncoder(values = {\n",
    "                            \"No Failure\": 1,\n",
    "                            \"Heat Dissipation Failure\": 2,\n",
    "                            \"Power Failure\": 3,\n",
    "                            \"Overstrain Failure\": 4,\n",
    "                            \"Tool Wear Failure\": 5\n",
    "                            }, \n",
    "                    columns=['Failure_Type'],\n",
    "                    datatype = 'integer'\n",
    "                  )\n",
    "\n",
    "# Define the standard scaler\n",
    "z_scaler = ZScore(columns = ['Air_temperature', 'Process_temperature',\n",
    "                      'Rotational_speed', 'Torque', 'Tool_wear'],\n",
    "            out_columns = ['Air_temperature', 'Process_temperature',\n",
    "                      'Rotational_speed', 'Torque', 'Tool_wear'])\n",
    "\n",
    "# Define the retain object\n",
    "retain = Retain(columns = \"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a9726-80fc-4267-a5e8-4f617f7f15a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = valib.Transform(data = df,\n",
    "                      label_encode = [type_encoder, failure_type_encoder],\n",
    "                      zscore = z_scaler,\n",
    "                      retain = retain,\n",
    "                      index_columns = 'UID')\n",
    "df_trans = obj.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c61d7-4c3d-4404-94f6-0701d227101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9421ea-c89c-4204-8dd2-b36259a364c1",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>As \"Type\" is a reserved keyword, we'll rename the column \"Machine_type.\"<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe1302-49c9-4b19-bd69-d9b5b5e5f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_td_reserved_keywords('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6e179-1b74-41f4-9bd6-ff7b518cd8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df_trans.assign(Machine_type = df_trans.Type)\n",
    "df_trans = df_trans.drop(columns=['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892747b-b280-423a-8699-5221485f66b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d805fbf-7d7f-47e8-a010-9be1a3da83bd",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>In the next step, we'll split the transformed dataset into training and testing datasets in the ratio 80:20, and we will save the datasets into Vantage.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d597b-988c-4f2e-bf64-9274c13d231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "df_sample = df_trans.sample(frac = [train_ratio, 1.0-train_ratio])\n",
    "\n",
    "# Split into 2 virtual dataframes\n",
    "df_train = df_sample[df_sample.sampleid==1].drop([\"sampleid\"], axis=1)\n",
    "df_test = df_sample[df_sample.sampleid==2].drop([\"sampleid\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4279af-ee91-4c18-9386-a109b9414760",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_to_sql(df_train,\n",
    "            table_name = 'df_train',\n",
    "            schema_name = 'demo_user',\n",
    "            if_exists = 'replace')\n",
    "\n",
    "copy_to_sql(df_test,\n",
    "            table_name = 'df_test',\n",
    "            schema_name = 'demo_user',\n",
    "            if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346840f5-df98-46b8-8ee8-4820ac8a0c86",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>5. In Database Model Training (Binary Classification)</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the next step, we'll use the TD_XGBOOST function to train an xgboost model using the 'Target' column as the target variable for binary classification.\n",
    "<br>\n",
    "<br>\n",
    "The TD_XGBoost function, eXtreme Gradient Boosting, implements the gradient-boosted decision tree designed for speed and performance. It has recently been dominating applied machine learning.\n",
    "<br>\n",
    "<br>\n",
    "of the previous iteration to correct the errors made by existing models. The predicted residual is multiplied by this learning rate and then added to the previous prediction. Models are added sequentially until no further improvements can be made. It is called gradient boosting because it uses a gradient descent algorithm to minimize the loss when adding new models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b0673-4775-4970-9777-6231ac93e190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a table xgb_model using TD_XGBoost from Teradata\n",
    "# The TD_XGBoost function partitions the data by any column, trains an XGBoost classification model with 10 trees, \n",
    "# maximum depth of 7, and 10 iterations, and saves the output to a metadata table xgb_out.\n",
    "# If the table xgb_model already exists, drop it and the metadata table xgb_out before creating the new table.\n",
    "\n",
    "query = f'''CREATE TABLE xgb_model AS (\n",
    "SELECT * FROM TD_XGBoost(\n",
    "ON df_train PARTITION BY ANY\n",
    "OUT TABLE MetaInformationTable(xgb_out) \n",
    "USING\n",
    "    ResponseColumn('Target')\n",
    "    InputColumns('[3:8]')\n",
    "    MaxDepth(7)\n",
    "    NumBoostedTrees(10)\n",
    "    ModelType('CLASSIFICATION')\n",
    "    Seed(2)\n",
    "    ShrinkageFactor(1)\n",
    "    IterNum(10) \n",
    "    ColumnSampling(1.0) \n",
    ") AS dt) WITH DATA;\n",
    "'''\n",
    "\n",
    "try:\n",
    "    eng.execute(query)\n",
    "except Exception as e:\n",
    "    # Drop the tables and try again if the table already exists\n",
    "    eng.execute(f'DROP TABLE xgb_model;')\n",
    "    eng.execute(f'DROP TABLE xgb_out;')\n",
    "    eng.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf90da-89ba-4b99-9a9f-0c8fa80b7917",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>6. In Database Model Scoring</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>\n",
    "In the next step, we'll use the TD_XGBoostPredict function to score the xgboost model trained in the previous step.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd16ea-de41-4920-9ebc-d19ad290a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''CREATE TABLE xgb_predict_out AS (\n",
    "SELECT * FROM TD_XGBoostPredict(\n",
    "ON df_test AS inputtable PARTITION BY ANY\n",
    "ON xgb_model AS modeltable DIMENSION ORDER BY task_index, tree_num, iter, class_num, tree_order\n",
    "USING\n",
    "IdColumn('uid')\n",
    "ModelType('classification')\n",
    "Accumulate('target')\n",
    ") AS dt\n",
    ") WITH DATA;\n",
    "'''\n",
    "\n",
    "try:\n",
    "    eng.execute(query)\n",
    "except Exception as e:\n",
    "    eng.execute('DROP TABLE xgb_predict_out;')\n",
    "    eng.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b928d6-568d-42ca-9106-4cde60fe87a4",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next, we'll use the TD_ClassificationEvaluator function to evaluate the trained xgboost model on test data. This will let us know how well our model has performed on unseen data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26749c5a-fd64-4900-9f90-e560a9b546b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the XGBoost model's performance using TD_CLASSIFICATIONEVALUATOR\n",
    "\n",
    "# Check if the necessary tables exist before executing the query\n",
    "if not eng.has_table('xgb_predict_out'):\n",
    "    print('Error: xgb_predict_out table does not exist.')\n",
    "    sys.exit(1)\n",
    "\n",
    "query = '''SELECT * from TD_CLASSIFICATIONEVALUATOR(\n",
    "    ON (\n",
    "        SELECT CAST(\"target\" AS INTEGER) AS \"target\", prediction FROM xgb_predict_out\n",
    "    ) AS InputTable\n",
    "    OUT TABLE OutputTable(additional_metrics)\n",
    "    USING\n",
    "        Labels(0, 1)\n",
    "        ObservationColumn('Target')\n",
    "        PredictionColumn('Prediction')\n",
    ") AS dt1\n",
    "ORDER BY 1, 2, 3;\n",
    "'''\n",
    "\n",
    "try:\n",
    "    eng.execute(query)\n",
    "except:\n",
    "    eng.execute('DROP TABLE additional_metrics;')\n",
    "    eng.execute(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c663fb-4911-4241-bbb2-6a625422c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('SELECT * FROM additional_metrics;', eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e7227-8a18-4c63-b071-13b940703d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data and compute confusion matrix\n",
    "xgb_result = DataFrame(in_schema('demo_user', 'xgb_predict_out')).to_pandas().reset_index()\n",
    "cm = confusion_matrix(xgb_result['Prediction'], xgb_result['Target'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Failure', 'Failure'])\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "\n",
    "# Add labels and annotations\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(ticks=[0, 1], labels=['No Failure', 'Failure'])\n",
    "plt.yticks(ticks=[0, 1], labels=['No Failure', 'Failure'])\n",
    "\n",
    "# Add text to the plot to show the actual values of the confusion matrix\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, f'{cm[i, j]}', ha='center', va='center', color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ed8a2-6a6f-4ed5-aaeb-f6d5cf0fc31a",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above metrics show that our model performs well on the binary classification test dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c32ff2-c021-468b-98a9-43af77318e0f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>7. In Database Model Training (Multi-Class Classification)</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the next step, we'll use the TD_XGBOOST function to train an xgboost model using Failure_Type as the target variable for multi-class classification.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ff9d93-5c9c-4a44-8bb9-f28464250bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "    CREATE TABLE xgb_model AS (\n",
    "        SELECT * FROM TD_XGBoost (\n",
    "            ON df_train PARTITION BY ANY\n",
    "            OUT TABLE MetaInformationTable(xgb_out) \n",
    "            USING\n",
    "                ResponseColumn('Failure_Type')\n",
    "                InputColumns('[3:8]')\n",
    "                MaxDepth(7)\n",
    "                NumBoostedTrees(10)\n",
    "                ModelType('CLASSIFICATION')\n",
    "                Seed(2)\n",
    "                ShrinkageFactor(0.9)\n",
    "                IterNum(10)\n",
    "                ColumnSampling(1) \n",
    "        ) AS dt\n",
    "    ) WITH DATA;\n",
    "'''\n",
    "\n",
    "try:\n",
    "    eng.execute(query)\n",
    "except Exception as e:\n",
    "    eng.execute('DROP TABLE xgb_model;')\n",
    "    eng.execute('DROP TABLE xgb_out;')\n",
    "    eng.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e69e89-62c6-4173-9cfe-d322fe0a58a3",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>8. In Database Model Scoring</b>\n",
    "<p style = 'font-size:16px;font-family:Arial'>In the next step, we'll use the TD_XGBoostPredict function to score the xgboost model trained in the previous step.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d68749b-5ffe-419e-b2a3-17b9928b43b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "    CREATE TABLE xgb_predict_out AS (\n",
    "        SELECT *\n",
    "        FROM TD_XGBoostPredict(\n",
    "            ON df_test AS inputtable PARTITION BY ANY\n",
    "            ON xgb_model AS modeltable DIMENSION ORDER BY task_index, tree_num, iter, class_num, tree_order\n",
    "            USING\n",
    "                IdColumn('uid')\n",
    "                ModelType('classification')\n",
    "                Accumulate('Failure_Type')\n",
    "        ) AS dt\n",
    "    ) WITH DATA;\n",
    "'''\n",
    "\n",
    "try:\n",
    "    eng.execute(query)\n",
    "except:\n",
    "    eng.execute('DROP TABLE xgb_predict_out;')\n",
    "    eng.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d094762-61a7-4034-a2c0-a5a7182d69aa",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>Next, we'll use the TD_ClassificationEvaluator function to evaluate the trained xgboost model on test data. This will let us know how well our model has performed on unseen data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1c56d-fc69-4004-8fb7-8b77af5c1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "    SELECT *\n",
    "    FROM TD_CLASSIFICATIONEVALUATOR(\n",
    "        ON (\n",
    "        SELECT CAST(\"Failure_Type\" AS INTEGER) AS \"Failure_Type\", prediction FROM xgb_predict_out) AS InputTable\n",
    "        OUT TABLE OutputTable(additional_metrics)\n",
    "        USING\n",
    "        Labels(0, 1, 2, 3, 4)\n",
    "        ObservationColumn('Failure_Type')\n",
    "        PredictionColumn('Prediction')\n",
    "    ) AS dt1\n",
    "    ORDER BY 1, 2, 3;\n",
    "'''\n",
    "\n",
    "try:\n",
    "    eng.execute(query)\n",
    "except:\n",
    "    eng.execute('DROP TABLE additional_metrics;')\n",
    "    eng.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904c56d-2407-4e7b-ab73-0fec2c5c1560",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('select * from additional_metrics', eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f42ba-0532-4db3-9088-4535c3c3a6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load prediction results into a pandas dataframe\n",
    "xgb_result = DataFrame(in_schema('demo_user', 'xgb_predict_out')).to_pandas().reset_index()\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(xgb_result['Prediction'], xgb_result['Failure_Type'])\n",
    "\n",
    "# Plot confusion matrix using ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "# Create figure and axes objects\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "\n",
    "# Set title and axis labels\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "\n",
    "# Set x and y ticks with labels and rotation\n",
    "plt.xticks(ticks=[0, 1, 2, 3, 4], labels=['No Failure', 'Heat Dissipation Failure', 'Power Failure', 'Overstrain Failure', 'Tool Wear Failure'], rotation=45)\n",
    "plt.yticks(ticks=[0, 1, 2, 3, 4], labels=['No Failure', 'Heat Dissipation Failure', 'Power Failure', 'Overstrain Failure', 'Tool Wear Failure'])\n",
    "\n",
    "# Add text to the plot to show the actual values of the confusion matrix\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, f'{cm[i, j]}', ha='center', va='center', color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b7ab3-a5db-4392-a67a-36b1f016c887",
   "metadata": {},
   "source": [
    "<p style = 'font-size:16px;font-family:Arial'>The above metrics show that our model performs well on the multi-class classification test dataset.</p>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Conclusion:</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>By implementing a predictive maintenance solution, <b>Y-Machine</b> can significantly reduce their machine downtime and maintenance costs while improving their overall production efficiency. The solution will allow them to proactively schedule maintenance and avoid costly breakdowns, reducing the need for emergency repairs and improving the reliability of their machines. With real-time reporting and analytics, <b>Y-Machine</b> can make data-driven decisions about their maintenance strategy, improving the performance of their machines and increasing their overall productivity.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8b817-c0ff-42b3-a651-c8268ac40942",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>9. Cleanup</b>\n",
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'><b>Work Tables</b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>Cleanup work tables to prevent errors next time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd8f89-67ed-4f8e-9942-ed37fbd30098",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE df_train;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923c1a5-b187-45f1-bf06-7c041c23ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE df_test;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3554f-a9ef-4d4d-b7c3-cf386314f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE xgb_model;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9efbc6-e495-4e30-adc9-8b3cdcdbcb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE xgb_out;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdc0db0-ad76-4c04-8cd8-2e12d9db2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.execute('DROP TABLE xgb_predict_out;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacb87c-0d81-40f0-8754-608d47e602cc",
   "metadata": {},
   "source": [
    "<p style = 'font-size:18px;font-family:Arial;color:#E37C4D'> <b>Databases and Tables </b></p>\n",
    "<p style = 'font-size:16px;font-family:Arial'>The following code will clean up tables and databases created above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b398148-9486-4535-8c06-d3f77669bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../run_procedure.py \"call remove_data('DEMO_PredictiveMaintenance');\"        # Takes 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef4cbe-1beb-4c65-ac60-ffd6250668a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae971f90-bef1-4228-bcbf-c333e9843284",
   "metadata": {},
   "source": [
    "<b style = 'font-size:28px;font-family:Arial;color:#E37C4D'>Dataset:</b>\n",
    "\n",
    "- `UID`: Unique identifier ranging from 1 to 10000\n",
    "- `Product_ID`: Unique Product ID consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\n",
    "- `Type`: Consisting of a letter L, M, or H for low (50% of all products), medium (30%) and high (20%) as product quality variants and a variant-specific serial number\n",
    "- `Air_temperature`: Generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\n",
    "- `Process_temperature`: Generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K\n",
    "- `Rotational_speed`: Calculated from a power of 2860 W, overlaid with a normally distributed noise\n",
    "- `Torque`: Torque values are normally distributed around 40 Nm with a Ïƒ = 10 Nm and no negative values\n",
    "- `Tool_wear`: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process\n",
    "- `Target`: If the machine failed or not (boolean)\n",
    "- `Failure_Type`: Type of failure -\n",
    "                            No Failure,\n",
    "                            Heat Dissipation Failure,\n",
    "                            Power Failure,\n",
    "                            Overstrain Failure,\n",
    "                            Tool Wear Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5463848-592f-4321-b852-287e133872dd",
   "metadata": {},
   "source": [
    "<footer style=\"padding:10px;background:#f9f9f9;border-bottom:3px solid #394851\">Copyright © Teradata Corporation - 2023. All Rights Reserved.</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
